======================<br><b>생성계정 : 타임게이트 타임게이트</b><br><b>생성날짜 : 2018-07-23T02:13:08Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2018-08-16T10:05:05Z</b><br><b>id : 500A000000bU9XVIA0</b><br>======================<br><br><b><font size=15>
제목  : RHCS 페일오버 관련
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요. 타임게이트 송기호입니다. 우선 작업지원 감사드립니다.<br>덕분에 작업은 잘 마무리 되었습니다. <br><br>작업후 페일오버 테스트를 진행하였는데요.<br>서비스망 절체 핫빗망절체 fence_node등 정상적으로 페일오버가 되었습니다.<br>그런데 <br>SAN스위치 FC포트 절체시에는 정상적으로 페일오버가 되지 않아 문의드립니다.<br>FC포트 절체는 1호기쪽으로 하였습니다.<br><br>&lt;FLPTRSD01&gt; 의 로그 <br>샌스위치의 포트를 제거 후 아래와 같은 로그가 발생<br><br>Jul 22 10:52:21 FLPTRSD01 qdiskd[5932]: qdiskd: read (system call) has hung for 15 seconds<br>Jul 22 10:52:21 FLPTRSD01 qdiskd[5932]: In 15 more seconds, we will be evicted<br>Jul 22 10:52:49 FLPTRSD01 multipathd: 8:0: mark as failed<br>Jul 22 10:52:49 FLPTRSD01 multipathd: ext0: remaining active paths: 1<br>Jul 22 10:52:49 FLPTRSD01 multipathd: 8:240: mark as failed<br>Jul 22 10:52:49 FLPTRSD01 multipathd: qdisk: remaining active paths: 1<br>Jul 22 10:52:49 FLPTRSD01 kernel: rport-0:0-0: blocked FC remote port time out: removing target and saving binding<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: device-mapper: multipath: Failing path 8:0.<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:7: rejecting I/O to offline device<br>...이하 생략<br><br>&lt;FLPTRSD02&gt;의로그<br>동일하게 장애 감지<br>Jul 22 10:58:10 FLPTRSD02 qdiskd[2120]: qdiskd on node 1 reports hung read()<br>Jul 22 10:58:18 FLPTRSD02 rgmanager[4547]: [script] Executing /etc/cluster/init.orajsa status<br>Jul 22 10:58:25 FLPTRSD02 qdiskd[2120]: qdiskd on node 1 reports hung read()<br>Jul 22 10:58:48 FLPTRSD02 rgmanager[6648]: [script] Executing /etc/cluster/init.orajsa status<br>Jul 22 10:58:55 FLPTRSD02 qdiskd[2120]: Writing eviction notice for node 1<br>Jul 22 10:58:58 FLPTRSD02 qdiskd[2120]: Node 1 evicted<br>..이하생략<br>Jul 22 11:00:17 FLPTRSD02 rgmanager[7267]: start on ip &quot;100.254.40.167&quot; returned 1 (generic error)<br>Jul 22 11:00:17 FLPTRSD02 rgmanager[7267]: #68: Failed to start service:svc_TRSD; return value: 1<br>Jul 22 11:00:17 FLPTRSD02 rgmanager[7267]: Stopping service service:svc_TRSD<br>Jul 22 11:00:17 FLPTRSD02 rgmanager[11241]: [script] Executing /etc/cluster/init.oracle stop<br>Jul 22 11:00:40 FLPTRSD02 rgmanager[14342]: [fs] unmounting /oracle12<br>Jul 22 11:00:40 FLPTRSD02 rgmanager[14574]: [fs] unmounting /oradata_PCDTS<br>Jul 22 11:00:40 FLPTRSD02 rgmanager[14809]: [fs] unmounting /orasys_PCDTS<br>Jul 22 11:00:40 FLPTRSD02 rgmanager[15029]: [fs] unmounting /oraarch_PCDTS<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[15244]: [fs] unmounting /dbadmin<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[15452]: [fs] unmounting /oracle_arch<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[15654]: [fs] unmounting /oracle<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[7267]: Service service:svc_TRSD is recovering<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[7267]: #71: Relocating failed service service:svc_TRSD<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[7267]: Service service:svc_TRSD is stopped<br><br>아이피 충돌(?)로 인해서 서비스 IP를 계속 가지오지 못하는 것으로 보입니다.<br><br><br>작업 중에도 보면<br>FLPTRSD02 에서 recoverable 시도하는 모습이 보이는데 시도하다가 fail로 변경된 후 정상적으로 서비스가 페일오버 되지 않았습니다.<br><br>어떠한 값을 변경해야 할까요??<br>동일한 작업이 금주 주말에 다른 장비에서 있어서 답변을 주시면 적용 후 동일하게 페일오버 테스트를 진행해볼까 합니다.<br><br>감사합니다.<br><br>============================================================================<br>* 고객 정보 (필수) - 실제 레드햇 서브스크립션을 소유하고 시스템에 사용 중인 엔드 유저<br>- 성함(직급) : 송기용 (책임)<br>- 회사명(부서명) : 삼성SDS<br>- 전화번호 :  82-10-9006-9506 <br>- 메일주소 : 송기용 &lt;kyyong.song@samsung.com&gt;<br><br>* 파트너 정보 (옵션) - 실제 고객의 시스템을 유지보수하는 업체<br>- 성함(직급) : 송기호(책임)<br>- 회사명(부서명) : 타임게이트(오픈소스팀)<br>- 전화번호 : 01036209917<br>- 메일주소 : kh.song@time-gate.com<br>==============================================================================<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>RHCS, 쿼럼 휴리스틱, 각각의서비스가 1호기active 2호기 active, oracle<br><br>언제 문제가 발생했습니까? 이러한 문제가 자주 발생합니까? 반복적으로 발생합니까? 특정 시간에 발생합니까?<br><br>물리적인 SAN 스위치 포트제거시<br><br>해결 기간이나 업무에 미치는 영향에 대한 정보를 제공해 주시겠습니까?<br><br>운영서버로 중요도가 높습니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 6.4</b><br><b>타입  : Configuration issue</b><br><b>계정 번호  : 1648604</b><br><b>심각도  : 3 (Normal)</b><br><hostname>FLPTRSD01 / FLPTRSD02</hostname><br><br><br><comment id="a0aA000000NJ2caIAD"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2018-07-30T13:28:31Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2018-07-30T13:28:30Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해주셔서 감사합니다.<br><br>관련 피드백 감사합니다.<br><br>&gt; 혹시 kernel.nmi_watchdog  혹은 kernel.unknown_nmi_panic 와 연관이 있는 걸까요?<br><br>이전 타케이스에서 저희 엔지니어가 안내드린 것 같습니다만<br>관련되었다는 정보는 찾아보기가 어렵습니다.<br><br>감사합니다.<br><br><publishedDate>2018-07-30T13:28:30Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000NIvOvIAL"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2018-07-30T02:33:33Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2018-07-30T02:33:33Z</b><br><br>답변감사합니다.<br>주말 작업중<br>펜싱에이젼트를 패치 했음에도 불구하고 여전히 SAN스위치 장애간에서는 펜싱이 발생하지 않았습니다.<br>의문점이 hardware watchdog  이라고 말씀하셨는데요.<br>혹시 kernel.nmi_watchdog  혹은 kernel.unknown_nmi_panic 와 연관이 있는 걸까요?<br>보통 grub.conf에 nmi_watchdog=0로 하고 있습니다.<br>감사합니다.<br><br><publishedDate>2018-07-30T02:33:33Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000NI5GPIA1"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2018-07-25T09:54:22Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2018-07-26T06:59:08Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해주셔서 감사합니다.<br><br>현재 문의하신 내용의 경우 유선상으로 말씀드렸습니다만,<br><br>&gt; Q) 현재 cluster설정에서 75초+알파 후에 페일오버가 되어야함에도 불구하고 페일오버가 되지 않은 점은 어떠한 원인인가요?<br><br>totem timeout 의 경우 token 교환이 정상적으로 이루어지지 않았을 때의 timeout 값이며<br>기본적으로 heartbeat 관련 장애(노드 크래쉬, 네트워크 장애, 스위치 장애 등으로 응답이 오지 않을 때)와 관련된 값입니다.<br>따라서, 현재와 같이 스토리지가 장애가 발생하였다고 해도 token 교환이 정상적으로 이루어진다면<br>totem timeout 에 의한 페일오버 대상은 되지 않으며 이는 예상된 동작입니다.<br><br>&gt; Q)장애노드에서 모든 서비스가 stop되지 않았음에도 불구하고 왜 정상노드에서 서비스를 가져가려고 한것은 어떠한 이유인가요?<br><br>이는 fencing 이 성공해서 입니다. 모든 페일오버를 위한 서비스의 필수 시작조건은 데이터보호를 위해 문제가 있는 상대노드에 대한 fencing 이 성공해야합니다.<br>따라서, 현재와 같이 fencing 이 성공한 후, 서비스를 시작하려고 하는 것은 정상적인 동작입니다.<br>====<br>Jul 22 11:00:12 FLPTRSD02 fenced[2500]: fencing node flptrsd01.cs<br>Jul 22 11:00:14 FLPTRSD02 fenced[2500]: fence flptrsd01.cs success<br>Jul 22 11:00:14 FLPTRSD02 rgmanager[7267]: Starting stopped service service:svc_TRSD<br>Jul 22 11:00:14 FLPTRSD02 rgmanager[8189]: [fs] mounting /dev/dm-24 on /oracle<br>Jul 22 11:00:14 FLPTRSD02 rgmanager[8301]: [fs] mount -t ext4 -o rw,nobarrier /dev/dm-24 /oracle <br>...<br>====<br><br>fencing 이 성공했는데 현재 IP collision 이 발생하여 페일오버가 실패하는 이유는 고객 환경에서 power fencing 이 아닌 스토리지 fencing 을 사용해서 입니다.<br>즉, 스토리지 fencing 성격상 스토리지 연결단만 차단되지 네트워크망은 여전히 동작하기 때문입니다.<br><br>현재는 기존 말씀드린바와 같이 hardware watchdog 스크립트를 사용해서 fence_scsi 에 의해 스토리지 fencing 이 이루어졌을 때<br>하드 리부팅이 발생하도록 하시면 개선될 것으로 예상됩니다. 다만 고객 환경상에서 실제 적용 및 테스트가 필요하므로 확인 후 피드백 부탁드립니다.<br><br>감사합니다.<br><br><publishedDate>2018-07-25T09:54:22Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000NI3CmIAL"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2018-07-25T07:25:39Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2018-07-25T07:25:38Z</b><br><br>답변감사합니다.<br>추가 문의 드립니다<br><br>Q) 현재 cluster설정에서 75초+알파 후에 페일오버가 되어야함에도 불구하고 페일오버가 되지 않은 점은 어떠한 원인인가요?<br><br>Q)장애노드에서 모든 서비스가 stop되지 않았음에도 불구하고 왜 정상노드에서 서비스를 가져가려고 한것은 어떠한 이유인가요?<br><br>답변부탁드립니다. ㅠ<br><br><publishedDate>2018-07-25T07:25:38Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000NHzxHIAT"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2018-07-25T01:06:21Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2018-07-25T01:06:20Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해주셔서 감사합니다.<br><br>일단 설치하신 watchdog 버젼 및 저희 관련 문서를 안내드리면 다음과 같습니다. <br><br>사용하시는 fence-agents 패키지버젼: fence-agents-3.1.5-25.el6.x86_64<br><br>Is there a watchdog script for fence_scsi to reboot a RHEL High Availability or Resilient Storage cluster node? <br>  https://access.redhat.com/solutions/65187<br>====<br>2) Link the fence_scsi_check.pl script to the /etc/watchdog.d/ directory.<br>Raw<br><br># ln -s /usr/share/cluster/fence_scsi_check.pl /etc/watchdog.d/<br><br>Starting with fence-agents-3.1.5-48.el6, an alternate script is offered that will issue a &quot;hard&quot; reboot on the node that was fenced rather than relying on watchdog's reboot procedure which may be prone to becoming blocked when using GFS2 or device-mapper-multipath. To use this version of the watchdog script, link it to the watchdog.d directory.:<br>Raw<br><br># ln -s /usr/share/cluster/fence_scsi_check_hardreboot.pl /etc/watchdog.d/<br><br>NOTE: Only one of the above scripts should be linked in the watchdog.d directory<br>====<br><br>상기문서에도 나와있지만, fence-agents-3.1.5-48.el6 이전 패키지에서 제공하는<br>fence_scsi_check.pl 의 경우 gfs2 또는 multipath 를 사용할 때 리부팅이 정상적으로 안되는 경우가 있어<br>fence-agents-3.1.5-48.el6 패키지부터 제공하는 fence_scsi_check_hardreboot.pl 스크립트를<br>사용하도록 말씀드리고 있습니다.<br><br>이와 관련해서는 기존 케이스 02135908 에서 저희 박과장이 이미 안내드린 것으로 파악되는데요.<br>클러스터를 위한 fence-agents 패키지의 업데이트라 고객 서비스에의 영향이 없을텐데<br>이전 버젼을 사용해야하는 이유가 있으신가요?<br><br>확인 바랍니다.<br><br>감사합니다.<br><br><publishedDate>2018-07-25T01:06:20Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000NHmHPIA1"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2018-07-24T08:46:13Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2018-07-24T08:46:13Z</b><br><br>아래의 부분은 고객이 문의하신 내용전문입니다.<br>분석시 참고 부탁드립니다.<br><br><br>안녕하세요,<br>Red Hat Global Support Services 를 이용해주셔서 감사합니다.<br>말씀하신 이슈는 다음 링크와 같이 기보고되어 있으며 fence_scsi 를 사용할 경우 발생할 수 있습니다.<br>Clustered IP resource fails to recover after active node is fenced using a storage method in RHEL<br>https://access.redhat.com/solutions/220323 '<br><br> <br><br>:  첫번째 링크에 나온 해결 방법중에 watchdog 적용이 있습니다.<br><br>   저희는 이미 watchdog적용이 되어 있는데, fail-over가 안된 부분 확인 필요합니다.<br><br>   (watchdog이 동작한건지 모르겠으나 SAN 장애감지후 약 15분 후에 서버가 리붓 되었습니다.)<br><br> <br><br>   작업전에 알려주신 fail-over 예상 timeout은 totem toekn인 75초였는데,<br><br>   실제 75초 동안에는 클러스터 관련 action 이 없었고,<br><br>   6분 가까이 경과후에 클러스터 fail-over 동작이 시작했습니다. (동작은 했으나 IP충돌로 실패)<br><br>   설정된 타임아웃이 동작하지 않은 이유도 확인 필요합니다.<br><br>  (참고로 heuristics에 설정된 G/W ping fail 감지시에는 75초안에 동작하였습니다.)<br><br> <br><br><br>저희는 일단 scsi 펜싱보다는 파워펜싱을 권장하고 있습니다만,<br>꼭 fence_scsi 를 사용하셔야 한다면 소프트 watchdog 또는 다음 링크의 멀티패스 타임아웃 관련 파라메터를<br>조절 및 적용해서 테스트해보시기 바랍니다.<br>multipath is not detecting path failures fast enough which results in application failure and system reboots<br>https://access.redhat.com/solutions/137073 ' <br><br> <br><br>: 여기서도 마찬가지로 watchdog 적용얘기를 하셨습니다.<br><br>  멀티패스 관련 링크부분은 저희 테스트와는 좀 다른 이슈 같아서요... <br><br>  watchdog이 정상동작하지 않은 부분 위주로 분석요청 드립니다.<br><br><publishedDate>2018-07-24T08:46:13Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000NHmG7IAL"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2018-07-24T08:44:58Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2018-07-24T08:44:58Z</b><br><br>답변감사합니다.<br>보내주신 솔류션 중에서 <br>3) Tune the storage stack to be able to time out faster. This is tricky, because I/O can fail in different ways, many of which have different length timeouts, and so its difficult to say with certainty that every type of I/O failure will come within the necessary window. However it should be possible to at least reduce the amount of time it takes any stuck status checks to complete when access to storage has been lost. If using device-mapper-multipath to manage the storage devices in question, it is usually beneficial to ensure that queue_if_no_path is disabled, and the no_path_retry queueing setting is either set to a low value, or disabled altogether. Otherwise, after a fence event with fence_scsi, I/O may get blocked indefinitely as paths fail, I/O is queued, paths are reinstated, I/O gets resubmitted causing another failure, I/O gets queued, etc etc.<br>말고<br><br>5)Set up watchdog to reboot a node if it detects it has been fenced. This is not ideal in RHEL 5 because you'd have to write a script to detect this, which may end up being complicated. Red Hat ships a watchdog script in RHEL 6 for detecting when fence_scsi has fenced a node, but there is nothing pre-made in RHEL <br><br><br>Q)3번의 솔류션말고 5번의 솔류션을 보면  작업 당신 와치독이 start되어있음에도 불구하고 노드펜싱이 늦게 발동된 이유가 무엇때문인가요??<br><br>Q)와치독을 설정시에 타임아웃값을 조정해서 펜싱을 장애감지후 바로 펜싱할수 있는 방안이 있을까요?<br><br>Q)IO에러가 발생시 장애에대한 우선순위가 멀티패스 데몬 rhcs보다 높기 때문에 펜싱이 늦게 된것일까요?<br><br>고생이 많으시네요.<br>추가 궁금하신 내용있으시면 연락부탁드립니다.<br><br>감사합니다.<br><br><publishedDate>2018-07-24T08:44:58Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000NHhaLIAT"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2018-07-24T00:51:46Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2018-07-24T00:51:46Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해주셔서 감사합니다.<br><br>어제 유선상으로 말씀나눈바와 같이<br>해당 케이스는 페일오버시 IP 어드레스 충돌 관련이므로<br>만약 추가 질문하실 내용이 있으시면 새롭게 케이스를 열어주시기 바랍니다.<br><br>따라서, 안내드린바와 같이 멀티패스 타임아웃이나 watchdog 등을 설정하신 후,<br>상황 개선 여부에 대한 피드백을 기다리도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2018-07-24T00:51:46Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000NHTxvIAH"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2018-07-23T08:36:47Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2018-07-23T08:36:47Z</b><br><br>답변감사합니다.<br>솔류션은 제가 적용후에 다시 회신드리겠습니다.<br>추가 문의가 있는데요.<br>작업 당시 서비스가<br>1호기(FLPTRSD01)<br>2호기(FLPTRSD02)<br><br>1호기에서는 &quot;svc_TRSD&quot; 스크립트는 &quot;/etc/cluster/init.oracle&quot;가<br>2호기에서는  &quot;svc_PJSA&quot; 스크립트는 &quot;/etc/cluster/init.orajsa&quot;가<br>start중에 있었는데요.<br><br>1호기의 FC망 절체후<br>1호기<br>10:52:06 SAN 포트 disable<br>10:52:21 qdiskd: read (system call) has hung for 15 seconds<br>            In 15 more seconds, we will be evicted<br>10:52:49 multipath fail ,rejecting I/O to offline device, <br>           path removed from map qdisk <br>           ..  다량 발생<br>10:58:10 qdiskd: read (system call) has hung for 15 seconds<br>           In 15 more seconds, we will be evicted<br>10:58:40 multipath fail ,rejecting I/O to offline device, <br>           path removed from map qdisk ..  다량 발생<br>10:58:43 qdiskd[5932]: Error reading node ID block .. <br>            다량 발생<br>10:58:55  Error writing to quorum disk<br>10:58:55 cman killed by node 2 because we were killed by cman_tool or other application<br>10:58:55 cluster is down, exiting<br>10:58:55 Shutting down uncleanly<br>            I/O error 다량 발생<br>10:58:55 [script] Executing /etc/cluster/init.orajsa stop<br> ###   이건 2호기 돌던 서비스를 중단시키는 액션이 발생하였습니다.<br>======================<br>2호기<br><br>10:52:26 qdiskd on node 1 reports hung read()<br>10:52:36 qdiskd on node 1 reports hung read()<br>======================<br>10:58:10 qdiskd on node 1 reports hung read()<br>10:58:25 qdiskd on node 1 reports hung read()<br>======================<br><br>10:58:55 Writing eviction notice for node 1<br>10:58:55 Node 1 Evicted<br>======================<br><br><br>11:00:12 fencing node flptrsd01.cs<br>11:00:14 fence flptrsd01.cs success<br>11:00:14 Starting stopped service service:svc_TRSD<br>            파일 시스템 마운트<br># 1호기에서 umount도 안했는데, 2호기에서 마운트를?<br>11:00:17 Adding IPv4 address 100.254.40.167/24 to bond0<br>            IPv4 address collision 100.254.40.167<br>            start on ip &quot;100.254.40.167&quot; returned 1 (generic error)<br>            Failed to start service:svc_TRSD; return value: 1<br>            Stopping service service:svc_TRSD<br>            Executing /etc/cluster/init.oracle stop<br># 1호기용 서비스 IP가 아직 remove 안되었는데,  2호기에 add 해서 오류발생해서 Fail-over 중단<br>11:00:41 FS umount<br>            Service service:svc_TRSD is stopped<br><br><br>정리하면 각각의 노드에서 다른서비스를 실행중에 있었는데<br>1호기에서는 &quot;svc_TRSD&quot; 스크립트는 &quot;/etc/cluster/init.oracle&quot;가<br>2호기에서는  &quot;svc_PJSA&quot; 스크립트는 &quot;/etc/cluster/init.orajsa&quot;가<br>1호기 문제로 1호기에서만 돌던 스크립트에 stop 인자를 날리면서<br>동시에 2호기의 스크립트에 stop인자까지 날리는지 문의가 왔습니다.<br><br>확인부탁드립니다. ㅠ<br><br><publishedDate>2018-07-23T08:36:47Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000NHTTvIAP"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2018-07-23T08:03:17Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2018-07-23T08:03:17Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해주셔서 감사합니다.<br><br>말씀하신 이슈는 다음 링크와 같이 기보고되어 있으며 fence_scsi 를 사용할 경우 발생할 수 있습니다.<br><br>Clustered IP resource fails to recover after active node is fenced using a storage method in RHEL<br>  https://access.redhat.com/solutions/220323<br><br>저희는 일단 scsi 펜싱보다는 파워펜싱을 권장하고 있습니다만,<br>꼭 fence_scsi 를 사용하셔야 한다면 소프트 watchdog 또는 다음 링크의 멀티패스 타임아웃 관련 파라메터를<br>조절 및 적용해서 테스트해보시기 바랍니다.<br><br>multipath is not detecting path failures fast enough which results in application failure and system reboots <br>  https://access.redhat.com/solutions/137073<br><br>감사합니다.<br><br><publishedDate>2018-07-23T08:03:17Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000NHQlUIAX"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2018-07-23T02:40:48Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2018-07-23T02:40:47Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해주셔서 감사합니다.<br><br>레드햇 신재욱 차장이라고 하며 앞으로 해당 케이스를 담당하게 되었습니다.<br><br>현재 케이스 내용을 살펴보는 중이며, 관련하여 업데이트 드리도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2018-07-23T02:40:47Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br>덕분에 작업은 잘 마무리 되었습니다. <br><br>작업후 페일오버 테스트를 진행하였는데요.<br>서비스망 절체 핫빗망절체 fence_node등 정상적으로 페일오버가 되었습니다.<br>그런데 <br>SAN스위치 FC포트 절체시에는 정상적으로 페일오버가 되지 않아 문의드립니다.<br>FC포트 절체는 1호기쪽으로 하였습니다.<br><br>&lt;FLPTRSD01&gt; 의 로그 <br>샌스위치의 포트를 제거 후 아래와 같은 로그가 발생<br><br>Jul 22 10:52:21 FLPTRSD01 qdiskd[5932]: qdiskd: read (system call) has hung for 15 seconds<br>Jul 22 10:52:21 FLPTRSD01 qdiskd[5932]: In 15 more seconds, we will be evicted<br>Jul 22 10:52:49 FLPTRSD01 multipathd: 8:0: mark as failed<br>Jul 22 10:52:49 FLPTRSD01 multipathd: ext0: remaining active paths: 1<br>Jul 22 10:52:49 FLPTRSD01 multipathd: 8:240: mark as failed<br>Jul 22 10:52:49 FLPTRSD01 multipathd: qdisk: remaining active paths: 1<br>Jul 22 10:52:49 FLPTRSD01 kernel: rport-0:0-0: blocked FC remote port time out: removing target and saving binding<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: device-mapper: multipath: Failing path 8:0.<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:0: rejecting I/O to offline device<br>Jul 22 10:52:49 FLPTRSD01 kernel: sd 0:0:0:7: rejecting I/O to offline device<br>...이하 생략<br><br>&lt;FLPTRSD02&gt;의로그<br>동일하게 장애 감지<br>Jul 22 10:58:10 FLPTRSD02 qdiskd[2120]: qdiskd on node 1 reports hung read()<br>Jul 22 10:58:18 FLPTRSD02 rgmanager[4547]: [script] Executing /etc/cluster/init.orajsa status<br>Jul 22 10:58:25 FLPTRSD02 qdiskd[2120]: qdiskd on node 1 reports hung read()<br>Jul 22 10:58:48 FLPTRSD02 rgmanager[6648]: [script] Executing /etc/cluster/init.orajsa status<br>Jul 22 10:58:55 FLPTRSD02 qdiskd[2120]: Writing eviction notice for node 1<br>Jul 22 10:58:58 FLPTRSD02 qdiskd[2120]: Node 1 evicted<br>..이하생략<br>Jul 22 11:00:17 FLPTRSD02 rgmanager[7267]: start on ip &quot;100.254.40.167&quot; returned 1 (generic error)<br>Jul 22 11:00:17 FLPTRSD02 rgmanager[7267]: #68: Failed to start service:svc_TRSD; return value: 1<br>Jul 22 11:00:17 FLPTRSD02 rgmanager[7267]: Stopping service service:svc_TRSD<br>Jul 22 11:00:17 FLPTRSD02 rgmanager[11241]: [script] Executing /etc/cluster/init.oracle stop<br>Jul 22 11:00:40 FLPTRSD02 rgmanager[14342]: [fs] unmounting /oracle12<br>Jul 22 11:00:40 FLPTRSD02 rgmanager[14574]: [fs] unmounting /oradata_PCDTS<br>Jul 22 11:00:40 FLPTRSD02 rgmanager[14809]: [fs] unmounting /orasys_PCDTS<br>Jul 22 11:00:40 FLPTRSD02 rgmanager[15029]: [fs] unmounting /oraarch_PCDTS<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[15244]: [fs] unmounting /dbadmin<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[15452]: [fs] unmounting /oracle_arch<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[15654]: [fs] unmounting /oracle<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[7267]: Service service:svc_TRSD is recovering<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[7267]: #71: Relocating failed service service:svc_TRSD<br>Jul 22 11:00:41 FLPTRSD02 rgmanager[7267]: Service service:svc_TRSD is stopped<br><br>아이피 충돌(?)로 인해서 서비스 IP를 계속 가지오지 못하는 것으로 보입니다.<br><br><br>작업 중에도 보면<br>FLPTRSD02 에서 recoverable 시도하는 모습이 보이는데 시도하다가 fail로 변경된 후 정상적으로 서비스가 페일오버 되지 않았습니다.<br><br>어떠한 값을 변경해야 할까요??<br>동일한 작업이 금주 주말에 다른 장비에서 있어서 답변을 주시면 적용 후 동일하게 페일오버 테스트를 진행해볼까 합니다.<br><br>감사합니다.<br><br>============================================================================<br>* 고객 정보 (필수) - 실제 레드햇 서브스크립션을 소유하고 시스템에 사용 중인 엔드 유저<br>- 성함(직급) : 송기용 (책임)<br>- 회사명(부서명) : 삼성SDS<br>- 전화번호 :  82-10-9006-9506 <br>- 메일주소 : 송기용 &lt;kyyong.song@samsung.com&gt;<br><br>* 파트너 정보 (옵션) - 실제 고객의 시스템을 유지보수하는 업체<br>- 성함(직급) : 송기호(책임)<br>- 회사명(부서명) : 타임게이트(오픈소스팀)<br>- 전화번호 : 01036209917<br>- 메일주소 : kh.song@time-gate.com<br>==============================================================================</issue><environment>RHCS, 쿼럼 휴리스틱, 각각의서비스가 1호기active 2호기 active, oracle</environment><periodicityOfIssue>물리적인 SAN 스위치 포트제거시</periodicityOfIssue><timeFramesAndUrgency>운영서버로 중요도가 높습니다.</timeFramesAndUrgency><cep>false</cep></case>