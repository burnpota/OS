======================<br><b>생성계정 : 타임게이트 타임게이트</b><br><b>생성날짜 : 2018-01-09T07:03:30Z</b><br><b>마지막 답변자 : 타임게이트 타임게이트</b><br><b>마지막 수정 일자 : 2018-01-23T00:29:40Z</b><br><b>id : 500A000000ZQ37cIAD</b><br>======================<br><br><b><font size=15>
제목  : pacemaker 에서 pcs resource cleanup 명령 의 시스템 영향도
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요. <br>예전 고객사에서 pacemaker 관련 발생한 이슈에 대한 문의 올립니다.<br><br> - &quot;pcs status&quot; 상에서 error 메시지가 출력되어 있음<br> - 각 resource 정상적으로 구동되고 있음<br><br>위 상황에서 error messasges 를 출력시키지 않고자 &quot;pcs resource cleanup&quot; 커맨드를 수행했더니 각 resource 가 restart 된 사례가 있었습니다.<br>======================<br><br><br><br>자체적으로 상황을 재현하고자 테스트를 진행하였으며, 내용은 아래와 같습니다.<br><br><br>1. node1에서 장애를 발생시켜 error message 를 발생시킴. failcount 는 초기화<br> <br> Resource Group: grp<br>     VIP        (ocf::heartbeat:IPaddr2):<br>Started node2-hb<br>     VG (ocf::heartbeat:LVM):   Started node2-hb<br>     FS (ocf::heartbeat:Filesystem):    Started node2-hb<br>     NTP        (lsb:ntp.sh):   Started node2-hb<br>scsi    (stonith:fence_scsi):   Started node1-hb<br><br>Migration Summary:<br>* Node node2-hb:<br>* Node node1-hb:<br>   VG: migration-threshold=1 fail-count=1000000<br>last-failure='Tue Jan  9 14:06:31 2018'<br><br>Failed Actions:<br>* VG_start_0 on node1-hb 'unknown error' (1): call=60, status=complete, exitreason='The volume_list filter must be initialized in lv<br>m.conf for exclusive activation without clvmd',<br>    last-rc-change='Tue Jan  9 14:06:30 2018', queued=0ms, exec=407ms<br>======================<br><br>======================<br>2. 위 상황에서 pcs resource cleanup 명령어 수행 결과<br><br>  2-1. log messages<br>Jan  9 15:17:45 node2 crmd[1405]:  notice: Forcing the status of all resources to be redetected<br>Jan  9 15:17:45 node2 crmd[1405]:  notice: State transition S_IDLE -&gt; S_POLICY_ENGINE<br>Jan  9 15:17:46 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   VIP#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   VG#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   FS#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   NTP#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   scsi#011(node2-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Calculated transition 48, saving inputs in /var/lib/pacemaker/pengine/pe-input-88.bz2<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Configuration ERRORs found during PE processing.  Please run &quot;crm_verify -L&quot; to identify issues.<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VIP_monitor_0 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VIP_monitor_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VG_monitor_0 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VG_monitor_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Requesting fencing (on) of node node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Requesting fencing (on) of node node1-hb<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Client crmd.1405.c17d8461 wants to fence (on) 'node2-hb' with device '(any)'<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Requesting peer fencing (on) of node2-hb<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Client crmd.1405.c17d8461 wants to fence (on) 'node1-hb' with device '(any)'<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Requesting peer fencing (on) of node1-hb<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: scsi can fence (on) node2-hb: static-list<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: scsi can fence (on) node2-hb: static-list<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Result of probe operation for VIP on node2-hb: 0 (ok)<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 8 (VIP_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Transition aborted by operation VIP_monitor_0 'create' on node2-hb: Event failed<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 8 (VIP_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:46 node2 stonith-ng[1401]: warning: fence_scsi[32591] stderr: [ WARNING:root:Parse error: Ignoring unknown option 'port=node2-hb' ]<br>Jan  9 15:17:46 node2 stonith-ng[1401]: warning: fence_scsi[32591] stderr: [  ]<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Operation 'on' [32591] (call 12 from crmd.1405) for host 'node2-hb' with device 'scsi' returned: 0 (OK)<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Operation on of node2-hb by node2-hb for crmd.1405@node2-hb.9e9d6dbf: OK<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Stonith operation 12/13:48:0:d594819f-6a54-42ff-a64e-bacf4c1acf96: OK (0)<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: node2-hb was successfully unfenced by node2-hb (at the request of node2-hb)<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation scsi_monitor_0 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Result of probe operation for scsi on node2-hb: 7 (not running)<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Operation on of node1-hb by node1-hb for crmd.1405@node2-hb.b6bb778c: OK<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Stonith operation 13/7:48:0:d594819f-6a54-42ff-a64e-bacf4c1acf96: OK (0)<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: node1-hb was successfully unfenced by node1-hb (at the request of node2-hb)<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation scsi_monitor_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Result of probe operation for VG on node2-hb: 0 (ok)<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 9 (VG_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 9 (VG_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Transition 48 (Complete=9, Pending=0, Fired=0, Skipped=5, Incomplete=15, Source=/var/lib/pacemaker/pengine/pe-input-88.bz2): Stopped<br><br>Jan  9 15:17:46 node2 pengine[1404]:  notice: On loss of CCM Quorum: Ignore<br>Jan  9 15:17:46 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   FS#011(node2-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   NTP#011(node2-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   scsi#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Calculated transition 49, saving inputs in /var/lib/pacemaker/pengine/pe-input-89.bz2<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Configuration ERRORs found during PE processing.  Please run &quot;crm_verify -L&quot; to identify issues.<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VIP_monitor_30000 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VG_monitor_10000 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation FS_monitor_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation NTP_monitor_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating start operation scsi_start_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation FS_monitor_0 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Result of probe operation for FS on node2-hb: 0 (ok)<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 4 (FS_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Transition aborted by operation FS_monitor_0 'create' on node2-hb: Event failed<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 4 (FS_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Transition 49 (Complete=7, Pending=0, Fired=0, Skipped=2, Incomplete=7, Source=/var/lib/pacemaker/pengine/pe-input-89.bz2): Stopped<br><br>Jan  9 15:17:47 node2 pengine[1404]:  notice: On loss of CCM Quorum: Ignore<br>Jan  9 15:17:47 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:47 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:47 node2 pengine[1404]:  notice: Start   NTP#011(node2-hb)<br>Jan  9 15:17:47 node2 pengine[1404]:  notice: Calculated transition 50, saving inputs in /var/lib/pacemaker/pengine/pe-input-90.bz2<br>Jan  9 15:17:47 node2 pengine[1404]:  notice: Configuration ERRORs found during PE processing.  Please run &quot;crm_verify -L&quot; to identify issues.<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Initiating monitor operation FS_monitor_20000 locally on node2-hb<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Initiating monitor operation NTP_monitor_0 locally on node2-hb<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Initiating monitor operation scsi_monitor_60000 on node1-hb<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Result of probe operation for NTP on node2-hb: 0 (ok)<br>Jan  9 15:17:47 node2 crmd[1405]: warning: Action 4 (NTP_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Transition aborted by operation NTP_monitor_0 'create' on node2-hb: Event failed<br>Jan  9 15:17:47 node2 crmd[1405]: warning: Action 4 (NTP_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Transition 50 (Complete=4, Pending=0, Fired=0, Skipped=0, Incomplete=3, Source=/var/lib/pacemaker/pengine/pe-input-90.bz2): Complete<br><br>Jan  9 15:17:47 node2 pengine[1404]:  notice: On loss of CCM Quorum: Ignore<br>Jan  9 15:17:47 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:47 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:47 node2 pengine[1404]:  notice: Calculated transition 51, saving inputs in /var/lib/pacemaker/pengine/pe-input-91.bz2<br>Jan  9 15:17:47 node2 pengine[1404]:  notice: Configuration ERRORs found during PE processing.  Please run &quot;crm_verify -L&quot; to identify issues.<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Initiating monitor operation NTP_monitor_30000 locally on node2-hb<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Transition 51 (Complete=1, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-91.bz2): Complete<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: State transition S_TRANSITION_ENGINE -&gt; S_IDLE<br>======================<br><br>======================<br><br>2-2. ntp resource status<br><br>############ cleanup 수행 전 ############<br>[root@node2 init.d]# systemctl status ntpd<br>● ntpd.service - Network Time Service<br>   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled)<br>   Active: active (running) since Tue 2018-01-09 15:15:46 KST; 47s ago<br>  Process: 31185 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS)<br> Main PID: 31188 (ntpd)<br>   CGroup: /system.slice/ntpd.service<br>           └─31188 /usr/sbin/ntpd -u ntp:ntp -g<br><br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 3 eth0 10.10.10.103 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 4 eth0 10.10.10.100 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 5 eth1 10.10.10.105 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 6 lo ::1 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 7 eth1 fe80::215:5dff:fe38:114 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 8 eth0 fe80::215:5dff:fe38:113 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listening on routing socket on fd #25 for interface updates<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c016 06 restart<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c012 02 freq_set kernel 0.000 PPM<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c011 01 freq_not_set<br>======================<br>############ cleanup 수행 후 ############<br>[root@node2 init.d]# systemctl status ntpd<br>● ntpd.service - Network Time Service<br>   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled)<br>   Active: active (running) since Tue 2018-01-09 15:15:46 KST; 2min 11s ago<br>  Process: 31185 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS)<br> Main PID: 31188 (ntpd)<br>   CGroup: /system.slice/ntpd.service<br>           └─31188 /usr/sbin/ntpd -u ntp:ntp -g<br><br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 3 eth0 10.10.10.103 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 4 eth0 10.10.10.100 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 5 eth1 10.10.10.105 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 6 lo ::1 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 7 eth1 fe80::215:5dff:fe38:114 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 8 eth0 fe80::215:5dff:fe38:113 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listening on routing socket on fd #25 for interface updates<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c016 06 restart<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c012 02 freq_set kernel 0.000 PPM<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c011 01 freq_not_set<br> <br><br><br>2-3. watch 로 마운트 상태 및 ntp process 상태를 지켜봤으나(0.1초 단위), 각 resource 가 계속 유지되어있음.<br>======================<br>제가 테스트 한 방법이 맞는지는 모르겠으나, 위 결과대로라면 resource 가 restart 된 흔적은 찾을 수 없었습니다.<br>======================<br>&lt;1&gt; 모든 resource가 정상적으로 started 된 상태에서도 cleanup 명령어 수행으로 인해 resource restart 될 가능성이 있는지요?<br><br>&lt;2&gt; cleanup 명령 수행 시 아래 메시지가 확인되었는데, 각 resource 의 start 의미가 무엇인지요? <br><br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   VIP#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   VG#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   FS#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   NTP#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   scsi#011(node2-hb)<br><br>&lt;3&gt; pcs status 에 error messages 를 지우고 싶다면(현재 모든 node 및 resource 는 정상이라는 가정), &quot;pcs resource cleanup&quot; 명령이 권고되는 사항인가요?<br>    혹은, &quot;pcs resource cleanup&quot; 명령 자체가 운영 서버에서 하지 말아야할 작업인가요?<br>======================<br>확인 부탁드립니다.<br><br>감사합니다.<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>고객사에서 발생한 이슈는 RHEL7.2,   테스트 장비는 7.4입니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.4</b><br><b>타입  : Defect / Bug</b><br><b>계정 번호  : 1648604</b><br><b>심각도  : 4 (Low)</b><br>======================<br><comment id="a0aA000000LMXZjIAP"><br>======================<br><b>생성계정 : Park, HyunYick</b><br><b>생성날짜 : 2018-01-15T01:14:47Z</b><br><b>마지막 답변자 : Park, HyunYick</b><br><b>마지막 수정 일자 : 2018-01-15T01:46:32Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>Q1) 전달주신 solution 은 storage 기반의 fenceing device(=fence_scsi) 에  대한 이슈로 보이는데,<br>fence_ipmilan 이 구성된 pacemaker에서도  &quot;# pcs resouce cleanup {RESOURCE_ID} &quot; 명령이 권고되는 사항 인것인가요?<br><br>A1) &quot;pcs resource cleanup {RESOURCE ID}&quot; 명령어를 말씀드렸던 것은 fence_scsi 장치 사용시 resource 재시작 이슈 때문에 안내하여 드린 부분이며,<br>fence_ipmilan 장치 사용시에도 반드시 상기 명령어를 사용해야하는 것은 아닙니다.<br>기본적으로 fence_ipmilan과 같이 unfencing을 제공하지 않는 장치에서는 pcs resource cleanup을 경우에는 resource가 재시작 되지 않을 것입니다.<br>만약 테스트 환경에서 재현이 가능하시면 재현 이후 sosreport와 /var/log 디렉토리를 업로드 부탁드립니다.<br><br><br>Q2) 첫 문의에서 말씀드렸듯이, pcs status 및 log messages 에서는 resource 가 restart된것처럼 보이지만, 실제 프로세스 및 daemon 상태를 확인했을 때는 서비스가 유지되는것을 확인했습니다. <br>fence_ipmilan  과 fence_scsi  각각 구성된 서버에서,  정상상태일 때  &quot;pcs resource cleanup&quot; 명령의 수행 결과가 resource 에 어떠한 영향을 끼치는지 확인 부탁드리겠습니다.<br><br>A2) resource가 정상적으로 시작된 상태이며, status가 정상이라면 pcs resource cleanup시에 resource가 재시작 동작은 발생하지 않을 것입니다.<br>resource cleanup을 하게 되면 resource의 상태, fail-count, resource의 동작 history를 제거하고 resource를 재발견(redetect)하게 됩니다.<br>말씀하신 restart 된 것처럼 보이는 현상이 pcs status에서 관찰된다면, resource reprobe 하는 동안 일시적으로 재시작 동작을 한것처럼 보일 수 있습니다.<br>하지만 만약 restart 기록이 log messages에 남는다면 그것은 실제로 restart 되었을 것 입니다.<br><br>감사합니다.<br><br><publishedDate>2018-01-15T01:14:47Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000LLs6MIAT"><br>======================<br><b>생성계정 : Park, HyunYick</b><br><b>생성날짜 : 2018-01-11T01:34:25Z</b><br><b>마지막 답변자 : Park, HyunYick</b><br><b>마지막 수정 일자 : 2018-01-11T01:50:37Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>문의하신 내용에 대한 답변입니다.<br><br>Q1) 모든 resource가 정상적으로 started 된 상태에서도 cleanup 명령어 수행으로 인해 resource restart 될 가능성이 있는지요?<br><br>A1) pcs resource cleanup을 하게 되면 모든 resource의 reprobe를 발생시켜 resource history를 제거하고, resource 상태를 재 발견합니다. 여기까지는 문제될만한 동작이 없는 부분입니다.<br>하지만 해당 클러스터에는 fence_scsi agent를 사용중이며, fence_scsi resource는 cleanup 시에 unfencing 작업을 하도록 되어있습니다.<br>unfencing이 동작하면 모든 resource가 stop되도록 되어있습니다. 그 이유로 인하여 resource cleanup 시에 모든 resource가 재시작 되었을 것입니다.<br>이것은 원치 않는 동작이며, bug zilla에 등록되어 다음 릴리즈에 반영될 예정입니다.<br>unfencing에 대해서 설명드리면 fence_scsi 장치를 통하여 fenced 된 문제의 노드가 리부팅 되서 다시 클러스터 멤버로 합류할때에 fenced 되었던 것을 다시 unfencing 하여 공유 스토리지에 접근할 수 있도록 하는 동작입니다.<br><br><br>Q2) cleanup 명령 수행 시 아래 메시지가 확인되었는데, 각 resource 의 start 의미가 무엇인지요? <br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   VIP#011(node1-hb)<br><br>A2) 상기 로그로 예를 들면 VIP 리소스가 node1-hb에서 시작되고 있다는 의미입니다.<br><br><br>Q3) pcs status 에 error messages 를 지우고 싶다면(현재 모든 node 및 resource 는 정상이라는 가정), &quot;pcs resource cleanup&quot; 명령이 권고되는 사항인가요? 혹은, &quot;pcs resource cleanup&quot; 명령 자체가 운영 서버에서 하지 말아야할 작업인가요?<br><br>A3) 현재 해당 이슈는 bugzilla에 등록되어 릴리즈 준비중입니다. 운영환경에서는 pcs resource cleanup 보다는 아래와 같은 Workaround를 통하여 진행하시기 바랍니다. <br><br>Workaround 1 : stonith resource는 cleanup하지 마시고 각 각의 resource를 지정하여 cleanup하시기 바랍니다.<br><br># pcs resource cleanup myResource<br><br>Workaround 2 : 만약 문제가 있었던 stonith resource가 문제가 해결되었고 pcs status에 fail-count가 남아 있거나 blocked 된 상태라면 아래와 같이 failcount를 reset하시기 바랍니다.<br><br># pcs resource failcount reset &lt;stonith resource&gt;<br><br>관련하여 추가 정보는 아래의 KCS를 참조하시기 바랍니다.<br><br>&quot;All resources restart after executing 'pcs resource cleanup' in a cluster with a stonith device that provides unfencing in a RHEL 6 or 7 High Availability cluster with pacemaker&quot;<br>https://access.redhat.com/solutions/2949821<br><br>감사합니다.<br><br><publishedDate>2018-01-11T01:34:24Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000LLs4aIAD"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2018-01-11T01:31:06Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2018-01-11T01:31:06Z</b><br><br>답변 감사합니다.<br><br>테스트 한 서버는 fence_scsi 구성된것이 맞지만,<br>실제 resource 가 restart 되어 이슈가 발생한 서버는 fencing device가 fence_ipmilan 이었습니다.<br><br>1. <br>전달주신 solution 은 storage 기반의 fenceing device(=fence_scsi) 에  대한 이슈로 보이는데,<br>fence_ipmilan 이 구성된 pacemaker에서도  &quot;# pcs resouce cleanup {RESOURCE_ID} &quot; 명령이 권고되는 사항 인것인가요?<br><br>2. <br>첫 문의에서 말씀드렸듯이, pcs status 및 log messages 에서는 resource 가 restart된것처럼 보이지만, 실제 프로세스 및 daemon 상태를 확인했을 때는 서비스가 유지되는것을 확인했습니다. <br>fence_ipmilan  과 fence_scsi  각각 구성된 서버에서,  정상상태일 때  &quot;pcs resource cleanup&quot; 명령의 수행 결과가 resource 에 어떠한 영향을 끼치는지 확인 부탁드리겠습니다.<br><br><br>확인 부탁드립니다.<br><br>감사합니다.<br><br><publishedDate>2018-01-11T01:31:06Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000LLjdhIAD"><br>======================<br><b>생성계정 : Bradley, Shane</b><br><b>생성날짜 : 2018-01-10T15:39:27Z</b><br><b>마지막 답변자 : Bradley, Shane</b><br><b>마지막 수정 일자 : 2018-01-10T15:39:27Z</b><br><br>They are hitting the following issue as they are using fence_scsi which includes unfencing:<br>  - All resources restart after executing 'pcs resource cleanup' in a cluster with a stonith device <br>    that provides unfencing in a RHEL 6 or 7 High Availability cluster with pacemaker <br>    https://access.redhat.com/solutions/2949821<br><br>  - Bug 1427648 – resource cleanup results in resource restarts with unfencing <br>    https://bugzilla.redhat.com/show_bug.cgi?id=1427648 (The bugzilla is private so most comments are not displayed.)<br><br><publishedDate>2018-01-10T15:39:27Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000LLbFlIAL"><br>======================<br><b>생성계정 : Park, HyunYick</b><br><b>생성날짜 : 2018-01-10T06:32:25Z</b><br><b>마지막 답변자 : Park, HyunYick</b><br><b>마지막 수정 일자 : 2018-01-10T06:32:25Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해 주셔서 감사합니다.<br><br>해당 케이스에 대하여 확인중에 있습니다.<br>확인 후 업데이트 드리겠습니다.<br><br>감사합니다.<br><br><publishedDate>2018-01-10T06:32:25Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br>예전 고객사에서 pacemaker 관련 발생한 이슈에 대한 문의 올립니다.<br><br> - &quot;pcs status&quot; 상에서 error 메시지가 출력되어 있음<br> - 각 resource 정상적으로 구동되고 있음<br><br>위 상황에서 error messasges 를 출력시키지 않고자 &quot;pcs resource cleanup&quot; 커맨드를 수행했더니 각 resource 가 restart 된 사례가 있었습니다.<br>======================<br><br><br><br>자체적으로 상황을 재현하고자 테스트를 진행하였으며, 내용은 아래와 같습니다.<br><br><br>1. node1에서 장애를 발생시켜 error message 를 발생시킴. failcount 는 초기화<br> <br> Resource Group: grp<br>     VIP        (ocf::heartbeat:IPaddr2):<br>Started node2-hb<br>     VG (ocf::heartbeat:LVM):   Started node2-hb<br>     FS (ocf::heartbeat:Filesystem):    Started node2-hb<br>     NTP        (lsb:ntp.sh):   Started node2-hb<br>scsi    (stonith:fence_scsi):   Started node1-hb<br><br>Migration Summary:<br>* Node node2-hb:<br>* Node node1-hb:<br>   VG: migration-threshold=1 fail-count=1000000<br>last-failure='Tue Jan  9 14:06:31 2018'<br><br>Failed Actions:<br>* VG_start_0 on node1-hb 'unknown error' (1): call=60, status=complete, exitreason='The volume_list filter must be initialized in lv<br>m.conf for exclusive activation without clvmd',<br>    last-rc-change='Tue Jan  9 14:06:30 2018', queued=0ms, exec=407ms<br>======================<br><br>======================<br>2. 위 상황에서 pcs resource cleanup 명령어 수행 결과<br><br>  2-1. log messages<br>Jan  9 15:17:45 node2 crmd[1405]:  notice: Forcing the status of all resources to be redetected<br>Jan  9 15:17:45 node2 crmd[1405]:  notice: State transition S_IDLE -&gt; S_POLICY_ENGINE<br>Jan  9 15:17:46 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   VIP#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   VG#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   FS#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   NTP#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   scsi#011(node2-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Calculated transition 48, saving inputs in /var/lib/pacemaker/pengine/pe-input-88.bz2<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Configuration ERRORs found during PE processing.  Please run &quot;crm_verify -L&quot; to identify issues.<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VIP_monitor_0 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VIP_monitor_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VG_monitor_0 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VG_monitor_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Requesting fencing (on) of node node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Requesting fencing (on) of node node1-hb<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Client crmd.1405.c17d8461 wants to fence (on) 'node2-hb' with device '(any)'<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Requesting peer fencing (on) of node2-hb<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Client crmd.1405.c17d8461 wants to fence (on) 'node1-hb' with device '(any)'<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Requesting peer fencing (on) of node1-hb<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: scsi can fence (on) node2-hb: static-list<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: scsi can fence (on) node2-hb: static-list<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Result of probe operation for VIP on node2-hb: 0 (ok)<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 8 (VIP_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Transition aborted by operation VIP_monitor_0 'create' on node2-hb: Event failed<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 8 (VIP_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:46 node2 stonith-ng[1401]: warning: fence_scsi[32591] stderr: [ WARNING:root:Parse error: Ignoring unknown option 'port=node2-hb' ]<br>Jan  9 15:17:46 node2 stonith-ng[1401]: warning: fence_scsi[32591] stderr: [  ]<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Operation 'on' [32591] (call 12 from crmd.1405) for host 'node2-hb' with device 'scsi' returned: 0 (OK)<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Operation on of node2-hb by node2-hb for crmd.1405@node2-hb.9e9d6dbf: OK<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Stonith operation 12/13:48:0:d594819f-6a54-42ff-a64e-bacf4c1acf96: OK (0)<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: node2-hb was successfully unfenced by node2-hb (at the request of node2-hb)<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation scsi_monitor_0 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Result of probe operation for scsi on node2-hb: 7 (not running)<br>Jan  9 15:17:46 node2 stonith-ng[1401]:  notice: Operation on of node1-hb by node1-hb for crmd.1405@node2-hb.b6bb778c: OK<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Stonith operation 13/7:48:0:d594819f-6a54-42ff-a64e-bacf4c1acf96: OK (0)<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: node1-hb was successfully unfenced by node1-hb (at the request of node2-hb)<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation scsi_monitor_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Result of probe operation for VG on node2-hb: 0 (ok)<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 9 (VG_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 9 (VG_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Transition 48 (Complete=9, Pending=0, Fired=0, Skipped=5, Incomplete=15, Source=/var/lib/pacemaker/pengine/pe-input-88.bz2): Stopped<br><br>Jan  9 15:17:46 node2 pengine[1404]:  notice: On loss of CCM Quorum: Ignore<br>Jan  9 15:17:46 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   FS#011(node2-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   NTP#011(node2-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   scsi#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Calculated transition 49, saving inputs in /var/lib/pacemaker/pengine/pe-input-89.bz2<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Configuration ERRORs found during PE processing.  Please run &quot;crm_verify -L&quot; to identify issues.<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VIP_monitor_30000 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation VG_monitor_10000 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation FS_monitor_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation NTP_monitor_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating start operation scsi_start_0 on node1-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Initiating monitor operation FS_monitor_0 locally on node2-hb<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Result of probe operation for FS on node2-hb: 0 (ok)<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 4 (FS_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:46 node2 crmd[1405]:  notice: Transition aborted by operation FS_monitor_0 'create' on node2-hb: Event failed<br>Jan  9 15:17:46 node2 crmd[1405]: warning: Action 4 (FS_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Transition 49 (Complete=7, Pending=0, Fired=0, Skipped=2, Incomplete=7, Source=/var/lib/pacemaker/pengine/pe-input-89.bz2): Stopped<br><br>Jan  9 15:17:47 node2 pengine[1404]:  notice: On loss of CCM Quorum: Ignore<br>Jan  9 15:17:47 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:47 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:47 node2 pengine[1404]:  notice: Start   NTP#011(node2-hb)<br>Jan  9 15:17:47 node2 pengine[1404]:  notice: Calculated transition 50, saving inputs in /var/lib/pacemaker/pengine/pe-input-90.bz2<br>Jan  9 15:17:47 node2 pengine[1404]:  notice: Configuration ERRORs found during PE processing.  Please run &quot;crm_verify -L&quot; to identify issues.<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Initiating monitor operation FS_monitor_20000 locally on node2-hb<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Initiating monitor operation NTP_monitor_0 locally on node2-hb<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Initiating monitor operation scsi_monitor_60000 on node1-hb<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Result of probe operation for NTP on node2-hb: 0 (ok)<br>Jan  9 15:17:47 node2 crmd[1405]: warning: Action 4 (NTP_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Transition aborted by operation NTP_monitor_0 'create' on node2-hb: Event failed<br>Jan  9 15:17:47 node2 crmd[1405]: warning: Action 4 (NTP_monitor_0) on node2-hb failed (target: 7 vs. rc: 0): Error<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Transition 50 (Complete=4, Pending=0, Fired=0, Skipped=0, Incomplete=3, Source=/var/lib/pacemaker/pengine/pe-input-90.bz2): Complete<br><br>Jan  9 15:17:47 node2 pengine[1404]:  notice: On loss of CCM Quorum: Ignore<br>Jan  9 15:17:47 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:47 node2 pengine[1404]:   error: Specifying on_fail=fence and stonith-enabled=false makes no sense<br>Jan  9 15:17:47 node2 pengine[1404]:  notice: Calculated transition 51, saving inputs in /var/lib/pacemaker/pengine/pe-input-91.bz2<br>Jan  9 15:17:47 node2 pengine[1404]:  notice: Configuration ERRORs found during PE processing.  Please run &quot;crm_verify -L&quot; to identify issues.<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Initiating monitor operation NTP_monitor_30000 locally on node2-hb<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: Transition 51 (Complete=1, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-91.bz2): Complete<br>Jan  9 15:17:47 node2 crmd[1405]:  notice: State transition S_TRANSITION_ENGINE -&gt; S_IDLE<br>======================<br><br>======================<br><br>2-2. ntp resource status<br><br>############ cleanup 수행 전 ############<br>[root@node2 init.d]# systemctl status ntpd<br>● ntpd.service - Network Time Service<br>   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled)<br>   Active: active (running) since Tue 2018-01-09 15:15:46 KST; 47s ago<br>  Process: 31185 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS)<br> Main PID: 31188 (ntpd)<br>   CGroup: /system.slice/ntpd.service<br>           └─31188 /usr/sbin/ntpd -u ntp:ntp -g<br><br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 3 eth0 10.10.10.103 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 4 eth0 10.10.10.100 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 5 eth1 10.10.10.105 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 6 lo ::1 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 7 eth1 fe80::215:5dff:fe38:114 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 8 eth0 fe80::215:5dff:fe38:113 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listening on routing socket on fd #25 for interface updates<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c016 06 restart<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c012 02 freq_set kernel 0.000 PPM<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c011 01 freq_not_set<br>======================<br>############ cleanup 수행 후 ############<br>[root@node2 init.d]# systemctl status ntpd<br>● ntpd.service - Network Time Service<br>   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled)<br>   Active: active (running) since Tue 2018-01-09 15:15:46 KST; 2min 11s ago<br>  Process: 31185 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS)<br> Main PID: 31188 (ntpd)<br>   CGroup: /system.slice/ntpd.service<br>           └─31188 /usr/sbin/ntpd -u ntp:ntp -g<br><br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 3 eth0 10.10.10.103 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 4 eth0 10.10.10.100 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 5 eth1 10.10.10.105 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 6 lo ::1 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 7 eth1 fe80::215:5dff:fe38:114 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listen normally on 8 eth0 fe80::215:5dff:fe38:113 UDP 123<br>Jan 09 15:15:46 node2 ntpd[31188]: Listening on routing socket on fd #25 for interface updates<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c016 06 restart<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c012 02 freq_set kernel 0.000 PPM<br>Jan 09 15:15:46 node2 ntpd[31188]: 0.0.0.0 c011 01 freq_not_set<br> <br><br><br>2-3. watch 로 마운트 상태 및 ntp process 상태를 지켜봤으나(0.1초 단위), 각 resource 가 계속 유지되어있음.<br>======================<br>제가 테스트 한 방법이 맞는지는 모르겠으나, 위 결과대로라면 resource 가 restart 된 흔적은 찾을 수 없었습니다.<br>======================<br>&lt;1&gt; 모든 resource가 정상적으로 started 된 상태에서도 cleanup 명령어 수행으로 인해 resource restart 될 가능성이 있는지요?<br><br>&lt;2&gt; cleanup 명령 수행 시 아래 메시지가 확인되었는데, 각 resource 의 start 의미가 무엇인지요? <br><br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   VIP#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   VG#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   FS#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   NTP#011(node1-hb)<br>Jan  9 15:17:46 node2 pengine[1404]:  notice: Start   scsi#011(node2-hb)<br><br>&lt;3&gt; pcs status 에 error messages 를 지우고 싶다면(현재 모든 node 및 resource 는 정상이라는 가정), &quot;pcs resource cleanup&quot; 명령이 권고되는 사항인가요?<br>    혹은, &quot;pcs resource cleanup&quot; 명령 자체가 운영 서버에서 하지 말아야할 작업인가요?<br>======================<br>확인 부탁드립니다.<br><br>감사합니다.</issue><environment>고객사에서 발생한 이슈는 RHEL7.2,   테스트 장비는 7.4입니다.</environment><cep>false</cep></case>