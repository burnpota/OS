======================<br><b>생성계정 : 타임게이트 타임게이트</b><br><b>생성날짜 : 2017-10-06T01:06:59Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2017-11-03T10:03:28Z</b><br><b>id : 500A000000YSLD7IAP</b><br>======================<br><br><b><font size=15>
제목  : NTP 동기화 시 PPM exceeds tolerance 500 PPM 이슈의 건
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요. <br><br>얼마 전 발생했던 Oracle ASM 리부팅 이슈 (https://access.redhat.com/support/cases/#/case/01942924) 에서 발견되었던 내용입니다.<br><br>해당 시스템들은 ntpdate 를 동기화를 하고 hwclock 을 설정해도 바로 jitter 가 벌어지는 문제가 있었습니다.<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>공교롭게도 이번에 발생했던 oracle 클러스터 노드가 모두 NTP 가 벌어지는 현상이 있었습니다.<br><br>확인을 해 보니 /var/log/messages 에 NTP 관련 에러가 상당히 많이 나오고 있습니다.<br><br>&quot; ntpd[3285]: frequency error -15113 PPM exceeds tolerance 500 PPM &quot;<br><br>ntpq 를 통해 peers 를 확인 해 보니, 2개의 NTP Server 중 한개 노드는 게속해서 x 로 나오면서 동기화가 안되고 있으며,<br><br>문제가 되는 NTP Server 를 제거 후 한개만 이용하여 동기화를 해 보니, 1~2 일 정도 지나서 정상적으로 동기화가 되고 있습니다.<br><br>2개의 NTP 서버를 구성했을 당시에는 ntpdate 로 수동으로 sync 후에 hwclock 고 맞춰준 후 ntpd 를 실행해도 offset  이 기본 300 이상 벌어지면서 문제가 있었습니다.<br><br>언제 문제가 발생했습니까? 이러한 문제가 자주 발생합니까? 반복적으로 발생합니까? 특정 시간에 발생합니까?<br><br>현재 추가적으로 확인 된 사항은 Dell iDRAC8 의 NTP 설정이 빠져 있어, 하드웨어 시간도 동기화를 할 예정인데요,<br><br>혹시 이렇게 iDRAC8 의 NTP 설정 후 다시 O/S 의 NTP 서버를 2개로 설정했을 때, 동일한 문제가 발생한다면,<br><br>물리적인 메인보드 또는 CPU 교체를 고려해야 하는지 여부를 확인 부탁 드립니다.<br><br>감사합니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>타입  : Defect / Bug</b><br><b>계정 번호  : 1648604</b><br><b>심각도  : 4 (Low)</b><br><hostname>SLPCSSDL01SL, SLPAFID02SL</hostname><br><br><br><comment id="a0aA000000KhqmMIAR"><br>======================<br><b>생성계정 : Song, Chang-An</b><br><b>생성날짜 : 2017-10-18T05:07:35Z</b><br><b>마지막 답변자 : Song, Chang-An</b><br><b>마지막 수정 일자 : 2017-10-18T05:07:35Z</b><br><br>안녕하세요? Red Hat 송 창 안 입니다.<br><br>Q. 만약 두개의 클라이언트의 ntp.conf에서 NTP_SERVER1 을 TRUE로 하고 NTP_SERVER2 는 아무 옵션을 주지않고<br>   설정을 하였을때 클라이언트는 TRUE를 준 NTP0_SERVER1 과 동기화를 하는것이 아닌 양쪽 NTP_SERVER1 NTP_SERVER2 와 동기화를 한다는 뜻인가요?<br><br>A.  클라이언트는 TRUE를 기재한 NTP0_SERVER1 과 동기화를 하는 것이 맞습니다. 하지만, 두대의 NTP 서버에 대해서 이 옵션을 이용하여 이중화에 사용하려는 경우에는 NTP 동기화 과정에서 <br>    2대의 NTP 구성에서는 Redundancy 보장 할수 없기 때문에, 추천 드리지 않습니다.<br><br>아래 내용은 제가 설명 한 내용의 근거가 되는 내용입니다.<br>If two NTP servers are required for redundancy, one server can be assumed a truechimer by using the true option. But the NTP client will not follow it blindly.<br>A server or peer configured with the true option is ipso facto a truechimer independent of this algorithm.<br><br>감사합니다.<br>송 창안 드림.<br><br><publishedDate>2017-10-18T05:07:35Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000KhihCIAR"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2017-10-17T16:19:48Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2017-10-17T16:19:48Z</b><br><br>답변감사합니다.<br><br>우선 해당 서버에 대해서 문제가 있는 NTP SERVER를 ntp.conf에서 제외 시킨 후 ntpdate [ntp_server] ; hwclock -w  를 하여서 현재는 정상적으로 판단됩니다.<br>참고해주신 <br>systemctl stop ntpd<br>ntpd -qg<br>systemctl start ntpd<br>는 동일한 문제가 다시 발생하면 시도해보겠습니다.<br><br>궁금한것이<br>만약 두개의 클라이언트의 ntp.conf에서  <br>NTP_SERVER1 을 TRUE로 하고 NTP_SERVER2 는 아무 옵션을 주지않고<br>설정을 하였을때<br>클라이언트는 TRUE를 준 NTP0_SERVER1 과 동기화를 하는것이 아닌<br>양쪽 NTP_SERVER1 NTP_SERVER2 와 동기화를 한다는 뜻인가요?<br><br><publishedDate>2017-10-17T16:19:48Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000KgYtmIAF"><br>======================<br><b>생성계정 : Song, Chang-An</b><br><b>생성날짜 : 2017-10-12T07:22:52Z</b><br><b>마지막 답변자 : Song, Chang-An</b><br><b>마지막 수정 일자 : 2017-10-13T02:16:25Z</b><br><br>안녕하세요? Red Hat 송 창 안 입니다.<br><br>문의 주신 내용에 대해서 제공 해주신 파일을 근거로 확인 한 내용은 아래와 같습니다.<br><br>[SLPAFIDL02]<br>@ message : SLPAFIDL02 <br>Oct  3 19:37:47 SLPAFIDL02 ntpd[43797]: Deleting interface #10 bond0:1, 100.254.54.214#123, interface stats: received=0, sent=0, dropped=0, active_time=7457219 secs<br>Oct  3 19:42:45 SLPAFIDL02 ntpd[3548]: ntpd 4.2.6p5@1.2349-o Tue May  3 14:57:03 UTC 2016 (1)<br>Oct  3 19:42:45 SLPAFIDL02 ntpd[3698]: proto: precision = 0.058 usec<br>Oct  3 19:42:45 SLPAFIDL02 ntpd[3698]: 0.0.0.0 c01d 0d kern kernel time sync enabled<br>Oct  3 19:42:45 SLPAFIDL02 ntpd[3698]: Listen and drop on 0 v4wildcard 0.0.0.0 UDP 123<br>Oct  3 19:42:45 SLPAFIDL02 ntpd[3698]: Listen and drop on 1 v6wildcard :: UDP 123<br>Oct  3 19:42:45 SLPAFIDL02 ntpd[3698]: Listen normally on 2 lo 127.0.0.1 UDP 123<br>Oct  3 19:42:45 SLPAFIDL02 ntpd[3698]: Listening on routing socket on fd #19 for interface updates<br>Oct  3 19:42:45 SLPAFIDL02 ntpd[3698]: 0.0.0.0 c016 06 restart<br>Oct  3 19:42:45 SLPAFIDL02 ntpd[3698]: 0.0.0.0 c012 02 freq_set ntpd 3.892 PPM<br>Oct  3 19:42:51 SLPAFIDL02 ntpd[3698]: Listen normally on 3 bond0 100.254.54.212 UDP 123<br>Oct  3 19:42:52 SLPAFIDL02 ntpd[3698]: 0.0.0.0 c615 05 clock_sync<br>Oct  3 19:42:54 SLPAFIDL02 ntpd[3698]: Listen normally on 4 bond1 192.168.1.116 UDP 123<br>Oct  3 19:43:48 SLPAFIDL02 ntpd[3698]: Listen normally on 5 bond1:1 169.254.121.23 UDP 123<br>Oct  3 19:44:20 SLPAFIDL02 ntpd[3698]: Listen normally on 6 bond0:1 100.254.54.214 UDP 123<br>Oct  3 19:52:36 SLPAFIDL02 ntpd[3698]: frequency error -3014 PPM exceeds tolerance 500 PPM &lt;--- 처음 발생된 시점<br>Oct  3 20:00:19 SLPAFIDL02 ntpd[3698]: frequency error -2888 PPM exceeds tolerance 500 PPM<br>Oct  3 20:03:37 SLPAFIDL02 ntpd[3698]: frequency error -1518 PPM exceeds tolerance 500 PPM<br>Oct  3 20:04:43 SLPAFIDL02 ntpd[3698]: frequency error -839 PPM exceeds tolerance 500 PPM<br>Oct  3 20:19:54 SLPAFIDL02 ntpd[3698]: frequency error -1670 PPM exceeds tolerance 500 PPM<br>Oct  3 20:26:30 SLPAFIDL02 ntpd[3698]: frequency error -1005 PPM exceeds tolerance 500 PPM<br>Oct  3 20:27:46 SLPAFIDL02 ntpd[3698]: frequency error -597 PPM exceeds tolerance 500 PPM<br>Oct  3 20:28:54 SLPAFIDL02 ntpd[3698]: frequency error -847 PPM exceeds tolerance 500 PPM<br>Oct  3 20:37:39 SLPAFIDL02 ntpd[3698]: frequency error -3169 PPM exceeds tolerance 500 PPM<br>Oct  3 20:41:58 SLPAFIDL02 ntpd[3698]: frequency error -1814 PPM exceeds tolerance 500 PPM<br>Oct  3 20:50:47 SLPAFIDL02 ntpd[3698]: frequency error -3182 PPM exceeds tolerance 500 PPM<br>Oct  3 20:52:57 SLPAFIDL02 ntpd[3698]: frequency error -1158 PPM exceeds tolerance 500 PPM<br><br><br>처음 시작된 ntpd가 계산 한 시간과 시스템의 local time을 보고 시간이 500 PPM (0.0005%) 초과 했기 때문에 로그에 메시지가 표시 되었습니다.<br>아래의 코드는 코드에서 관련된 부분에 대해서 발쵀 하였습니다.<br><br>@ include/ntp_proto.h<br>..<br>#define NTP_MAXFREQ<br>500e-6<br>..<br><br>@ ntpd/ntp_loopfilter.c<br>int<br>local_clock<br>....<br>        /*<br>         * Clamp the frequency within the tolerance range and calculate<br>         * the frequency difference since the last update.<br>         */<br>        if (fabs(clock_frequency) &gt; NTP_MAXFREQ) &lt;--- ntpd가 계산 한 시간과 시스템의 local time을 보고 시간이 500 PPM (0.0005%) 초과<br>                msyslog(LOG_NOTICE,<br>                    &quot;frequency error %.0f PPM exceeds tolerance %.0f PPM&quot;,<br>                    clock_frequency * 1e6, NTP_MAXFREQ * 1e6);<br>....<br><br>아래의 저희 KCS에서 이런 경우 해결 할수 있는 방안이 언급되어 있습니다.<br>Why does NTP error messsage &quot; ntpd[xxxx]: frequency error -512 PPM exceeds tolerance 500 PPM &quot; displayed in /var/log/messages ?<br>https://access.redhat.com/solutions/35640<br><br>참고적으로,  기존 사례 등을 조사한 결과 /var/lib/ntp/drift 값이 ntp 서버와의 동기화를 방해하는 경우가 있기에 <br>그 경우 다음 테스트를 통해 상황이 개선되는지 여부에 대해서 확인이 필요 합니다.<br><br>=======================================================<br># systemctl stop ntpd<br># mv /var/lib/ntp/drift /var/lib/ntp/drift.bak<br>또는<br># rm /var/lib/ntp/drift<br>또는<br># echo -n &quot;0&quot; &gt; /var/lib/ntp/drift<br># ntpdate &lt;상위 ntp 서버 아이피&gt;<br># systemctl start ntpd<br>=======================================================<br><br>하지만, 이와는 별개로 NTP 구성에서도 이미 이해하고 계신 내용으로, true 옵션을 사용 하더라도, 2대의 NTP 구성에서는 Redundancy 보장 할수 없습니다. 따라서, 가능한 4개 이상의 NTP 서버를 구성 하는 것이 맞습니다.<br>현재 구성된 ntp 설정에 대한 내용을 리뷰 해보았습니다.<br><br>@ntp.conf<br><br>...<br>server PNTPML01SL true<br>restrict PNTPML01SL mask 255.255.255.255 nomodify notrap noquery<br>server PNTPML02SL<br>restrict PNTPML02SL mask 255.255.255.255 nomodify notrap noquery<br>...<br><br>아래는 제가 위에서 언급한 내용에 대해서 KCS 문서에 표현된 내용을 발쵀 하였습니다. <br><br>Can NTP be used with two NTP servers, specifying one as primary and another as backup? <br>https://access.redhat.com/solutions/58025<br>....<br>Redundancy<br>If two NTP servers are required for redundancy, one server can be assumed a truechimer by using the true option. But the NTP client will not follow it blindly.<br><br>Note that this option defeats the purpose of NTP's timesource selection algorithms and allow the sources with this option to set the system clock. If the specified time source is unstable, the system will not be able to identify the problem.<br>....<br><br>감사합니다.<br><br><publishedDate>2017-10-12T07:22:51Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000KgDh8IAF"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2017-10-11T16:11:06Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2017-10-11T16:11:06Z</b><br><br>안녕하세요.<br>해당 파일 업로드 합니다.<br>02 번이 이상이 있는 서버이고요<br>01 번이 정상 서버 입니다.<br><br>messages 파일 sar파일 sosreport첨부해드립니다.<br><br>감사합니다.<br><br><publishedDate>2017-10-11T16:11:06Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000Kg5pIIAR"><br>======================<br><b>생성계정 : Song, Chang-An</b><br><b>생성날짜 : 2017-10-11T06:52:57Z</b><br><b>마지막 답변자 : Song, Chang-An</b><br><b>마지막 수정 일자 : 2017-10-11T06:52:57Z</b><br><br>안녕하세요? Red Hat 송 창 안 입니다.<br>유선상으로 설명 드린 내용과 같이 NTP Source 선택 알고리즘에 대한 설명이 필요 할것으로 판단 되어 아래와 같이 정리 해보았습니다.<br><br>1. NTP에서 Source를 선택하는 알고리즘는 아래와 같습니다.<br>- NTP 표준(RFC1305)에 의하면 NTP Source를 선택 알고리즘은 크게 Intersection, Cluster 알고리즘 2가지가 사용되게 됩니다.<br><br>1.1. Intersection 알고리즘<br>- 본 알고리즘은 Peer와 Local 시간의  offset(시간차)과 distance(거리)를 이용하여 신뢰구간을 계산하게 됩니다.<br>- 예를 들어, 다음과 같이 3개의 Peer가 있을 경우,<br><br><br>Source A : offset 6, distance 3<br><br>Source B : offset 3, distance 2 <br><br>Source C : offset 4, distance 3<br><br>- distance는 오차범위로 보고 각  source 별 신뢰구간을 offset +- distance로 계산 하게 됩니다.<br><br><br>Source A : offset 6, distance 3 = correctness interval [3, 9]<br><br>Source B : offset 3, distance 2 = correctness interval [1, 5]<br><br>Source C : offset 4, distance 3 = correctness interval [1, 7]<br><br>- 여기서 Intersection 즉 공통부분은 [3, 5]가 되며, 이 구간에   포함된 Peer는 trueticker가 설정 되게 됩니다.<br>- 만약 구간을 벗어난 Peer가 있다면 이는 falseticker가 설정되게 됩니다<br><br><br>A    |# # #|# # # #<br><br>B # #|# # #|<br><br><br>C # #|# # #|# #<br>======================<br><br>  1 2 3 4 5 6 7 8 9 10 <br><br>- 위 A, B, C Peer는 모두 trueticker로 지정되게 되는 것을 예로 확인이 가능합니다.<br><br>1.2. Cluster 알고리즘<br>- Intersection Algorithm에서 falseticker로 선택된 Peer 제외되게 됩니다.<br>- offset, jitter, 가중치(weight factor)에 의해 가장 신뢰도가 높은 Peer를 계산 을 하게 됩니다.<br>-   각 Peer의 Network latency인 jitter에 대한 평균제곱근(RMS)을 계산하고, 각 Peer의 RMS 범위중에 가장 멀리 떨어져 있는 Peer는 제외되게 됩니다.<br><br>1.2. Mitigation 알고리즘 <br>- Cluster Algorithm을 통과한 survivor 목록은 다음과 같은 Rule(Mitigation Rule)에 의해 최종 Source가 선택되게 됩니다.<br> (1) prefer peer (flag FLAG_PREFER),<br> (2) pps peers (type REFCLK_ATOM_PPS), <br> (3) the existing system peer, if any, and <br> (4) the head of the survivor list.  <br><br>1.3. NTP Source 선택 에 대한 설명<br>- NTP는 위와 같은 알고리즘에 따라 Peer 중에 유효한 Peer를 선택(+)하고 동기화 대상을 선택(*)하게 됩니다.<br>- 만약 Peer를 신뢰할 수 없는 경우, 해당 Peer를 배제(x)할 수 있습니다. <br>- 여기에는 stratum, offset, jitter 등 다양한 변수들이 상호 영향을 주고 받기 때문에 실제 환경에 따라 결과는 계속해서 달라질 수 있습니다. <br><br>1.4 현재의 이슈에 대해서 추측<br>1.1 절 부터 총 1.3 절까지 많은 선택 과정을 진행 되기 때문에, 향후 디버깅을 위해서 이전에 알려 드린 디버깅 방법에 대해서 정보가 수집이 된다면,<br>로그 및 상황을 통한 분석이 가능 할것으로 판단 됩니다.<br><br>2. NTP 동기화 과정의 디버깅을 위한 방법<br>2.1 ntp의 현재 상태에 대한 스크립트<br><br>그 상황이 발생 했을 때, system a,b,c,d 와 같은 노드에서 아래의 정보들을 아래 스크립트를 수집이 필요 할것으로 판단 됩니다.<br><br>#  s(){ printf &quot;\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n&quot;;}; s; printf '`date`:\t   '; date; printf '`hwclock`: '; hwclock; s; printf '`ntpq -pn`:\n\n'; ntpq -pn; s; printf '`ntpq -c as`:\n'; ntpq -c as; for id in $(ntpq -c as | awk '/^  ./{print $2}'); do s; printf &quot;\`ntpq -c \&quot;rv $id\&quot;\`:\n\n&quot;; ntpq -c &quot;rv $id&quot;; done<br><br>2.2 ntpq command 를 통한 정보 수집<br>아래의 정보를 제공 해주시면, 그 내용을 토대로 저희 전문 엔지니어와 확인 하도록 하겠습니다.<br>~~~<br>  ntpq<br>  ntpq&gt; peers<br>  ntpq&gt; as<br>  ntpq&gt; rv &lt;asID&gt;   &lt;&lt;--(where &lt;asID&gt; should be replace with the number that is showed in the previous output, second column)<br>~~~<br><br>2.3. 네트워크 이슈로 만약 판단 된다면, 아래 내용을 수집 해주시면 될것으로 판단 됩니다.<br>~~~<br>tcpdump -s0 port 123 -vvv -i &lt;NIC&gt; -w port123.cap<br>~~~<br><br>2.4. RHEL6의 /etc/ntp.conf에서 추가 설정을 하실 경우에,  진행중인 ntp 작업에 대한 디버그 로그를 확인할 수 있습니다.<br>~~~<br>tinker panic 100000<br>enable stats<br>statsdir /var/log/ntpstats/<br>statistics clockstats loopstats peerstats sysstats rawstats<br>filegen clockstats file clockstats type day enable<br>filegen loopstats file loopstats type day enable<br>filegen peerstats file peerstats type day enable<br>filegen sysstats file sysstats type day enable<br>filegen rawstats file rawstats type day enable<br>~~~<br><br>2.5. 마지막으로 이슈가 발생하는 상황에서 sosreport를 수집하여, 발생된 시간에 대해서 언급해 주시면, 이슈를 확인함에 있어서 <br>   많은 도움이 될것으로 판단 됩니다.<br><br>추가적으로 좀더 도식화된 내용으로 확인을 하고자 하신다면, 제가 참고한 내용을 첨부 하도록 하겠습니다.<br>또한 저희 전문 엔지니어와 논의된 내용 중에 추천드리는 내용을 전달해드린다면, 두개의 NTP 서버에 대해서는 추천 드리는 구성은 아닙니다.  가능한 4개 이상의 NTP 서버를 구성 하는 것이 의견입니다.<br><br>[1]Can NTP be used with two NTP servers, specifying one as primary and another as backup? <br>https://access.redhat.com/solutions/58025<br><br>[2]NTP Procedure Descriptions and Flow Diagrams<br>https://www.eecis.udel.edu/~mills/database/brief/flow/flow.pdf<br><br>감사합니다.<br>송 창 안 드림<br><br><publishedDate>2017-10-11T06:52:57Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000Kg4ysIAB"><br>======================<br><b>생성계정 : Song, Chang-An</b><br><b>생성날짜 : 2017-10-11T05:13:31Z</b><br><b>마지막 답변자 : Song, Chang-An</b><br><b>마지막 수정 일자 : 2017-10-11T05:13:31Z</b><br><br>안녕하세요? Red Hat 송 창 안 입니다.<br><br>공유 해주신 내용을 토대로 관련 내용을 확인 작업 중에 있습니다.<br>만약 시스템에서의 확인이 필요한 정보가 있는 경우 현재 케이스에서<br>업데이트 하도록 하겠습니다.<br><br>감사합니다.<br>송 창 안 드림.<br><br><publishedDate>2017-10-11T05:13:31Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000KfY4lIAF"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2017-10-09T01:07:18Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2017-10-09T01:07:18Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>금일은 한글날 공휴일이며, 엔지니어들이 대부분 휴무입니다.<br>엔지니어가 배정되는대로 조속하게 처리해드릴 수 있도록 하겠습니다.<br><br>감사합니다.<br><br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>Email: jaeshin@redhat.com <br><br>Red Hat, Asia-Pacific Pty Ltd <br>Website: www.redhat.com<br><br><publishedDate>2017-10-09T01:07:18Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br><br>얼마 전 발생했던 Oracle ASM 리부팅 이슈 (https://access.redhat.com/support/cases/#/case/01942924) 에서 발견되었던 내용입니다.<br><br>해당 시스템들은 ntpdate 를 동기화를 하고 hwclock 을 설정해도 바로 jitter 가 벌어지는 문제가 있었습니다.</issue><environment>공교롭게도 이번에 발생했던 oracle 클러스터 노드가 모두 NTP 가 벌어지는 현상이 있었습니다.<br><br>확인을 해 보니 /var/log/messages 에 NTP 관련 에러가 상당히 많이 나오고 있습니다.<br><br>&quot; ntpd[3285]: frequency error -15113 PPM exceeds tolerance 500 PPM &quot;<br><br>ntpq 를 통해 peers 를 확인 해 보니, 2개의 NTP Server 중 한개 노드는 게속해서 x 로 나오면서 동기화가 안되고 있으며,<br><br>문제가 되는 NTP Server 를 제거 후 한개만 이용하여 동기화를 해 보니, 1~2 일 정도 지나서 정상적으로 동기화가 되고 있습니다.<br><br>2개의 NTP 서버를 구성했을 당시에는 ntpdate 로 수동으로 sync 후에 hwclock 고 맞춰준 후 ntpd 를 실행해도 offset  이 기본 300 이상 벌어지면서 문제가 있었습니다.</environment><periodicityOfIssue>현재 추가적으로 확인 된 사항은 Dell iDRAC8 의 NTP 설정이 빠져 있어, 하드웨어 시간도 동기화를 할 예정인데요,<br><br>혹시 이렇게 iDRAC8 의 NTP 설정 후 다시 O/S 의 NTP 서버를 2개로 설정했을 때, 동일한 문제가 발생한다면,<br><br>물리적인 메인보드 또는 CPU 교체를 고려해야 하는지 여부를 확인 부탁 드립니다.<br><br>감사합니다.</periodicityOfIssue><cep>false</cep></case>