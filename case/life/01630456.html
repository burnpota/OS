======================<br><b>생성계정 : 타임게이트 타임게이트</b><br><b>생성날짜 : 2016-05-09T02:22:18Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2016-05-27T10:04:29Z</b><br><b>id : 500A000000U59j9IAB</b><br>======================<br><br><b><font size=15>
제목  : [장애문의]multipath관련
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요.<br>멀티패스관련 질문 요청드립니다.<br>기존에 /dev/sdi 와 /dev/sdk가 /dev/mapper/mpatha 되어있었는데요.<br>라인문제로 한쪽 패스가 절체되었습니다.<br>그후 리부팅 하니 볼륨그룹의 pv가 기존 /dev/mapper/mpatha  가 들어가있던 것이<br>/dev/sdi 하나만 들어가있는 상태로 변경되었습니다. 현재 multipath daemon은 stop시켜놓은 상태입니다.<br><br>질문은<br>1. 만약 san 라인을 되살린후 멀티패스 데몬을 시작하면 볼륨그룹에 /dev/sdi로만 되있던 것이 /dev/mapper/mpatha 자동으로 변경되는지<br>2. 위의 작업이 가능하다면 파일스시템 상에서 저장되어있는 데이타에는 영향이 없는지<br>3. 오라클 서비스가 돌아가고 있는데 온라인중에 가능한지<br><br>알고 싶습니다.<br>감사합니다.2<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 6.6</b><br><b>계정 번호  : 1648604</b><br><b>심각도  : 3 (Normal)</b><br>======================<br><comment id="a0aA000000GDzC3IAL"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-05-10T04:31:22Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-05-11T05:34:37Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>Q1) 한쪽 패스를 살려도 볼륨그룹에 들어가 있던 pv가 자동으로 변경되지 않는다는 말씀이신가요?<br>A1) /dev/mapper/mpathN 은 시스템이 접근을 하기 이전 부팅시 생성이 되지 않기 때문에 PV<br>    생성을 위해서 사용이 되지 않습니다. 그래서, LVM 볼륨정보와는 무관하다고 이해하시면 될거<br>    같습니다.<br><br>Q2) 추가적으로 sdi와 sdj가 mpatha로 멀티패스되어 있을시 sdj가 문제가 발생하면<br>    볼륨그룹에서 자동으로 mpatha였던 것이 sdi로 바뀌는 것은 어떠한 이유때문에 그런건지요?<br>A2) 이는 multipath 의 failover 의 정책때문에 한 path 로 연결이 되어 있던 디바이스가<br>    Active 였던것이 연결이 끊어져서 다른 디바이스가 Active 되었다라고 이해하시면 될거 <br>   같습니다.<br><br><br>Q3) 아래의 로그가 나타나는 원인은 무엇인가요?<br><br>May  8 15:44:02 FLPIMD01 kernel: Buffer I/O error on device sdk, logical block 4<br>May  8 15:44:02 FLPIMD01 kernel: Buffer I/O error on device sdk, logical block 5<br><br><br>A3) 이는 서버가 부팅중이거나, fdisk 혹은 vgscan 을 실행하는 명령중일때 나타나는 buffer I/O 에러이고,<br>    fabric 채널을 통한 스토리지 array 에 의해서 나타나는 LUN 을 사용하는중인것을 나타냅니다.<br><br>    이 I/O 에러 메시지는 SAN 이 Active/Passive 로 구성될때 나타나는 메시지인데, path 로서 접근될수 없는<br>    Passive devices 가 active 가 되지 않은것이고, I/O 에러로 리턴된것입니다.<br><br>    passive paths 상의 I/O 에러가 예상되지만, 다만 이 I/O 는 유해하지 않고, 무시해도 상관이 없는 메시지<br>    이긴 합니다.<br><br>    이 에러의 원인으로서 SAN 디바이스로 이 passive path 상에 보여지는 I/O 에러는 dm-multipath 사용과,<br>    multipath 디바이스를 검색하는 lvm 명령의 제한에 의해서 인것으로 예상이 됩니다.<br><br>    lvm 명령은 /etc/lvm/lvm.conf 파일내에 filter 를 설정하므로서 passive paths 스캔에서 제한될 수 <br>    있는데, 아래와 같이 /etc/lvm/lvm.conf 을 아래와 같이 수정하신 뒤에<br><br><br>from <br><br>        filter = [ &quot;a/.*/&quot; ] <br><br>to <br><br><br>filter = [ &quot;a|/dev/mapper/mpath.*|&quot;, &quot;a|/dev/sdb.*|&quot;, &quot;r|.|&quot; ]<br><br><br>아래의 명령어로 lvm cache 를 리빌드하셔서 문제가 해소되는지 확인해보시길 바랍니다.<br><br>     $ pvscan<br>     $ vgscan<br>     $ lvscan<br><br><br>     그리고, 시스템이 부팅하는 동안, 커널은 현재 상태를 검증하기 위해서 발견된 모든 scsi 디바이스들상에서<br>     small I/O 를 실행합니다. 만약, 이 에러가 passive path 로 문제가 된다면, 이는 I/O 에러 메시지의<br>     결과가 나타나게 되는것으로 이는 예상된 동작입니다.<br><br>     lvm filter 가 /etc/lvm/lvm.conf 에 구성될때, 관찰된 &quot;Buffer I/o error&quot;, &quot;end_request: I/O<br>     error&quot; 는 위의 lvm 명령을 구동해서 제거될 수 있습니다.<br><br><br>     마지막으로, 위의 lvm 명령을 실행하고 난 뒤에, 변경된 lvm.conf 와 multipath.conf 를 반영하기 위해서<br>     initrd 를 재생성해서 재부팅시 나타날 수 있는 I/O 에러가 나타나는지 확인해보시길 바랍니다.<br><br>     $ cp /boot/initrd-$(uname -r).img /boot/initrd-$(uname -r).img.bak<br>     $ mkinitrd -f -v /boot/initrd-$(uname -r).img $(uname -r)<br>======================<br>[ 참고문서 ]<br><br>[1] Why do I see I/O errors on a RHEL system using devices from an active/passive storage array?<br>- https://access.redhat.com/solutions/18746<br><br>[2] How to rebuild the initial ramdisk image in Red Hat Enterprise Linux<br>- https://access.redhat.com/site/solutions/1958<br><br><br>감사합니다.<br><br><publishedDate>2016-05-10T04:31:22Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GEJQ5IAP"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2016-05-11T02:15:16Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2016-05-11T02:15:16Z</b><br><br>안녕하세요.<br>스토리지 장치가 보이지 않는 문제에대해서 <br>샌쪽과 스토리지 상에서는 문제가 없다고 합니다.<br><br>서버쪽에서 추가로 봐야할 부분이 있을까요??<br><br><publishedDate>2016-05-11T02:15:16Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GEJMcIAP"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2016-05-11T02:04:20Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2016-05-11T02:04:19Z</b><br><br>안녕하세요.<br>아래와 같은 로그가 발생중인데요..<br><br>혹시 서버쪽에서 봐야할 점이 있을까요?<br><br>May  8 15:44:02 FLPIMD01 kernel: Buffer I/O error on device sdk, logical block 4<br>May  8 15:44:02 FLPIMD01 kernel: Buffer I/O error on device sdk, logical block 5<br>May  8 15:44:02 FLPIMD01 kernel: Buffer I/O error on device sdk, logical block 6<br>May  8 15:44:02 FLPIMD01 kernel: Buffer I/O error on device sdk, logical block 7<br>May  8 15:44:02 FLPIMD01 kernel: Buffer I/O error on device sdk, logical block 8<br>May  8 15:44:02 FLPIMD01 kernel: Buffer I/O error on device sdk, logical block 9<br>May  8 15:44:02 FLPIMD01 kernel: Buffer I/O error on device sdk, logical block 10<br>May  8 15:44:02 FLPIMD01 kernel: Buffer I/O error on device sdk, logical block 11<br><br><publishedDate>2016-05-11T02:04:19Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000H5cTxIAJ"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2016-05-10T02:40:44Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2016-05-10T02:40:44Z</b><br><br>답변감사합니다.<br>한쪽 패스를 살려도<br>볼륨그룹에 들어가 있던 pv가 자동으로 변경되지 않는다는 말씀이신가요?<br><br>추가적으로<br>sdi와 sdj가 mpatha로 멀티패스되어 있을시<br>sdj가 문제가 발생하면<br>볼륨그룹에서 자동으로 mpatha였던 것이 sdi로 바뀌는 것은 어떠한 이유때문에 그런건지요?<br><br><publishedDate>2016-05-10T02:40:44Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000H5QgIIAV"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-05-09T10:47:16Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-05-10T02:19:39Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>기존에 /dev/sdi 와 /dev/sdk가 /dev/mapper/mpatha 되어있었는데요.<br>라인문제로 한쪽 패스가 절체되었습니다.<br>그후 리부팅 하니 볼륨그룹의 pv가 기존 /dev/mapper/mpatha  가 들어가있던 것이<br>/dev/sdi 하나만 들어가있는 상태로 변경되었습니다. 현재 multipath daemon은 stop시켜놓은 상태입니다.<br><br><br>Q1) 만약 san 라인을 되살린후 멀티패스 데몬을 시작하면 볼륨그룹에 /dev/sdi로만 되있던 것이 /dev/mapper/mpatha 자동으로 변경되는지<br>A1) multipathd 는 실패된 path 를 모니터링을 하다가, 실패된 path 가 있을때 path 가 소속된 multipath map 을<br>    재구성하는 담당하는 데몬이고, multipath 는 fail-over 또는 performance 를 위해서 디바이스들로 multipath<br>    를 수동으로 발견하거나 제어하는데 사용이 되는 도구로서 역할이 다릅니다.<br><br>    그래서, SAN 연결이 이후에 /dev/sdk 디바이스가 식별이 된다고 하더라도 multipath map 에 존재하지 않으므로 인식<br>    이 되지 않을 것입니다.<br><br>    SAN 을 재연결 한 이후에에는 수동으로 &quot;multipath -F&quot; 명령어를 실행하셔서 디바이스와 path 의 변경사항을 반영 하실<br>    수는 있습니다.<br><br><br>Q2) 위의 작업이 가능하다면 파일스시템 상에서 저장되어있는 데이타에는 영향이 없는지<br>A2) 한쪽 Path 가 살아있는 상태라면 Path A 가 다른 Path B 로 failover 되는 동안 일어나던 I/O 들이 대기큐에 있다가<br>    제시간에 failover 가 잘되어서 실패가 되지 않았다면 데이터가 유실이 되지는 않았을것입니다.<br><br>    그래서, 이는 스토리지에 저장이 되어 있는 데이터와는 무관할것이긴 합니다만 저희는 데이터에 대해서 보장해드리지 않으므로,<br>    중요한 데이터의 경우는 항상 백업을 하실것을 권장드립니다.<br><br><br>Q3) 오라클 서비스가 돌아가고 있는데 온라인중에 가능한지<br>A3) 온라인중에도 가능은 하나, I/O 의 상태에 따라서 변경사항이 적용이 되는동안에 I/O 가 일시적인 지연현상을 발생을 할 수도<br>    있기 때문에 mission critical 한 시스템인 경우는 가능한 정기유지보수 시점에 적용하거나, 그렇지 못하다면 서비스의 <br>    부하가 가장적은 시점에 실행하는것이 가장 좋은 방법입니다.<br><br><br>감사합니다.<br><br><publishedDate>2016-05-09T10:47:15Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000H5O97IAF"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-05-09T05:59:27Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-05-09T05:59:26Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>현재 올려주신 문의내용을 자세히 살펴보고 있는중입니다. 확인이 되는대로 업데이트를 남기도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-05-09T05:59:26Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br>멀티패스관련 질문 요청드립니다.<br>기존에 /dev/sdi 와 /dev/sdk가 /dev/mapper/mpatha 되어있었는데요.<br>라인문제로 한쪽 패스가 절체되었습니다.<br>그후 리부팅 하니 볼륨그룹의 pv가 기존 /dev/mapper/mpatha  가 들어가있던 것이<br>/dev/sdi 하나만 들어가있는 상태로 변경되었습니다. 현재 multipath daemon은 stop시켜놓은 상태입니다.<br><br>질문은<br>1. 만약 san 라인을 되살린후 멀티패스 데몬을 시작하면 볼륨그룹에 /dev/sdi로만 되있던 것이 /dev/mapper/mpatha 자동으로 변경되는지<br>2. 위의 작업이 가능하다면 파일스시템 상에서 저장되어있는 데이타에는 영향이 없는지<br>3. 오라클 서비스가 돌아가고 있는데 온라인중에 가능한지<br><br>알고 싶습니다.<br>감사합니다.2</issue><cep>false</cep></case>