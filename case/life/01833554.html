======================<br><b>생성계정 : 타임게이트 타임게이트</b><br><b>생성날짜 : 2017-04-19T06:39:21Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2017-05-10T10:08:24Z</b><br><b>id : 500A000000X8CcWIAV</b><br>======================<br><br><b><font size=15>
제목  : [삼성생명erp] 페이스 메이커 fail-over건
</font></b><br><br>======================<br><b>사전문의<br></b><br>안녕하세요?<br>이번에 vmware에 있는 게스트호스트 6대가 같은시간 16일 17시 10분경 fail over가 진행되었습니다.<br>fence시  vcenter와의 통신이 되지 않는 증상이 보이는데...<br>어떠한 이유에 의해서 fail-over가 진행되었는지 궁금합니다.<br><br>3개의 서비스(DCRM, PCRM, PIAS) 6대의 os의 문제가 발생되었습니다.<br>해당 사항에 대한 분석 요청 드립니다. 감사합니다.<br><br>시간이 지체 된 만큼 빠른 처리 부탁드립니다. 감사합니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>타입  : Other</b><br><b>계정 번호  : 1648604</b><br><b>심각도  : 3 (Normal)</b><br>======================<br><comment id="a0aA000000JK9S7IAL"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2017-04-24T02:02:46Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2017-04-24T02:02:46Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>전체 타임 흐름에는 문제가 없는것으로 보이며 아래와 같은 미세한 부분은 수정해 주시면 좋을것으로 보입니다.<br><br>2. resource-threshold 3 설정으로 인하여 스토니스 리소스(vmware_stonith1) restart 작업 시행 및 fence 진행<br><br>----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<br> |<br>--17시 10분 20초 : vmware_stonith1 리소스 stop 성공 (1번째  resource restart 작업 시행)<br><br>===&gt; 리소스 모니터링이 실패될 때 recover 작업을 진행합니다. restart보다 recover으로 안내해 드리면 더 합당할 것으로 보입니다.<br><br><br> | ## vmware_stonith1 리소스 start 타임 아웃 20초 <br> | <br>-|-- <br> |  <br> | ## cluster-delay 60초 <br><br><br>==&gt; 상기 부분은 timeout에는 실제로 timeout설정+cluster-delay 이 걸리게 되는데 상기와 같이 시간 흐름으로 timeout설정후<br>cluster-delay 가 흘렀다고 표시하는것보다는 함께 써주시는것이 좋을것으로 보입니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-24T02:02:46Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JK48yIAD"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2017-04-22T08:39:17Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2017-04-22T08:39:17Z</b><br><br>PCRM, PIAS, DCRM 세건 모두 FENCE 모니터링 에러로 인하여 FENCING이 진행된 상태였습니다.<br>IAS위주로 진행사항을 정리하여 보내드립니다. 확인 부탁드립니다.<br><br> <br><br>총 장애 발생부터 팬싱되기까지 걸린시간 약 3분 38초<br><br> <br><br>1. 모니터링 에러로 인한 fence monitor 장애 발생<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:    error: process_lrm_event: Operation vmware_stonith1_monitor_1200000 (node=PIASCL02SL-HB, call=148, status=4, cib-update=280, confirmed=false) Error<br><br> <br><br>2. resource-threshold 3 설정으로 인하여 스토니스 리소스(vmware_stonith1) restart 작업 시행 및 fence 진행<br><br>----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<br> |<br>--17시 10분 20초 : vmware_stonith1 리소스 stop 성공 (1번째  resource restart 작업 시행)<br> |  Apr 16 17:10:20 [23124] PIASCL02SL       crmd:   notice: process_lrm_event:     Operation vmware_stonith1_stop_0: ok (node=PIASCL02SL-HB, call=162, rc=0, cib-update=284, confirmed=true)<br> | <br> | ## vmware_stonith1 리소스 start 타임 아웃 20초 <br> | <br>-|-- <br> |  <br> | ## cluster-delay 60초 <br> |<br>--17시 11분 40초 팬싱디바이스의 어떠한 문제로 인해서 start 실패(문제 발생된 노드의 fail-count-vmware_stonith1의 스코어가 infinity로 설정되며 이는 해당 노드에서 기동 할수 없음을 의미합니다.)<br> |  Apr 16 17:11:40 [23124] PIASCL02SL       crmd:  warning: cib_action_update: rsc_op 30: vmware_stonith1_start_0 on PIASCL02SL-HB timed out<br> |   <br>--17시 11분 41초 어떠한 노드에서도 start 할수 없음을 인지 <br> |   Apr 16 17:11:41 [21776] PIASCL02SL    pengine:   notice: LogActions: Stop    vmware_stonith1 (PIASCL02SL-HB) <br> |   Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: native_color: Resource vmware_stonith1 cannot run anywhere <br>--<br> | <br> | ## vmware_stonith1 리소스 stop 타임 아웃 20초 <br> | <br>-|-- <br> |  <br> | ## cluster-delay 60초 <br> |<br>--17시 13분 01초 vmware_stonith1 stop 타임아웃 발생 (2번째  resource restart진행중 stop이 fail되면서 fence 조건 만족)<br> |   Apr 16 17:13:01 [23124] PIASCL02SL       crmd:  warning: cib_action_update: rsc_op 5: vmware_stonith1_stop_0 on PIASCL02SL-HB timed out<br> |<br>--17시 13분 02초 kdump 진입<br> |   Apr 16 17:13:02 PIASCL01SL fence_kdump[49020]: waiting for message from '172.18.21.72' <br> |<br> | ## kdump timeout 60초 <br> |<br>--17시 14분 02초 kdump 타임아웃<br> |   Apr 16 17:14:02 PIASCL01SL stonith-ng[13369]:  notice: Call to kdump_stonith for PIASCL02SL-HB on behalf of crmd.23124@PIASCL01SL-HB: Timer expired (-62)<br>--17시 14분 02초 PIASCL01SL 에서 ipmilan_fencing 실행<br> |   Apr 16 17:14:02 [13369] PIASCL01SL stonith-ng:     info: call_remote_stonith:   Requesting that PIASCL01SL-HB perform op reboot PIASCL02SL-HB with vmware_stonith2 for crmd.23124 (72s)<br> |<br>--17시 14분 43초 PIASCL01SL 에서 ipmilan_fencing 성공에 대한 리턴값 획득<br> |   Apr 16 17:14:43 PIASCL01SL stonith-ng[13369]:  notice: Operation 'reboot' [49803] (call 3 from crmd.23124) for host 'PIASCL02SL-HB' with device 'vmware_stonith2' returned: 0 (OK) <br>-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<br><br><publishedDate>2017-04-22T08:39:17Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJwMnIAL"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2017-04-21T08:15:17Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2017-04-21T08:15:17Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>[1]위와 같은 메시지를 보내는데 어떠한 retry나 timeout이 17시 10분 20초 전에 없었는지 궁금합니다. 최초 펜스에 문제가 생긴시간을 알고 싶습니다.<br>   그리고 Generic Pacemaker error에 대한 원인을 알고 싶습니다.<br><br>클러스터 corosync 로그에 의하면 서버별 처음으로 이슈가 발생된 시점은 아래와 같으며 messages 파일에 로깅된 일부 팬싱 디바이스에<br>관련된 로그는 어떻게 출력되었는지 확인하기 어렵습니다. pacemaker에 의한 로그이다면 동일 시점에 아래와 같이 corosync.log 로그에도 관련<br>메시지가 기록됩니다.<br><br>Apr 16 17:06:07 [23122] PIASCL02SL stonith-ng:     info: internal_stonith_action_execute:       Attempt 2 to execute fence_vmware_soap (monitor). remaining timeout is 950<br>Apr 16 17:10:20 [23122] PIASCL02SL stonith-ng:     info: update_remaining_timeout:      Attempted to execute agent fence_vmware_soap (monitor) the maximum number of times (2) allowed<br>Apr 16 17:10:20 [23122] PIASCL02SL stonith-ng:   notice: log_operation: Operation 'monitor' [5431] for device 'vmware_stonith1' returned: -201 (Generic Pacemaker error)<br><br><br>Apr 16 17:05:45 [41606] DCRMCL01SL stonith-ng:     info: internal_stonith_action_execute:       Attempt 2 to execute fence_vmware_soap (monitor). remaining timeout is 949<br>Apr 16 17:09:56 [41606] DCRMCL01SL stonith-ng:     info: update_remaining_timeout:      Attempted to execute agent fence_vmware_soap (monitor) the maximum number of times (2) allowed<br>Apr 16 17:09:56 [41606] DCRMCL01SL stonith-ng:   notice: log_operation: Operation 'monitor' [59967] for device 'vmware_stonith2' returned: -201 (Generic Pacemaker error)<br><br><br>Apr 16 17:06:13 [5118] PCRMCL02SL stonith-ng:     info: internal_stonith_action_execute:        Attempt 2 to execute fence_vmware_soap (monitor). remaining timeout is 950<br>Apr 16 17:10:24 [5118] PCRMCL02SL stonith-ng:     info: update_remaining_timeout:       Attempted to execute agent fence_vmware_soap (monitor) the maximum number of times (2) allowed<br>Apr 16 17:10:24 [5118] PCRMCL02SL stonith-ng:   notice: log_operation:  Operation 'monitor' [41072] for device 'vmware_stonith1' returned: -201 (Generic Pacemaker error)<br><br><br>[2]모니터링 에러의 발생이란 무엇을 뜻하는것인가요? 에러의 발생 원인을 위에 말씀드렸듯이 알고 싶습니다. <br>(ex. 통신단절)<br><br>현재 기록된 로그로 이슈 발생시 팬싱 디바이스에 구체적으로 어떤 에러가 있는지를 알수가 없습니다. <br>팬싱 디바이스에 어떤 이슈가 있는지는 이슈 발생시 아래의 문서에 따라 원인 분석을 해보셔야 합니다.<br><br>https://access.redhat.com/solutions/473603<br>https://access.redhat.com/solutions/378413<br><br><br>[3]STONITH가 UNCLEAN되는 상태란 무엇이고 모니터링 에러로 발생되는 상태의 차이는 무엇입니까?<br><br>STONITH가 UNCLEAN 상태는 어떤 경우를 말씀하시는것인지요? 노드 UNCLEAN 상태를 말씀하시는건가요?<br><br>&quot;이번 팬싱 이슈는 팬싱 디바이스의 리소스가 모니터링에 실패하여 recover 작업을 진행시 팬싱 디바이스 stop 작업이 실패되어 팬싱 이슈가 발생된 것입니다.&quot;<br>[4]위의 설명을 재가 아래와 같이 해석하는데 맞는지요?<br>--&gt; 네, 맞게 이해 하셨습니다.<br><br>이번 팬싱 이슈는 팬싱 디바이스의 리소스(vmware_stonith1)가 모니터링(vmware_stonith1_monitor)에 실패하여 recover 작업(migration-threshold 3)<br>진행시 팬싱 디바이스 stop(이 작업은 구체적으로 무엇을 말하는것입니까? 어떤 로그를 말씀하시는지 잘 모르겠습니다.디바이스 stop인지 resource stop인지...)<br><br>리소스 스톱 작업이 실패하여 팬싱 되었습니다.<br>Apr 16 17:13:01 [23124] PIASCL02SL       crmd:  warning: cib_action_update:     rsc_op 5: vmware_stonith1_stop_0 on PIASCL02SL-HB timed out <br>^^^^^^^^^^^ 스톱 작업이 time out 됨<br>Apr 16 17:13:02 [23124] PIASCL02SL       crmd:     info: process_graph_event:   Detected action (149.5) vmware_stonith1_stop_0.-1=unknown error: failed<br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: pe_fence_node: Node PIASCL02SL-HB will be fenced because of resource failure(s)<br><br><br>[5]- migration-threshold 설정에 따라 다시 모니터링 작업 시도 (3번 시도하는것으로 아는데 어떤 건인지? 시도하는 인터벌은 몇초인지 궁금합니다. 어떤식으로 3번 시도를 하는지 로그에서 찍어주셨으면 좋겠습니다.)<br><br>이번 팬싱이슈에 대한 시간 흐름은 아래와 같습니다.<br>pacemaker는 리소스 모니터링 작업이 실패되는 recover 작업을 시도하게 되며 이때 리소스 stop 작업 성공 됨<br><br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:   notice: process_lrm_event:     Operation vmware_stonith1_stop_0: ok (node=PIASCL02SL-HB, call=162, rc=0, cib-update=284, confirmed=true)<br>^^^^^^^ 리소스 stop 작업 성공<br><br>리소스 start 작업이 실패됨<br>리소스의 start 작업은 pacemaker의 하드 코딩에 의하여 한번 실패하게 될 경우 failcount가 INFINITY로 설정되어 해당 노드에서 기동될수 없게 됩니다.<br><br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:  warning: unpack_rsc_op_failure: Processing failed op monitor for vmware_stonith1 on PIASCL02SL-HB: unknown error (1)<br>Apr 16 17:11:41 [23124] PIASCL02SL       crmd:     info: update_failcount:      Updating failcount for vmware_stonith1 on PIASCL02SL-HB after failed start: rc=1 (update=INFINITY, time=1492330301)<br>^^^^^^^ start 작업이 실패되어 failcount가 INFINITY로 설정<br><br>아래의 설정에 의하면 vmware_stonith1는 PIASCL01SL노드에서 기동될수 없습니다.<br><br>      &lt;rsc_location id=&quot;const_vmware1&quot; node=&quot;PIASCL01SL-HB&quot; rsc=&quot;vmware_stonith1&quot; score=&quot;-INFINITY&quot;/&gt;<br><br>따라서 vmware_stonith1는 어느 노드에서도 기동할수 없는것으로 판단 되어 리소스 stop 작업 실시<br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: native_color:  Resource vmware_stonith1 cannot run anywhere<br><br>리소스 stop 작업 실시 time out 되면서 실패<br><br>Apr 16 17:11:41 [23124] PIASCL02SL       crmd:     info: do_lrm_rsc_op: Performing key=5:149:0:bd1787e5-49a9-41a7-b670-9701d76e2cbc op=vmware_stonith1_stop_0<br>Apr 16 17:13:01 [23124] PIASCL02SL       crmd:     info: create_operation_update:       cib_action_update: Updating resource vmware_stonith1 after stop op Timed Out (interval=0)<br><br>따라서 디폴트 on-fail 값에 의하여 PIASCL02SL 노드 팬싱 됨<br><br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: pe_fence_node: Node PIASCL02SL-HB will be fenced because of resource failure(s)<br><br><br>이번 이슈 발생시에는 recover 시도시 stop 작업이 성공하였지만 start 작업이 실패되어 failcount가 INFINITY로 설정되면서<br>모니터링을 3번 시도하지 못하고 한번 실패후 서비스 stop 작업 time out에 의하여 팬싱이 되었습니다.<br><br><br>- 동시에 vmware_stonith1 이 FAILED 상태로 진입한것이 확인되어 pacemaker가 recover 작업 시도. 즉 stop/start 작업 실시 <br>[6] (이것도 migration thredhod값에 의해서 시도 되는것인지요?)<br><br>migration-threshold은 모니터링이 몇번 실패할수 있는지를 결정합니다.<br>즉 모니터링이 실패시 pacemaker가 리소스 recover(stop/start) 작업을 진행하게 되는데<br>이때 stop/start 작업이 성공하고 이후에 모니터링이 다시 실패하면 migration-threshold<br>값에 의하여 또 다시 recover 작업을 시도하게 됩니다.<br>다만 만일 stop/start 작업이 실패되면 해당 이슈와 같이 migration-threshold 설정한<br>만큼 모니터링 재기동 시도를 하지 않았지만 팬싱이 될수 있습니다.<br><br><br>- 그리하여 vmware_stonith1_monitor 작업이 cancel 됨<br>[7](위 그리하여라는 것은 뭐가 그러하다는것인지 모르겠습니다. cancelled 된 시간안 17시 10분 20초인데 recover작업은 17시 11분 41초까지 진행중입니다. 모니터가 캔슬되면 migration thredhod가 작동하는것인지요?)<br><br>17시 10분 20초에 리소스 stop 작업이 성공되면서 vmware_stonith1_monitor 작업이 cancel 되었습니다.<br>그리고 리소스 start 작업이 실행되었는데 17시 11분 41초에 time out가 되었습니다.<br>start 작업의 timeout 설정이 20초 인데 80초가 걸린 원인은 pacemaker는 actime timeout에 디폴트로 60초를 추가하기 때문입니다.<br>관련 코드는 아래와 같습니다.<br><br>action의 timeout에 graph-&gt;network_delay 값을 추가하는것으로 확인됨<br><br>    action-&gt;timer-&gt;source_id = g_timeout_add(action-&gt;timer-&gt;timeout + graph-&gt;network_delay,<br>                                             action_timer_callback, (void *)action-&gt;timer);<br><br>graph-&gt;network_delay 값은 cluster-delay 값에 의하여 결정 되는것으로 확인<br><br>        time = crm_element_value(xml_graph, &quot;cluster-delay&quot;);<br>        CRM_CHECK(time != NULL, free(new_graph);<br>                  return NULL);<br>        new_graph-&gt;network_delay = crm_get_msec(time); &lt;=========<br><br>cluster-delay 의 디폴트 값은 60초입니다.<br>따라서 해당 이슈에서 action의 timeout 값을 20초로 설정시 실제 timeout에 걸리는 시간은 80초로 됩니다.<br><br><br>[8]- stop 작업 성공 (이 작업 성공이 무엇을 의미하는것인지요?)<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:   notice: process_lrm_event:<br>Operation vmware_stonith1_stop_0: ok (node=PIASCL02SL-HB, call=162, rc=0, cib-update=284, confirmed=true)<br><br>리소스 recover 작업시 리소스 스톱 작업이며 해당 리소스가 정상적으로 스톱됨을 알립니다.<br><br><br>[9]- start 작업이 time out 됨<br>(17시 10분 20초에 스타트 하였으나 17시 11분 40초에 타임아웃이 생겼다면 약 1분 20초의 타임아웃 시간이 있다고 보는데 이는 어떤 컨피그 설정 값인지요?)<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:   notice: te_rsc_command:<br>Initiating action 30: start vmware_stonith1_start_0 on PIASCL02SL-HB (local)<br>Apr 16 17:11:40 [23124] PIASCL02SL       crmd:  warning: cib_action_update:<br>rsc_op 30: vmware_stonith1_start_0 on PIASCL02SL-HB timed out<br><br>[7] 번 답변 참고하시기 바랍니다.<br><br><br>- fail-count를 INFINITY로 설정<br>[10] (PIASCL02SL에서 fail-count-vmware_stonith1[PIASCL02SL-HB]의 스코어가 1에서 INFINITY로 변경된다는 말인가요? 이렇게 되면 어떤 증상이 생기는지요?)<br>Apr 16 17:11:41 [23123] PIASCL02SL      attrd:     info: attrd_peer_update:<br>Setting fail-count-vmware_stonith1[PIASCL02SL-HB]: 1 -&gt; INFINITY from PIASCL02SL-HB<br><br>failcount가 INFINITY로 설정하게 되면 이슈가 발생된 리소스가 해당 노드에서 기동될수 없게 됩니다.<br><br><br>- vmware_stonith1 리소스가 어느 노드에서도 기동될수 없는것으로 판단 및 stop 작업 실시<br>[11](어떤 노드에서도 기동될수 없음에 대한 판단은 무엇으로 한것인가요? 로그가 아래와 같은 메시지를 보내는 근거가 무엇인지요? 스코어 값에 의해 그런것 같은데 설명 부탁드릴게요)<br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:   notice: LogActions:<br>Stop    vmware_stonith1<br>(PIASCL02SL-HB)<br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: native_color:<br>Resource vmware_stonith1 cannot run anywhere<br><br>[5]번 답변 참고하세요.<br><br><br>- stop 작업이 time out 되면서 vmware_stonith1 리소스가 failed 상태에 빠짐<br>[12](이것도 마찬가지로 op에 대한 interval, start, stop timeout값이 얼마인지요?  그리고 vmware_stonith1 리소스가 failed되면서 바로 kdump에 진입되나요?)<br><br>action의 디폴트 interval 값은 20초 입니다. 다만 cluster-delay 값에 의하여 실제로 timeout에는 80초 걸립니다.<br>리소스가 stop 작업에 failed 되면 바로 팬싱을 시도하게 되는데 현재 고객님 환경 팬싱 레벨 설정에 의하면 fence_kdump가 실행되게 됩니다.<br><br><br>- PIASCL01SL에서 PIASCL02SL로 vmware_soap_fence 실행하여 성공<br>[13](kdump 타임아웃 이후 약 43초 후에 파워 펜싱이 진행되었는데 kdump 타임아웃후 인터벌이 존재하는지요? 약 40초가 걸린 이유가 궁금합니다.)<br>Apr 16 17:14:43 PIASCL01SL stonith-ng[13369]:  notice: Operation 'reboot' [49803] (call 3 from crmd.23124) for host 'PIASCL02SL-HB' with device 'vmware_stonith2' returned: 0 (OK)<br><br>kdump가 타임아웃된후 바로 vmware_stonith2 디바이스로 팬싱 request를 보낸것으로 확인됩니다.<br>Apr 16 17:14:02 [13369] PIASCL01SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PIASCL02SL-HB on behalf of crmd.23124@PIASCL01SL-HB: Timer expired (-62)<br>Apr 16 17:14:02 [13369] PIASCL01SL stonith-ng:     info: call_remote_stonith:   Requesting that PIASCL01SL-HB perform op reboot PIASCL02SL-HB with vmware_stonith2 for crmd.23124 (72s)<br><br>17:14:43 시점은 팬싱 디바이스쪽으로 부터 팬싱이 성공된것에 대한 return 값을 받은 시점입니다.<br><br><br>[14] vmware_soap_fence의 start, stop의 interval 값과 timeout값은 어떻게 되는지요? recover(stop &amp; restart) 할때의 총 시간은 얼마인지요?<br><br>리소스 start, stop 의 디폴트 timeout 값은 20초 이며 interval는 없습니다.<br>recover 할때의 총 시간은 이슈에 따라 다름으로 이번 이슈에서 소요된 시간은 [5]번 답변 확인해 보시기 바랍니다.<br><br>이 총시간들이 3회 실시되면 migration threshold가 걸린 총 시간이 되는것인지요?<br>==&gt;<br>위에서 말씀 드렸듯이 이번 이슈 발생시에는 모니터링을 3회 실행하지 못하였습니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-21T08:15:17Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JJmq4IAD"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2017-04-20T15:59:32Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2017-04-20T15:59:32Z</b><br><br>클론은 매 5분 마다 기동됩니다. 클론에서 나타내는 문제는 root: FAILED CHECKING FENCE DEVICE (Hardware Error) <br>이 로그로 판단합니다. 클론으로 발생된 로그라면 5분에 한번씩 발생하여야 하나 보시면 아시겠지만 fence_vmware_soap가 랜덤하게 메시지를 보내고 있습니다.<br>클론에서 보내는 메시지는 아닌것으로 보이는데... <br><br>Apr 16 17:04:10 PIASCL02SL fence_vmware_soap: Unable to connect/login to fencing device<br>Apr 16 17:04:10 PIASCL02SL root: FAILED CHECKING FENCE DEVICE (Hardware Error) : CHECK FENCE DEVICE( 100.254.69.224 ) - [ Invalid Status ] or [ Incorrect Login credentials ]<br><br>Apr 16 17:05:01 PIASCL02SL CROND[5015]: (root) CMD (/bin/sh /sysadmin/syscheck/stonith_check_vmware.sh &gt; /dev/null 2&gt;&amp;1)<br>.<br>.<br>Apr 16 17:06:07 PIASCL02SL fence_vmware_soap: Unable to connect/login to fencing device<br>.<br>.<br>Apr 16 17:09:12 PIASCL02SL fence_vmware_soap: Unable to connect/login to fencing device<br>.<br>.<br><br>Apr 16 17:10:20 [23122] PIASCL02SL stonith-ng:   notice: log_operation:<br>Operation 'monitor' [5431] for device 'vmware_stonith1' returned: -201 (Generic Pacemaker error)<br>[1]위와 같은 메시지를 보내는데 어떠한 retry나 timeout이 17시 10분 20초 전에 없었는지 궁금합니다. 최초 펜스에 문제가 생긴시간을 알고 싶습니다.<br>   그리고 Generic Pacemaker error에 대한 원인을 알고 싶습니다.<br>======================<br><br>[2]모니터링 에러의 발생이란 무엇을 뜻하는것인가요? 에러의 발생 원인을 위에 말씀드렸듯이 알고 싶습니다. <br>(ex. 통신단절)<br>======================<br>[3]STONITH가 UNCLEAN되는 상태란 무엇이고 모니터링 에러로 발생되는 상태의 차이는 무엇입니까?<br>======================<br><br>&quot;이번 팬싱 이슈는 팬싱 디바이스의 리소스가 모니터링에 실패하여 recover 작업을 진행시 팬싱 디바이스 stop 작업이 실패되어 팬싱 이슈가 발생된 것입니다.&quot;<br>[4]위의 설명을 재가 아래와 같이 해석하는데 맞는지요?<br>--&gt;<br>이번 팬싱 이슈는 팬싱 디바이스의 리소스(vmware_stonith1)가 모니터링(vmware_stonith1_monitor)에 실패하여 recover 작업(migration-threshold 3)<br>진행시 팬싱 디바이스 stop(이 작업은 구체적으로 무엇을 말하는것입니까? 어떤 로그를 말씀하시는지 잘 모르겠습니다.디바이스 stop인지 resource stop인지...)<br><br><br>[5]- migration-threshold 설정에 따라 다시 모니터링 작업 시도 (3번 시도하는것으로 아는데 어떤 건인지? 시도하는 인터벌은 몇초인지 궁금합니다. 어떤식으로 3번 시도를 하는지 로그에서 찍어주셨으면 좋겠습니다.)<br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:     info: get_failcount_full:<br>vmware_stonith1 has failed 1 times on PIASCL02SL-HB<br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:     info: common_apply_stickiness:<br>vmware_stonith1 can fail 2 more times on PIASCL02SL-HB before being forced off<br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:     info: RecurringOp:<br> Start recurring monitor (1200s) for vmware_stonith1 on PIASCL02SL-HB<br><br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: get_failcount_full:<br>vmware_stonith1 has failed 1 times on PIASCL02SL-HB<br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: common_apply_stickiness:<br>vmware_stonith1 can fail 2 more times on PIASCL02SL-HB before being forced off<br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: RecurringOp:<br> Start recurring monitor (1200s) for vmware_stonith1 on PIASCL02SL-HB<br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: get_failcount_full:<br>vmware_stonith1 has failed INFINITY times on PIASCL02SL-HB<br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:  warning: common_apply_stickiness:<br>Forcing vmware_stonith1 away from PIASCL02SL-HB after 1000000 failures (max=3)<br><br><br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:     info: get_failcount_full:<br>vmware_stonith1 has failed INFINITY times on PIASCL02SL-HB<br><br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: common_apply_stickiness:<br>Forcing vmware_stonith1 away from PIASCL02SL-HB after 1000000 failures (max=3)<br>======================<br>- 동시에 vmware_stonith1 이 FAILED 상태로 진입한것이 확인되어 pacemaker가 recover 작업 시도. 즉 stop/start 작업 실시 <br>[6] (이것도 migration thredhod값에 의해서 시도 되는것인지요?)<br><br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:     info: native_print:<br>vmware_stonith1<br>(stonith:fence_vmware_soap):<br>FAILED PIASCL02SL-HB<br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:   notice: LogActions:<br>Recover vmware_stonith1<br>(Started PIASCL02SL-HB)<br><br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:     info: native_print:<br>vmware_stonith1<br>(stonith:fence_vmware_soap):<br>FAILED PIASCL02SL-HB<br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:   notice: LogActions:<br>Recover vmware_stonith1<br>(Started PIASCL02SL-HB)<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:   notice: te_rsc_command:<br>Initiating action 6: stop vmware_stonith1_stop_0 on PIASCL02SL-HB (local)<br><br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: native_print:<br>vmware_stonith1<br>(stonith:fence_vmware_soap):<br>FAILED PIASCL02SL-HB<br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:   notice: LogActions:<br>Recover vmware_stonith1<br>(Started PIASCL02SL-HB)<br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: native_print:<br>vmware_stonith1<br>(stonith:fence_vmware_soap):<br>FAILED PIASCL02SL-HB<br>Apr 16 17:11:41 [23124] PIASCL02SL       crmd:   notice: te_rsc_command:<br>Initiating action 5: stop vmware_stonith1_stop_0 on PIASCL02SL-HB (local)<br><br><br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:     info: native_print:<br>vmware_stonith1<br>(stonith:fence_vmware_soap):<br>FAILED PIASCL02SL-HB<br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:     info: native_print:<br>vmware_stonith1<br>(stonith:fence_vmware_soap):<br>FAILED PIASCL02SL-HB<br><br><br>- 그리하여 vmware_stonith1_monitor 작업이 cancel 됨<br>[7](위 그리하여라는 것은 뭐가 그러하다는것인지 모르겠습니다. cancelled 된 시간안 17시 10분 20초인데 recover작업은 17시 11분 41초까지 진행중입니다. 모니터가 캔슬되면 migration thredhod가 작동하는것인지요?)<br><br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:     info: do_lrm_rsc_op:<br>Performing key=6:147:0:bd1787e5-49a9-41a7-b670-9701d76e2cbc op=vmware_stonith1_stop_0<br>Apr 16 17:11:41 [23124] PIASCL02SL       crmd:     info: do_lrm_rsc_op:<br>Performing key=5:149:0:bd1787e5-49a9-41a7-b670-9701d76e2cbc op=vmware_stonith1_stop_0<br><br>Apr 16 17:10:20 [21774] PIASCL02SL       lrmd:     info: log_execute:<br>executing - rsc:vmware_stonith1 action:stop call_id:162<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:     info: process_lrm_event:<br>Operation vmware_stonith1_monitor_1200000: Cancelled (node=PIASCL02SL-HB, call=148, confirmed=true)<br>Search &quot;info: log_execute:<br>executing&quot; (3 hits in 1 file)<br>Apr 16 17:10:20 [21774] PIASCL02SL       lrmd:     info: log_execute:<br>executing - rsc:vmware_stonith1 action:start call_id:163<br>Apr 16 17:13:16 [21774] PIASCL02SL       lrmd:     info: log_execute:<br>executing - rsc:vmware_stonith1 action:stop call_id:164<br>======================<br>[8]- stop 작업 성공 (이 작업 성공이 무엇을 의미하는것인지요?)<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:   notice: process_lrm_event:<br>Operation vmware_stonith1_stop_0: ok (node=PIASCL02SL-HB, call=162, rc=0, cib-update=284, confirmed=true)<br><br>[9]- start 작업이 time out 됨<br>(17시 10분 20초에 스타트 하였으나 17시 11분 40초에 타임아웃이 생겼다면 약 1분 20초의 타임아웃 시간이 있다고 보는데 이는 어떤 컨피그 설정 값인지요?)<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:   notice: te_rsc_command:<br>Initiating action 30: start vmware_stonith1_start_0 on PIASCL02SL-HB (local)<br>Apr 16 17:11:40 [23124] PIASCL02SL       crmd:  warning: cib_action_update:<br>rsc_op 30: vmware_stonith1_start_0 on PIASCL02SL-HB timed out<br>======================<br>- fail-count를 INFINITY로 설정<br>[10] (PIASCL02SL에서 fail-count-vmware_stonith1[PIASCL02SL-HB]의 스코어가 1에서 INFINITY로 변경된다는 말인가요? 이렇게 되면 어떤 증상이 생기는지요?)<br>Apr 16 17:11:41 [23123] PIASCL02SL      attrd:     info: attrd_peer_update:<br>Setting fail-count-vmware_stonith1[PIASCL02SL-HB]: 1 -&gt; INFINITY from PIASCL02SL-HB<br>======================<br><br>- vmware_stonith1 리소스가 어느 노드에서도 기동될수 없는것으로 판단 및 stop 작업 실시<br>[11](어떤 노드에서도 기동될수 없음에 대한 판단은 무엇으로 한것인가요? 로그가 아래와 같은 메시지를 보내는 근거가 무엇인지요? 스코어 값에 의해 그런것 같은데 설명 부탁드릴게요)<br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:   notice: LogActions:<br>Stop    vmware_stonith1<br>(PIASCL02SL-HB)<br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: native_color:<br>Resource vmware_stonith1 cannot run anywhere<br>======================<br><br>- stop 작업이 time out 되면서 vmware_stonith1 리소스가 failed 상태에 빠짐<br>[12](이것도 마찬가지로 op에 대한 interval, start, stop timeout값이 얼마인지요?  그리고 vmware_stonith1 리소스가 failed되면서 바로 kdump에 진입되나요?)<br><br>Apr 16 17:13:01 [23124] PIASCL02SL       crmd:  warning: cib_action_update:<br>rsc_op 5: vmware_stonith1_stop_0 on PIASCL02SL-HB timed out<br><br><br>Line 2500: Apr 16 17:10:20 [23124] PIASCL02SL       crmd:     info: abort_transition_graph:<br>Transition aborted by vmware_stonith1_monitor_1200000 'create' on PIASCL02SL-HB: Foreign event (magic=4:1;27:181:0:f2a7b761-9be4-43b5-a759-0fdf698e2499, cib=0.137.1, source=process_graph_event:588, 1)<br><br>Line 2502: Apr 16 17:10:20 [23124] PIASCL02SL       crmd:     info: process_graph_event:<br>Detected action (181.27) vmware_stonith1_monitor_1200000.148=unknown error: failed<br><br><br>Line 2638: Apr 16 17:11:41 [23124] PIASCL02SL       crmd:     info: abort_transition_graph:<br>Transition aborted by vmware_stonith1_start_0 'modify' on PIASCL02SL-HB: Inactive graph (magic=2:1;30:147:0:bd1787e5-49a9-41a7-b670-9701d76e2cbc, cib=0.137.5, source=process_graph_event:598, 1)<br><br>Line 2640: Apr 16 17:11:41 [23124] PIASCL02SL       crmd:     info: process_graph_event:<br>Detected action (147.30) vmware_stonith1_start_0.-1=unknown error: failed<br><br><br>Line 2641: Apr 16 17:11:41 [23124] PIASCL02SL       crmd:     info: abort_transition_graph:<br>Transition aborted by vmware_stonith1_start_0 'modify' on PIASCL02SL-HB: Inactive graph (magic=2:1;30:147:0:bd1787e5-49a9-41a7-b670-9701d76e2cbc, cib=0.137.5, source=process_graph_event:598, 1)<br><br>Line 2643: Apr 16 17:11:41 [23124] PIASCL02SL       crmd:     info: process_graph_event:<br>Detected action (147.30) vmware_stonith1_start_0.-1=unknown error: failed<br><br><br>Line 2751: Apr 16 17:13:02 [23124] PIASCL02SL       crmd:     info: abort_transition_graph:<br>Transition aborted by vmware_stonith1_stop_0 'modify' on PIASCL02SL-HB: Inactive graph (magic=2:1;5:149:0:bd1787e5-49a9-41a7-b670-9701d76e2cbc, cib=0.137.8, source=process_graph_event:598, 1)<br><br>Line 2753: Apr 16 17:13:02 [23124] PIASCL02SL       crmd:     info: process_graph_event:<br>Detected action (149.5) vmware_stonith1_stop_0.-1=unknown error: failed<br><br><br>Line 2754: Apr 16 17:13:02 [23124] PIASCL02SL       crmd:     info: abort_transition_graph:<br>Transition aborted by vmware_stonith1_stop_0 'modify' on PIASCL02SL-HB: Inactive graph (magic=2:1;5:149:0:bd1787e5-49a9-41a7-b670-9701d76e2cbc, cib=0.137.8, source=process_graph_event:598, 1)<br><br>Line 2756: Apr 16 17:13:02 [23124] PIASCL02SL       crmd:     info: process_graph_event:<br>Detected action (149.5) vmware_stonith1_stop_0.-1=unknown error: failed<br><br><br>- 팬싱 작업 실시<br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: pe_fence_node:<br>Node PIASCL02SL-HB will be fenced because of resource failure(s)<br><br>- kdump진입<br>Apr 16 17:13:02 PIASCL01SL fence_kdump[49020]: waiting for message from '172.18.21.72'<br><br>- kdump 타임아웃<br>Apr 16 17:14:02 PIASCL01SL stonith-ng[13369]:  notice: Call to kdump_stonith for PIASCL02SL-HB on behalf of crmd.23124@PIASCL01SL-HB: Timer expired (-62)<br><br>- PIASCL01SL에서 PIASCL02SL로 vmware_soap_fence 실행하여 성공<br>[13](kdump 타임아웃 이후 약 43초 후에 파워 펜싱이 진행되었는데 kdump 타임아웃후 인터벌이 존재하는지요? 약 40초가 걸린 이유가 궁금합니다.)<br>Apr 16 17:14:43 PIASCL01SL stonith-ng[13369]:  notice: Operation 'reboot' [49803] (call 3 from crmd.23124) for host 'PIASCL02SL-HB' with device 'vmware_stonith2' returned: 0 (OK)<br>======================<br><br>======================<br>[14] vmware_soap_fence의 start, stop의 interval 값과 timeout값은 어떻게 되는지요? recover(stop &amp; restart) 할때의 총 시간은 얼마인지요?<br><br>이 총시간들이 3회 실시되면 migration threshold가 걸린 총 시간이 되는것인지요?<br><br>최초 발생시간부터 타임테이블로 어떻게 진행이 되는지 어떤 조건에 의해 상황이 전개 되는지 궁금합니다. <br><br>내용이 하도 많아서 두서 없이 적었습니다. 양해바라고 좋은 답변 부탁드립니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-20T15:59:32Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJfq7IAD"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2017-04-20T08:15:45Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2017-04-20T08:15:45Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>[1] 최초 인지한 시간은 17시 04분 10초가 맞는지요?<br>Apr 16 17:04:10 PIASCL02SL fence_vmware_soap: Unable to connect/login to fencing device<br><br>상기 메시지는 고객님께서 실행하시는 cronjob에 의한 로그인것으로 보입니다.<br>Apr 16 16:55:01 PIASCL02SL CROND[1060]: (root) CMD (/bin/sh /sysadmin/syscheck/stonith_check_vmware.sh &gt; /dev/null 2&gt;&amp;1)<br>Apr 16 17:00:01 PIASCL02SL CROND[3481]: (root) CMD (/bin/sh /sysadmin/syscheck/stonith_check_vmware.sh &gt; /dev/null 2&gt;&amp;1)<br>Apr 16 17:05:01 PIASCL02SL CROND[5015]: (root) CMD (/bin/sh /sysadmin/syscheck/stonith_check_vmware.sh &gt; /dev/null 2&gt;&amp;1)<br><br>Apr 16 17:04:10 PIASCL02SL fence_vmware_soap: Unable to connect/login to fencing device<br>Apr 16 17:09:12 PIASCL02SL fence_vmware_soap: Unable to connect/login to fencing device<br>Apr 16 17:10:19 PIASCL02SL fence_vmware_soap: Unable to connect/login to fencing device<br><br>pacemaker 로그에 의하여 시간을 추정해보면 17:03:57에 실행된 모니터링 작업 부터 팬싱 디바이스와의 연결이 문제가 있는것으로 인지하였습니다.<br>Apr 16 17:06:07 PIASCL02SL fence_vmware_soap: Unable to connect/login to fencing device<br>Apr 16 17:06:07 [23122] PIASCL02SL stonith-ng:     info: internal_stonith_action_execute:       Attempt 2 to execute fence_vmware_soap (monitor). remaining timeout is 950<br><br>[2] 모니터링이 실패된것이 맞다면 타임아웃에 의한 메시지인가요? 타임아웃이라면 아래에 보이는 컨피그의 어트리뷰트값의 1200S 값을 말하는것인지요? <br>Apr 16 17:10:20 [23122] PIASCL02SL stonith-ng:   notice: log_operation: Operation 'monitor' [5431] for device 'vmware_stonith1' returned: -201 (Generic Pacemaker error)<br><br>상기 메시지는 모니터링 작업 실행시 리턴 값이 0이 아닌 -201 이여서 모니터링 에러가 리포팅 되었습니다.<br>즉 이는 timeout에 의한 메시지가 아닙니다.<br><br><br>[3] 아니라면 컨피그 부분에서 어떠한 값을 가지고 타임아웃 체크를 하는것인지요?<br><br>모니터링 timeout는 현재 설정하신 1200초로 확인합니다.<br><br><br>[4]아니면 모니터링 자체에 대한 에러로 보는게 맞는가요?<br><br>모니터링시 팬싱 디바이스의 리턴 값이 0이 아니어서 에러가 발생된 것으로 판단하였습니다.<br><br><br>[5] 이 부분도 궁금하네요... 리소스를 기동하려는 액션이 config 에서 설정이 되어 있나요? 설정이 되어 있따면 어떤 부분인지 말씀 부탁드립니다. <br><br>아래의 migration-threshold 설정에 의하여 모니터링 timeout 되기전에 최대로 3차례 재시도를 하게 됩니다.<br>        &lt;nvpair id=&quot;rsc_defaults-options-migration-threshold&quot; name=&quot;migration-threshold&quot; value=&quot;3&quot;/&gt;<br><br><br>[6]그리고 1000000 failures 라는것은 1000000 번 실패를 했다는 이야기인가요? 그리고 max=3은 무엇을 말하는것인지요?  저희가 컨피그 설정한 부분에서 어떠한 부분인지요?<br><br>이는 최대치를 도달할 경우 pacemaker가 failures 값은 INFINITY으로 설정하게 되는데 이때 해당 값을 수치로 1000000으로 설정하게 됩니다.<br>max=3은 [5]번에서 말씀 드린 migration-threshold 입니다.<br><br><br>- vmware_stonith1 리소스 failed 이슈 때문에 PIASCL02SL 노드 팬싱 작업 요청<br>([7] 이 액션 역시 어떤 컨피그에서 작동하는것인지 궁금합니다.)<br><br>이와 같은 action은 리소스 관련 옵션에 on-fail 에 의하여 결정되며 해당 값의 기본값은 fence 입니다.<br>참고문서:<br>https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/High_Availability_Add-On_Reference/s1-resourceoperate-HAAR.html<br><br><br>([8] 팬싱시키는 조건이 어떤 것인지 궁금합니다. 컨피그의 내용으로 설명 부탁드립니다. <br>[7] 번 답변 참고하시기 바랍니다.<br><br><br>[9]위의 흐름을 시간대로 설명 부탁드릴게요... vmware_soap_fence(or fence_ipmilan)의 네트워크나 디바이스가 장애가 발생하여도 fence는 발생 되지 않늦것으로 판단하고 있었습니다. 타임아웃값이나 retry값이 어떻게 적용되는지 궁금합니다. 설명 부탁드립다.<br><br>이번 팬싱 이슈는 팬싱 디바이스의 리소스가 모니터링에 실패하여 recover 작업을 진행시 팬싱 디바이스 stop 작업이 실패되어 팬싱 이슈가 발생된 것입니다.<br><br>- 팬싱 리소스 모니터링 작업이 0이 아닌 return 값을 받아 error 발생<br><br>Apr 16 17:10:20 [23122] PIASCL02SL stonith-ng:   notice: log_operation:<br>Operation 'monitor' [5431] for device 'vmware_stonith1' returned: -201 (Generic Pacemaker error)<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:    error: process_lrm_event:<br>Operation vmware_stonith1_monitor_1200000 (node=PIASCL02SL-HB, call=148, status=4, cib-update=280, confirmed=false) Error<br><br>- migration-threshold 설정에 따라 다시 모니터링 작업 시도<br><br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:     info: get_failcount_full:<br>vmware_stonith1 has failed 1 times on PIASCL02SL-HB<br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:     info: common_apply_stickiness:<br>vmware_stonith1 can fail 2 more times on PIASCL02SL-HB before being forced off<br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:     info: RecurringOp:<br> Start recurring monitor (1200s) for vmware_stonith1 on PIASCL02SL-HB<br><br>- 동시에 vmware_stonith1 이 FAILED 상태로 진입한것이 확인되어 pacemaker가 recover 작업 시도. 즉 stop/start 작업 실시<br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:     info: native_print:<br>vmware_stonith1<br>(stonith:fence_vmware_soap):<br>FAILED PIASCL02SL-HB<br>Apr 16 17:10:20 [21776] PIASCL02SL    pengine:   notice: LogActions:<br>Recover vmware_stonith1<br>(Started PIASCL02SL-HB)<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:   notice: te_rsc_command:<br>Initiating action 6: stop vmware_stonith1_stop_0 on PIASCL02SL-HB (local)<br><br>- 그리하여 vmware_stonith1_monitor 작업이 cancel 됨<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:     info: do_lrm_rsc_op:<br>Performing key=6:147:0:bd1787e5-49a9-41a7-b670-9701d76e2cbc op=vmware_stonith1_stop_0<br>Apr 16 17:10:20 [21774] PIASCL02SL       lrmd:     info: log_execute:<br>executing - rsc:vmware_stonith1 action:stop call_id:162<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:     info: process_lrm_event:<br>Operation vmware_stonith1_monitor_1200000: Cancelled (node=PIASCL02SL-HB, call=148, confirmed=true)<br><br>- stop 작업 성공<br><br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:   notice: process_lrm_event:<br>Operation vmware_stonith1_stop_0: ok (node=PIASCL02SL-HB, call=162, rc=0, cib-update=284, confirmed=true)<br><br>- start 작업이 time out 됨<br>Apr 16 17:10:20 [23124] PIASCL02SL       crmd:   notice: te_rsc_command:<br>Initiating action 30: start vmware_stonith1_start_0 on PIASCL02SL-HB (local)<br>Apr 16 17:11:40 [23124] PIASCL02SL       crmd:  warning: cib_action_update:<br>rsc_op 30: vmware_stonith1_start_0 on PIASCL02SL-HB timed out<br><br>- fail-count를 INFINITY로 설정<br>Apr 16 17:11:41 [23123] PIASCL02SL      attrd:     info: attrd_peer_update:     Setting fail-count-vmware_stonith1[PIASCL02SL-HB]: 1 -&gt; INFINITY from PIASCL02SL-HB<br><br>- vmware_stonith1 리소스가 어느 노드에서도 기동될수 없는것으로 판단 및 stop 작업 실시<br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: native_color:  Resource vmware_stonith1 cannot run anywhere<br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:   notice: LogActions:    Stop    vmware_stonith1 (PIASCL02SL-HB)<br><br>- stop 작업이 time out 되면서 vmware_stonith1 리소스가 failed 상태에 빠짐<br>Apr 16 17:13:01 [23124] PIASCL02SL       crmd:  warning: cib_action_update:     rsc_op 5: vmware_stonith1_stop_0 on PIASCL02SL-HB timed out<br>Apr 16 17:13:02 [23124] PIASCL02SL       crmd:     info: process_graph_event:   Detected action (149.5) vmware_stonith1_stop_0.-1=unknown error: failed<br><br>- 팬싱 작업 실시<br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: pe_fence_node: Node PIASCL02SL-HB will be fenced because of resource failure(s)<br><br><br>여기서 PIASCL01SL 노드 팬싱되기전 vmware_stonith1 리소스 기동에 성공된것이 확인됨<br>([10] 이 내용이 무엇을 의미하는지 잘 모르겠습니다. 팬싱전에 상대방 스토니스 리소스가 기동되었다는것은 문제 되었던 펜싱디바이스가 정상 복구 됐다는 말씀이신가요? 그로 인해 미치는 영향은 무엇인가요?)<br><br>해당 메시지는 문제가 되었던 팬싱 디바이스가 PIASCL01SL 노드가 팬싱되기전에 복구된것을 알리며<br>이에 의하여 노드와 팬싱 디바이스와의 연결에 일시적으로 문제가 발생되었음을 알수 있습니다.<br>따라서 리소스 모니터링 실패 원인 분석에는 17:13:17 이전에 노드와 vCenter 사이의 통신 이슈 및 vCenter에 어떤 이슈가 있는지를 분석해 보시면 됩니다. <br><br><br>[11] 아래와 같은 팬싱성공 여부가 확인되지 않는 상태는 PIASCL01SL에서도 발생되었습니다. 그런데 dcrm, pcrm 환경에서는 팬싱 신호를 보냈으나 팬싱 성공 여부가 확인이 되지 않았다는 말씀이 무슨 말씀이신지요?<br>Apr 16 17:13:37 [41204] DCRMCL02SL stonith-ng:     info: call_remote_stonith:   Requesting that DCRMCL02SL-HB perform op reboot DCRMCL01SL-HB with vmware_stonith1 for crmd.41610 (72s)<br>--&gt; 팬싱 작업에 대한 return 값 확인하지 못함<br><br>Apr 16 17:14:02 [13369] PIASCL01SL stonith-ng:     info: call_remote_stonith:<br>Requesting that PIASCL01SL-HB perform op reboot PIASCL02SL-HB with vmware_stonith2 for crmd.23124 (72s)<br>Apr 16 17:14:06 [53333] PCRMCL01SL stonith-ng:     info: call_remote_stonith:<br>Requesting that PCRMCL01SL-HB perform op reboot PCRMCL02SL-HB with vmware_stonith2 for crmd.5122 (72s)<br><br><br>[12] 위 내용 설명 부탁드리고<br>펜싱 디바이스가 문제되는 케이스를 시간대별로 설명 부탁드립니다.<br><br>[9]번 답변 참고하시기 바랍니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-20T08:15:45Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JJX1SIAX"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2017-04-19T17:17:34Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2017-04-19T17:17:34Z</b><br><br>[1] 최초 인지한 시간은 17시 04분 10초가 맞는지요?<br>Apr 16 17:04:10 PIASCL02SL fence_vmware_soap: Unable to connect/login to fencing device<br><br>[2] 모니터링이 실패된것이 맞다면  타임아웃에 의한 메시지인가요? 타임아웃이라면 아래에 보이는 컨피그의 어트리뷰트값의 1200S 값을 말하는것인지요? <br>Apr 16 17:10:20 [23122] PIASCL02SL stonith-ng:   notice: log_operation: Operation 'monitor' [5431] for device 'vmware_stonith1' returned: -201 (Generic Pacemaker error)<br><br>만약 그렇다면 최초 인지한시간은 20분전인 16시 50분 20초이어야 하는데... 그 당시의 메시지는 아무것도 없었습니다. <br><br>[3] 아니라면 컨피그 부분에서 어떠한 값을 가지고 타임아웃 체크를 하는것인지요?<br><br>[4]아니면 모니터링 자체에 대한 에러로 보는게 맞는가요?<br><br>==================================================================================================================================================================================<br>- 여러차례 vmware_stonith1 리소스를 기동하려 했으나 실패<br>([5] 이 부분도 궁금하네요... 리소스를 기동하려는 액션이 config 에서 설정이 되어 있나요? 설정이 되어 있따면 어떤 부분인지 말씀 부탁드립니다. <br>[6]그리고 1000000 failures 라는것은 1000000 번 실패를 했다는 이야기인가요? 그리고 max=3은 무엇을 말하는것인지요?  저희가 컨피그 설정한 부분에서 어떠한 부분인지요?)<br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: get_failcount_full:    vmware_stonith1 has failed INFINITY times on PIASCL02SL-HB<br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:  warning: common_apply_stickiness:       Forcing vmware_stonith1 away from PIASCL02SL-HB after 1000000 failures (max=3)<br><br>- vmware_stonith1 리소스 failed 이슈 때문에 PIASCL02SL 노드 팬싱 작업 요청<br>([7] 이 액션 역시 어떤 컨피그에서 작동하는것인지 궁금합니다.)<br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: unpack_rsc_op_failure: Processing failed op stop for vmware_stonith1 on PIASCL02SL-HB: unknown error (1)<br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: unpack_rsc_op_failure: Processing failed op stop for vmware_stonith1 on PIASCL02SL-HB: unknown error (1)<br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: pe_fence_node: Node PIASCL02SL-HB will be fenced because of resource failure(s)<br><br><br> Resource: vmware_stonith1 (class=stonith type=fence_vmware_soap)<br>  <br>Attributes: ipaddr=100.254.69.224 login=administrator@vsphere.local passwd=VMware1! ssl=1 ssl_insecure=1 action=reboot port=PIASCL01SL pcmk_host_list=PIASCL01SL-HB delay=15 pcmk_monitor_timeout=1200s <br>  <br>Operations: monitor interval=1200s (vmware_stonith1-monitor-interval-1200s)<br><br>==================================================================================================================================================================================<br><br>==================================================================================================================================================================================<br>- PIASCL01SL 노드에서 vmware_stonith2으로 PIASCL02SL 노드를 팬싱함<br>([8] 팬싱시키는 조건이 어떤 것인지 궁금합니다. 컨피그의 내용으로 설명 부탁드립니다. <br>제가 판단하건데 Attributes: ipaddr=100.254.69.224 login=administrator@vsphere.local passwd=VMware1! ssl=1 ssl_insecure=1 action=reboot port=PIASCL01SL pcmk_host_list=PIASCL01SL-HB delay=15 pcmk_monitor_timeout=1200s <br>에서 action=reboot 이 팬싱을 시키는 파라메터 값인가요?)<br><br>Apr 16 17:14:02 [13369] PIASCL01SL stonith-ng:     info: call_remote_stonith:<br>Requesting that PIASCL01SL-HB perform op reboot PIASCL02SL-HB with vmware_stonith2 for crmd.23124 (72s)<br><br>==================================================================================================================================================================================<br><br><br>[9]위의 흐름을 시간대로 설명 부탁드릴게요... vmware_soap_fence(or fence_ipmilan)의 네트워크나 디바이스가 장애가 발생하여도 fence는 발생 되지 않늦것으로 판단하고 있었습니다. 타임아웃값이나 retry값이 어떻게 적용되는지 궁금합니다. 설명 부탁드립다.<br><br><br>- 팬싱 성공 및 리소스 fail over 함<br>Apr 16 17:14:43 [13373] PIASCL01SL       crmd:   notice: tengine_stonith_notify:<br>Peer PIASCL02SL-HB was terminated (reboot) by PIASCL01SL-HB for PIASCL01SL-HB: OK (ref=daf29a96-8126-435a-a79f-1c0d65cdcd12) by client crmd.23124<br><br>- 여기서 PIASCL01SL 노드 팬싱되기전 vmware_stonith1 리소스 기동에 성공된것이 확인됨<br>([10] 이 내용이 무엇을 의미하는지 잘 모르겠습니다. 팬싱전에 상대방 스토니스 리소스가 기동되었다는것은 문제 되었던 펜싱디바이스가 정상 복구 됐다는 말씀이신가요? 그로 인해 미치는 영향은 무엇인가요?)<br>Apr 16 17:13:17 [23124] PIASCL02SL       crmd:     info: process_graph_event:   Detected action (147.30) vmware_stonith1_start_0.163=ok: arrived really late<br>======================<br><br><br>다른 두 클러스터 환경에서도 vmware_stonith1 리소스 failed 이슈가 발생된 노드가 부팅전 vmware_stonith1 리소스 기동에 <br>성공한것이 확인됩니다. 다만 dcrm, pcrm 환경에서는 팬싱 신호를 보냈으나 팬싱 성공 여부가 확인이 되지 않았고 상대 노드가 다운이<br>된것을 확인하여 fail over 작업을 진행한것이 확인 됩니다. 또한 팬싱된 노드가 부팅전 vmware_stonith1 리소스 기동에 성공된것이 확인됨<br><br>[11] 아래와 같은 팬싱성공 여부가 확인되지 않는 상태는 PIASCL01SL에서도 발생되었습니다. 그런데 dcrm, pcrm 환경에서는 팬싱 신호를 보냈으나 팬싱 성공 여부가 확인이 되지 않았다는 말씀이 무슨 말씀이신지요?<br>Apr 16 17:13:37 [41204] DCRMCL02SL stonith-ng:     info: call_remote_stonith:   Requesting that DCRMCL02SL-HB perform op reboot DCRMCL01SL-HB with vmware_stonith1 for crmd.41610 (72s)<br>--&gt; 팬싱 작업에 대한 return 값 확인하지 못함<br><br>Apr 16 17:14:02 [13369] PIASCL01SL stonith-ng:     info: call_remote_stonith:<br>Requesting that PIASCL01SL-HB perform op reboot PIASCL02SL-HB with vmware_stonith2 for crmd.23124 (72s)<br>Apr 16 17:14:06 [53333] PCRMCL01SL stonith-ng:     info: call_remote_stonith:<br>Requesting that PCRMCL01SL-HB perform op reboot PCRMCL02SL-HB with vmware_stonith2 for crmd.5122 (72s)<br><br>[12] 위 내용 설명 부탁드리고<br>펜싱 디바이스가 문제되는 케이스를 시간대별로 설명 부탁드립니다.<br>감사합니다.<br>번호별로 답변 부탁드릴게요<br><br><publishedDate>2017-04-19T17:17:34Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJP2aIAH"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2017-04-19T07:27:58Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2017-04-19T07:27:58Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>저희 폴러시에 따라 기술문의를 다시 생성해 주셔서 대단히 감사드립니다.<br><br>올려주신 3개의 클러스터 2-node 환경중 PIAS를 예를 들어 분석 결과를 안내 드립니다.<br><br>- 먼저, 16일 17:10:20 시점에 vmware_stonith1 모니터링이 실패된 것이 확인됨<br><br>Apr 16 17:10:20 [23122] PIASCL02SL stonith-ng:   notice: log_operation: Operation 'monitor' [5431] for device 'vmware_stonith1' returned: -201 (Generic Pacemaker error)<br><br>- 여러차례 vmware_stonith1 리소스를 기동하려 했으나 실패<br><br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:     info: get_failcount_full:    vmware_stonith1 has failed INFINITY times on PIASCL02SL-HB<br>Apr 16 17:11:41 [21776] PIASCL02SL    pengine:  warning: common_apply_stickiness:       Forcing vmware_stonith1 away from PIASCL02SL-HB after 1000000 failures (max=3)<br><br>- vmware_stonith1 리소스 failed 이슈 때문에 PIASCL02SL 노드 팬싱 작업 요청<br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: unpack_rsc_op_failure: Processing failed op stop for vmware_stonith1 on PIASCL02SL-HB: unknown error (1)<br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: unpack_rsc_op_failure: Processing failed op stop for vmware_stonith1 on PIASCL02SL-HB: unknown error (1)<br>Apr 16 17:13:02 [21776] PIASCL02SL    pengine:  warning: pe_fence_node: Node PIASCL02SL-HB will be fenced because of resource failure(s)<br><br>- PIASCL01SL 노드에서 vmware_stonith2으로 PIASCL02SL 노드를 팬싱함<br><br>Apr 16 17:14:02 [13369] PIASCL01SL stonith-ng:     info: call_remote_stonith:<br>Requesting that PIASCL01SL-HB perform op reboot PIASCL02SL-HB with vmware_stonith2 for crmd.23124 (72s)<br><br>- 팬싱 성공 및 리소스 fail over 함<br>Apr 16 17:14:43 [13373] PIASCL01SL       crmd:   notice: tengine_stonith_notify:<br>Peer PIASCL02SL-HB was terminated (reboot) by PIASCL01SL-HB for PIASCL01SL-HB: OK (ref=daf29a96-8126-435a-a79f-1c0d65cdcd12) by client crmd.23124<br><br>- 여기서 PIASCL01SL 노드 팬싱되기전 vmware_stonith1 리소스 기동에 성공된것이 확인됨<br><br>Apr 16 17:13:17 [23124] PIASCL02SL       crmd:     info: process_graph_event:   Detected action (147.30) vmware_stonith1_start_0.163=ok: arrived really late<br><br><br>다른 두 클러스터 환경에서도 vmware_stonith1 리소스 failed 이슈가 발생된 노드가 부팅전 vmware_stonith1 리소스 기동에 <br>성공한것이 확인됩니다. 다만 dcrm, pcrm 환경에서는 팬싱 신호를 보냈으나 팬싱 성공 여부가 확인이 되지 않았고 상대 노드가 다운이<br>된것을 확인하여 fail over 작업을 진행한것이 확인 됩니다. 또한 팬싱된 노드가 부팅전 vmware_stonith1 리소스 기동에 성공된것이 확인됨<br><br>Apr 16 17:13:37 [41204] DCRMCL02SL stonith-ng:     info: call_remote_stonith:   Requesting that DCRMCL02SL-HB perform op reboot DCRMCL01SL-HB with vmware_stonith1 for crmd.41610 (72s)<br>--&gt; 팬싱 작업에 대한 return 값 확인하지 못함<br><br>[41186] DCRMCL02SL corosyncnotice  [TOTEM ] A new membership (172.19.21.112:144) was formed. Members left: 1<br>[41186] DCRMCL02SL corosyncnotice  [TOTEM ] Failed to receive the leave message. failed: 1<br>[41186] DCRMCL02SL corosyncnotice  [QUORUM] Members[1]: 2<br>--&gt; 상대 노드가 다운된것을 감지함<br><br>종합해보면 이슈발생 시점에 일시적으로 팬싱 디바이스와의 연결이 되지 않은것으로 판단됩니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-19T07:27:58Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JJOjiIAH"><br>======================<br><b>생성계정 : 타임게이트, 타임게이트</b><br><b>생성날짜 : 2017-04-19T07:00:40Z</b><br><b>마지막 답변자 : 타임게이트, 타임게이트</b><br><b>마지막 수정 일자 : 2017-04-19T07:00:40Z</b><br><br>CASE 01832536 연장건입니다. <br>계정번호 5251314에서 진행하던 건입니다.<br><br><publishedDate>2017-04-19T07:00:40Z</publishedDate><createdByType>Customer</createdByType><br>======================<br></comments><br>