======================<br><b>생성계정 : hyangjun son</b><br><b>생성날짜 : 2018-03-12T08:27:47Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2018-04-04T10:05:16Z</b><br><b>id : 500A000000Zt5BCIAZ</b><br>======================<br><br><b><font size=15>
제목  : dtmsapp1, 2번 서버가 클러스터 구성되어있는데, 어떤이유에서인지 resource group이 2번 서버로 넘어갔습니다.
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>3/12일 16:10분 정도에 unknown에러와 함께 2번 서버로 클러스터가 넘어갔습니다.<br>(어떤 이유에서인지는 분석요청)<br><br>Mar 12 16:11:22 dtmsapp1 pengine[14037]:  warning: unpack_rsc_op_failure: Processing failed op m<br>onitor for rsc_lvm on dtmsapp1: unknown error (1)<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>redhat 6.7버전, Dell R730장비. <br>(두서버 같은 사양)<br><br>언제 문제가 발생했습니까? 이러한 문제가 자주 발생합니까? 반복적으로 발생합니까? 특정 시간에 발생합니까?<br><br>16:30분 쯤 업무담당자에게 전화연락으로 발생인지.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 6.7</b><br><b>타입  : Configuration issue</b><br><b>계정 번호  : 1596892</b><br><b>심각도  : 4 (Low)</b><br><hostname>dtmsapp1, dtmsapp2</hostname><br><br><br><comment id="a0aA000000Ku9bPIAR"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2018-03-19T06:10:36Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2018-03-19T06:10:36Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>1. warning: unpack_rsc_op_failure: Processing failed op monitor for rsc_lvm on dtmsapp1: unknown error (1)<br>이 메세지는  dtmsapp1   /var/log/messages 에서 보면 클러스터 문제나기전 몇일전 부터  꾸준히 나오고 있는 메세지 인데 이메세지는 무엇인가요?<br><br>상기의 메시지는 LVM 리소스를 모니터링 하면서 해당 리소스에 대한 모니터링에 대해서 시간 초과가 발생하여 출력된 메시지입니다.<br>상기 메시지 발생 원인은 이슈 분석시 추가적인 분석이 필요하지만 기존 이슈에 의하면 이와 같은 이슈가 시스템 로드가 높을때 <br>모니터링 프로세스가 규정된 시간내에 답변을 받지 못하여 발생되는 경우가 많습니다.<br>그리하여 앞서 안내하기를 모니터링 타임아웃 값은 기본으로 설정되어 있는 값 보다 더 높은 값(90 혹은 120)으로 늘리면 상기 <br>설명한 이슈가 발생하지 않을 것으로 판단하고 있습니다.<br># pcs resource update &lt;resource id&gt; op monitor timeout=120<br><br>2. <br>Mar 12 16:58:02 dtmsapp1 kernel: EXT4-fs (dm-18): warning: maximal mount count reached, running e2fsck is recommended<br>Mar 12 16:58:02 dtmsapp1 kernel: EXT4-fs (dm-18): mounted filesystem with ordered data mode. Opts:<br><br>상기와 같은 메시지가 출력될 경우에는 백업 작업을 진행후 fsck를 하시는것을 권장드립니다.<br>이는 상기와 같은 메시지가 발생시에는 해당 파일시스템에 알수 없는 이슈가 감지됨을 알리며<br>만일 장기간 fsck를 진행하지 않아 복귀 불가능한 상황이면 파일시스템 재구성이 필요하실수 <br>있으며 데이터 복귀가 불가능할수도 있습니다.<br>따라서 일정을 정하셔서 fsck를 진행하시는것을 권장드립니다.<br><br>&gt; tune2fs  -c  -1   /dev/mapper/vgvsp01-FILE_lv <br>실행할려고 하는데  상관없는지요?<br><br>테스트시 상기 명령어는 온라인으로 실행하셔도 적용이 되며 서비스에는 문제가 없습니다.<br>다만 이와 같이 설정하시면 파일시스템에 이슈가 발생시 바로 알수 없으므로 복귀 가능한<br>에러 발생시에도 제때에 복구하지 못하게 됩니다.<br><br>감사합니다.<br><br><publishedDate>2018-03-19T06:10:36Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000KtSQ8IAN"><br>======================<br><b>생성계정 : os, support</b><br><b>생성날짜 : 2018-03-15T06:50:53Z</b><br><b>마지막 답변자 : os, support</b><br><b>마지막 수정 일자 : 2018-03-15T06:50:53Z</b><br><br>답변감사합니다. <br>로그상의 내용을 보고 몇가지 추가 질문 드립니다.<br><br>1. warning: unpack_rsc_op_failure: Processing failed op monitor for rsc_lvm on dtmsapp1: unknown error (1)<br>이 메세지는  dtmsapp1   /var/log/messages 에서 보면 클러스터 문제나기전 몇일전 부터  꾸준히 나오고 있는 메세지 인데 이메세지는 무엇인가요?<br><br>2. 클러스터가 노드로 이동한뒤에 아래와 같은 메세지가 발생하였습니다.<br><br>Mar 12 16:58:02 dtmsapp1 kernel: EXT4-fs (dm-18): warning: maximal mount count reached, running e2fsck is recommended<br>Mar 12 16:58:02 dtmsapp1 kernel: EXT4-fs (dm-18): mounted filesystem with ordered data mode. Opts:<br><br>현재 클러스터는 ha-lvm 으로 구성되어 있어서  maximal count  값을 변경하고 싶습니다.<br>클러스터가  띄워진 상태에서  halvm 으로 구성된 마운트가  된 상태에서  lvm 볼륨에 <br><br>tune2fs  -c  -1   /dev/mapper/vgvsp01-FILE_lv <br>실행할려고 하는데  상관없는지요?<br><br>클러스터를 내리면 해당  VG 가 비활성화 되기 때문에 마운트 된 상태에서 진행할려고 합니다. 상관없는지요?<br><br><publishedDate>2018-03-15T06:50:53Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000KtQ6uIAF"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2018-03-15T02:06:05Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2018-03-15T02:06:05Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br>sosreport 및 제공 해주신 내용을 전문 엔지니어와 확인 내용을 업데이트 하도록 하겠습니다.<br><br>현재의 이슈는 LVM 리소스를 모니터링 하면서 해당 리소스에 대한 모니터링에 대해서 시간 초과가 발생이 하면서 리소스에 대해서 다른 노드로 pacemaker가 옮기는 과정을 진행 된것으로 판단 됩니다. <br>LVM모니터링 시간 초과를 이후에 상황에 방지하려면 모니터링 작업 시간 초과를 늘리는 것이 좋은 것으로 판단이 됩니다. 일부 환경에서는 기본 30초 제한 시간이 충분하지 않다는 것이 확인된 내용이 있습니다. <br><br>예를 들어, 백업 작업 중에 높은 CPU사용률 기간과 일치하는 리소스에 대한 시간 초과가 로그에서 확인되는 경우, 백업 작업이 실행되는 방식을 조정하여 백업과정에서 발생하는 workload로 인해 중요한 프로세스가 holding이 되는 경우가 발생하지 않도록 하는 방안이 필요 합니다.<br>또는 커널이 메모리 회수 중에 과도한 CPU사용량을 발생하면서 사용된 메모리 임계값을 넘을 때마다 시간 초과가 발생하면 시스템의 시스템 설정 및 메모리 사용 프로필을 조정하여 너무 많은 메모리가 사용되지 않도록 하는 방안이 필요 합니다.<br><br>제가 예를 들어 설명 드린 여러 상황에 대해서 아래의 매개 변수에 통해 기본으로 설정되어 있는 값 보다 더 높은 값(90 혹은 120)으로 늘리면 아래의 설명한 이슈가 발생하지 않을 것으로 판단하고 있습니다.<br>해당 명령은 아래와 같습니다.<br># pcs resource update &lt;resource id&gt; op monitor timeout=120<br><br>현재 설정 되어 있는 값은 sosreport를 토대로 30초 인것으로 확인 되었습니다.<br>...<br>  Resource: rsc_lvm (class=ocf provider=heartbeat type=LVM)<br>   Attributes: volgrpname=vgvsp01 exclusive=true<br>   Operations: start interval=0s timeout=30 (rsc_lvm-start-interval-0s)<br>               stop interval=0s timeout=30 (rsc_lvm-stop-interval-0s)<br>               monitor interval=10 timeout=30 (rsc_lvm-monitor-interval-10) &lt;------ 30 초<br>...<br><br>또한 아래의 명령을 토대로 시스템에서 확인이 가능합니다. <br># pcs resource show --full<br> Resource: vg01-r (class=ocf provider=heartbeat type=LVM)<br>  Attributes: volgrpname=vg01 exclusive=true<br>  Operations: start interval=0s timeout=30 (vg01-r-start-interval-0s)<br>              stop interval=0s timeout=30 (vg01-r-stop-interval-0s)<br>              monitor enabled=true interval=60s (vg01-r-monitor-interval-60s)<br> Resource: vg01-lv01-fs (class=ocf provider=heartbeat type=Filesystem)<br>  Attributes: device=/dev/mapper/vg01-lv01 directory=/vg01-lv01/ fstype=xfs<br>  Meta Attrs: interval=3s resource-stickiness=1000 <br>  Operations: start interval=0s timeout=60 (vg01-lv01-fs-start-interval-0s)<br>              stop interval=0s timeout=60 (vg01-lv01-fs-stop-interval-0s)<br>              monitor interval=60s timeout=2s (vg01-lv01-fs-monitor-interval-60s)<br><br>또한, 아래는 제공 해주신 자료를 토대로 전문 엔지니어와 해당 리소스가 다른 노드로 옮기는 과정에 대해 확인 된 내용 입니다.<br>LVM monitoring timeout:<br><br>Mar 12 16:29:29 [14035] dtmsapp1       lrmd:  warning: child_timeout_callback:  rsc_lvm_monitor_10000 process (PID 108020) timed out<br>Mar 12 16:29:29 [14035] dtmsapp1       lrmd:  warning: operation_finished:      rsc_lvm_monitor_10000:108020 - timed out after 30000ms<br><br>This is already 2nd failure:<br><br>Mar 12 16:29:31 [14037] dtmsapp1    pengine:     info: get_failcount_full:      rsc_lvm has failed 2 times on dtmsapp1<br>Mar 12 16:29:31 [14037] dtmsapp1    pengine:     info: common_apply_stickiness:         rsc_lvm can fail 1 more times on dtmsapp1 before being forced off<br><br>Due to  migration-threshold: 3 parameter in cluster configuration any resource can fail 3 times before it is migrated to other node. Here is 3rd failure:<br><br>Mar 12 16:29:32 [14037] dtmsapp1    pengine:  warning: unpack_rsc_op_failure:   Processing failed op monitor for rsc_lvm on dtmsapp1: unknown error (1)<br>Mar 12 16:29:32 [14037] dtmsapp1    pengine:     info: get_failcount_full:      rsc_lvm has failed 3 times on dtmsapp1<br><br>Pacemaker moved the resource to node 2:<br><br>Mar 12 16:29:32 [14037] dtmsapp1    pengine:  warning: common_apply_stickiness:         Forcing rsc_lvm away from dtmsapp1 after 3 failures (max=3)<br><br><br>Node 2 activated the resource:<br><br>Mar 12 16:29:40 dtmsapp2 LVM(rsc_lvm)[104478]: INFO: Reading all physical volumes. This may take a while... Found volume group &quot;vgvsp01&quot; using metadata type lvm2 Found volume group &quot;vg00&quot; using metadata type lvm2<br>Mar 12 16:29:40 dtmsapp2 LVM(rsc_lvm)[104478]: INFO: New tag &quot;pacemaker&quot; added to vgvsp01<br>Mar 12 16:29:40 dtmsapp2 LVM(rsc_lvm)[104478]: INFO: 1 logical volume(s) in volume group &quot;vgvsp01&quot; now active<br><br>Then all other resources are started on node 2 correctly. <br><br><br>After some time it pacemaker is stopped:<br><br>Mar 12 16:57:11 dtmsapp2 pacemaker: Waiting for shutdown of managed resources<br><br>However this looks like manual shutdown and not fencing.<br><br>감사합니다.<br><br><publishedDate>2018-03-15T02:06:05Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000LuZaZIAV"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2018-03-13T03:20:27Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2018-03-13T03:20:27Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>LVM 리소스가 timeout된 원인은 아래의 문서의 &lt;Diagnostic Steps&gt;와 같은 방법으로 추가적인<br>원인 분석이 필요하며 이와 같은 이슈는 모니터링 타임아웃 값을 증가하셔서 회피하실수 있으십니다.<br><br>    # pcs resource update &lt;resource id&gt; op monitor timeout=60<br><br><br>Why do LVM monitor operations time out and fail with unknown error (1)?<br>https://access.redhat.com/solutions/3110711<br><br>감사합니다.<br><br><publishedDate>2018-03-13T03:20:27Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br>(어떤 이유에서인지는 분석요청)<br><br>Mar 12 16:11:22 dtmsapp1 pengine[14037]:  warning: unpack_rsc_op_failure: Processing failed op m<br>onitor for rsc_lvm on dtmsapp1: unknown error (1)</issue><environment>redhat 6.7버전, Dell R730장비. <br>(두서버 같은 사양)</environment><periodicityOfIssue>16:30분 쯤 업무담당자에게 전화연락으로 발생인지.</periodicityOfIssue><cep>false</cep></case>