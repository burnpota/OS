======================<br><b>생성계정 : Seung-Pil Kim</b><br><b>생성날짜 : 2016-07-09T07:36:33Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2016-07-30T10:04:59Z</b><br><b>id : 500A000000UpsgWIAR</b><br>======================<br><br><b><font size=15>
제목  : [삼성화재][보험ERP][가동계] dssalp01 - system hang-up ( crash ) unexpectly
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>1) SYSTEM HANG ( CRASH ) estimation time<br>   - Sat Jul 9 09:20:32 KST<br>2) This system is a node1 of 2 node HA with pacemaker.<br>3) Kdump service has configured, but vmcore file is not found after &quot;dssalp01&quot; system rebooting.<br><br>Need a analysis of root cause.<br>What's the root cause?<br><br>-----------------------------------------------------------------------------------------------<br>SYSTEM INFO - dssalp01<br>-----------------------------------------------------------------------------------------------<br># sar<br>09:20:01        all      8.85      0.00      1.46      0.02      0.00     89.68<br>Average:        all      0.46      0.00      0.47      0.01      0.00     99.06<br><br>09:28:05          LINUX RESTART<br><br>09:29:01        CPU     %user     %nice   %system   %iowait    %steal     %idle<br>09:30:01        all      0.29      0.00      0.62      0.12      0.00     98.97<br>09:31:01        all      4.09      0.00      0.70      0.05      0.00     95.16<br>======================<br><br># cat /var/log/messages<br>Jul  9 03:07:03 dssalp01 rhsmd: In order for Subscription Manager to provide your system with updates, your system must be registered with the Customer Portal. Please enter your Red Hat login to ensure your system is up-to-date.<br>Jul  9 09:28:17 dssalp01 kernel: imklog 5.8.10, log source = /proc/kmsg started.<br>Jul  9 09:28:17 dssalp01 rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;5.8.10&quot; x-pid=&quot;9083&quot; x-info=&quot;http://www.rsyslog.com&quot;] start<br><br>-----------------------------------------------------------------------------------------------<br>SYSTEM INFO - dssalp02<br>-----------------------------------------------------------------------------------------------<br># cat /var/log/messages<br><br>Jul  9 09:20:32 dssalp02 corosync[133378]:   [TOTEM ] A processor failed, forming new configuration.<br>Jul  9 09:20:33 dssalp02 corosync[133378]:   [QUORUM] Members[1]: 2<br>Jul  9 09:20:33 dssalp02 corosync[133378]:   [TOTEM ] A processor joined or left the membership and a new membership was formed.<br>Jul  9 09:20:33 dssalp02 crmd[133636]:   notice: crm_update_peer_state: cman_event_callback: Node dssalp01-HB[1] - state is now lost (was member)<br>Jul  9 09:20:33 dssalp02 crmd[133636]:  warning: match_down_event: No match for shutdown action on dssalp01-HB<br>Jul  9 09:20:33 dssalp02 crmd[133636]:   notice: peer_update_callback: Stonith/shutdown of dssalp01-HB not matched<br>Jul  9 09:20:33 dssalp02 pacemakerd[133625]:   notice: crm_update_peer_state: cman_event_callback: Node dssalp01-HB[1] - state is now lost (was member)<br>Jul  9 09:20:33 dssalp02 corosync[133378]:   [CPG   ] chosen downlist: sender r(0) ip(192.168.25.102) r(1) ip(42.1.231.102) ; members(old:2 left:1)<br>Jul  9 09:20:33 dssalp02 crmd[133636]:   notice: do_state_transition: State transition S_IDLE -&gt; S_INTEGRATION [ input=I_NODE_JOIN cause=C_FSA_INTERNAL origin=check_join_state ]<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:   notice: crm_update_peer_state: st_peer_update_callback: Node dssalp01-HB[1] - state is now lost (was member)<br>Jul  9 09:20:33 dssalp02 corosync[133378]:   [MAIN  ] Completed service synchronization, ready to provide service.<br>Jul  9 09:20:33 dssalp02 attrd[133634]:   notice: attrd_local_callback: Sending full refresh (origin=crmd)<br>Jul  9 09:20:33 dssalp02 attrd[133634]:   notice: attrd_trigger_update: Sending flush op to all hosts for: shutdown (0)<br>Jul  9 09:20:33 dssalp02 crmd[133636]:  warning: match_down_event: No match for shutdown action on dssalp01-HB<br>Jul  9 09:20:33 dssalp02 crmd[133636]:   notice: peer_update_callback: Stonith/shutdown of dssalp01-HB not matched<br>Jul  9 09:20:33 dssalp02 cib[133631]:   notice: crm_update_peer_state: cib_peer_update_callback: Node dssalp01-HB[1] - state is now lost (was member)<br>Jul  9 09:20:33 dssalp02 cib[133631]:   notice: crm_reap_dead_member: Removing dssalp01-HB/1 from the membership list<br>Jul  9 09:20:33 dssalp02 cib[133631]:   notice: reap_crm_member: Purged 1 peers with id=1 and/or uname=(null) from the membership cache<br>Jul  9 09:20:33 dssalp02 kernel: dlm: closing connection to node 1<br>Jul  9 09:20:33 dssalp02 attrd[133634]:   notice: attrd_trigger_update: Sending flush op to all hosts for: probe_complete (true)<br>Jul  9 09:20:33 dssalp02 fenced[133434]: fencing node dssalp01-HB<br>Jul  9 09:20:33 dssalp02 attrd[133634]:   notice: attrd_trigger_update: Sending flush op to all hosts for: pingd (10)<br>Jul  9 09:20:33 dssalp02 fence_pcmk[21748]: Requesting Pacemaker fence dssalp01-HB (reset)<br>Jul  9 09:20:33 dssalp02 stonith_admin[21749]:   notice: crm_log_args: Invoked: stonith_admin --reboot dssalp01-HB --tolerance 5s --tag cman<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:   notice: handle_request: Client stonith_admin.cman.21749.eeb2c632 wants to fence (reboot) 'dssalp01-HB' with device '(any)'<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:   notice: initiate_remote_stonith_op: Initiating remote operation reboot for dssalp01-HB: 377332a8-8d80-480b-8329-d5489c67df1b (0)<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:   notice: can_fence_host_with_device: kdump_stonith can fence (reboot) dssalp01-HB: static-list<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:   notice: can_fence_host_with_device: ipmilan_stonith1 can fence (reboot) dssalp01-HB: static-list<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:  warning: stonith_device_execute: Agent 'fence_kdump' does not advertise support for 'reboot', performing 'off' action instead<br>Jul  9 09:20:33 dssalp02 fence_kdump[21751]: waiting for message from '192.168.25.101'<br>Jul  9 09:22:33 dssalp02 stonith-ng[133632]:   notice: stonith_action_async_done: Child process 22470 performing action 'off' timed out with signal 15<br>Jul  9 09:22:33 dssalp02 stonith-ng[133632]:    error: log_operation: Operation 'reboot' [22470] (call 2 from stonith_admin.cman.21749) for host 'dssalp01-HB' with device 'kdump_stonith' returned: -62 (Timer expired)<br>Jul  9 09:22:33 dssalp02 stonith-ng[133632]:   notice: process_remote_stonith_exec: Call to kdump_stonith for dssalp01-HB on behalf of stonith_admin.cman.21749@dssalp02-HB: Timer expired (-62)<br>Jul  9 09:23:02 dssalp02 stonith-ng[133632]:   notice: log_operation: Operation 'reboot' [23032] (call 2 from stonith_admin.cman.21749) for host 'dssalp01-HB' with device 'ipmilan_stonith1' returned: 0 (OK)<br>Jul  9 09:23:02 dssalp02 stonith-ng[133632]:   notice: process_remote_stonith_exec: Call to ipmilan_stonith1 for dssalp01-HB on behalf of stonith_admin.cman.21749@dssalp02-HB: OK (0)<br>Jul  9 09:23:02 dssalp02 stonith-ng[133632]:  warning: get_xpath_object: No match for //@st_delegate in /st-reply<br>Jul  9 09:23:02 dssalp02 stonith-ng[133632]:   notice: remote_op_done: Operation reboot of dssalp01-HB by dssalp02-HB for stonith_admin.cman.21749@dssalp02-HB.377332a8: OK<br>Jul  9 09:23:02 dssalp02 stonith-ng[133632]:   notice: remote_op_done: Operation reboot of dssalp01-HB by dssalp02-HB for crmd.133636@dssalp02-HB.dce7b578: OK<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Peer dssalp01-HB was terminated (reboot) by dssalp02-HB for dssalp02-HB: OK (ref=377332a8-8d80-480b-8329-d5489c67df1b) by client stonith_admin.cman.21749<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Notified CMAN that 'dssalp01-HB' is now fenced<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Confirmed CMAN fencing event for 'dssalp01-HB'<br>...<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Peer dssalp01-HB was terminated (reboot) by dssalp02-HB for dssalp02-HB: OK (ref=dce7b578-3457-4828-acbb-c4e9e5e15771) by client crmd.133636<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Notified CMAN that 'dssalp01-HB' is now fenced<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Confirmed CMAN fencing event for 'dssalp01-HB'<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: run_graph: Transition 5467 (Complete=1, Pending=0, Fired=0, Skipped=14, Incomplete=1, Source=/var/lib/pacemaker/pengine/pe-warn-6.bz2): Stopped<br>Jul  9 09:23:02 dssalp02 fenced[133434]: fence dssalp01-HB success<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 6.5</b><br><b>계정 번호  : 1596892</b><br><b>심각도  : 3 (Normal)</b><br><br><br><folderNumber>74166</folderNumber><br><comment id="a0aA000000HTpPMIA1"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-07-15T07:55:43Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-07-15T07:55:42Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>문의 주시내용에 대해서 설명을 드리면 우선 token의 timeout은 현재 5000ms (5 sec) 입니다.<br><br>그리고.. 해당 token을 확인하기 위해서 udp로 multicast를 일반적으로 이용하게 되며, 현재 retrans는 4번이 설정되어 있으며 해당 retrans는 token timeout 5초안에 4번을 나눠서 패킷을 보내게 되면 이중에 하나가 성공하면 됩니다.<br><br>retransmits before loss (4 retrans) <br><br><br>결론적으로, token의 타임아웃은 5000ms로 현재설정되었다고 보시면 됩니다.<br>======================<br>그리고.. 현재 재차 발생한 건에 대한 sosreport를 보내주시면 로그를 다시 검토하도록 하겠습니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-07-15T07:55:42Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HTYlCIAX"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-07-14T01:55:33Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-07-14T01:55:33Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>문의주신 내용에 대해서 현재 몇 가지 확인중에 있으며, 확인하여 같이 답변 드리도록 하겠습니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-07-14T01:55:33Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HTG7VIAX"><br>======================<br><b>생성계정 : 이, 주호</b><br><b>생성날짜 : 2016-07-13T02:34:43Z</b><br><b>마지막 답변자 : 이, 주호</b><br><b>마지막 수정 일자 : 2016-07-13T02:34:43Z</b><br><br>문의드립니다.<br>- 추가적으로 해당 시점의 sar데이터를 분석한 결과, 문제가 발생하는 시점 전으로 갑작스러운 workload 부하가 있었던 것으로 보이고 또한 이 현상으로 paging activity가 상당히 증가하는 것으로 보이며, 이러한 현상이 순간적으로 시스템이 클러스터와의 통신을 해야하는 시점에 영향을 주었을 가능성도 배제할 수 없는 상황입니다.<br> =&gt; 해당 페이지 증가관련은 메모리와 Disk 간 I/O 증가로 이해하면 되는지요?<br><br><br>1. 현재 interrunpt가 골고루 분배되어 처리할 수 있도록 irqbalance 기능을 활성화<br> =&gt; 현재는 interrupt 가 분산되지 않는 것인지와 그 판단을 어떻게 하셨는지 궁금합니다.<br>       추가로 해당 기능을 사용하면 어떤것이 개선되고 적용방법 및 리부팅 필요유무를 가이드 부탁드립니다.<br><br>2. totem token timeout 변경 5초 -&gt; 10초 <br>현재 totem token는 5000 ms(5초)로 설정되어 있는 상태입니다. 특별한 구조상의 이유가 있었을 것으로 보이나, 기본 RHEL6에서 token timout 기본값은 10초임에 따라, 현재 5초의 설정을 10초로 변경하는 것에 대해서 검토해 보시는 것에 대해서 제안드립니다.<br> =&gt;  해당 파라미터의 로직과 Cluster Time-out 체크 시간과의 관계를 문의드립니다.<br>        해당 값을 변경하기 전과 변경 후 전체 Time-out 값의 전 후  차이를 문의드립니다.<br><br><publishedDate>2016-07-13T02:34:43Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HT4h4IAD"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-07-12T13:19:09Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-07-13T01:23:11Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다<br><br>이번 클러스터 시스템에서 dssalp01 노드가 리부팅된 것에 대해서 sosreport 데이터를 분석한 내용을 드립니다.<br><br><br>* dssalp01 리부팅된 시점<br>7/9일 09:20:33에 dssalp02 노드에서 dssalp01노드를 펜싱한 것으로 분석됩니다.<br><br><br>* 펜싱원인<br>- dssalp02 노드에서 dssalp01 노드와 클러스를 구성하는데 있어서 충족을 못하는 조건이 발생함에 따라 dssalp01 노드가 이상이 있다고 판단되어 해당 노드를 펜싱을 하게됨.<br><br><br>Jul 09 09:09:57 [133636] dssalp02       crmd:   notice: do_state_transition:    State transition S_TRANSITION_ENGINE -&gt; S_IDLE [ input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd ]<br>Jul 09 09:20:32 corosync [TOTEM ] A processor failed, forming new configuration.<br>Jul 09 09:20:33 corosync [QUORUM] Members[1]: 2<br><br>May 13 11:23:27 fenced fenced 3.0.12.1 started<br>Jul 09 09:20:33 fenced fencing node dssalp01-HB<br>Jul 09 09:23:02 fenced fence dssalp01-HB success<br><br><br>* 당시 dssalp01 노드에 대한 분석<br><br>- 우선 dssalp01의 로그를 분석한 결과, 09:20:02분에 일부 로그를 출력을 하는 과정에서 시스템의 어떠한 문제로 인하여 제대로 출력을 완료하지 못한 상황으로 시스템이 hang 또는 갑작스러운 workload에 시스템이 비정상적으로 보이는 현상이 발생된 것으로 분석됩니다.<br> <br>Jul 09 09:20:02 [90238] dssalp01 stonith-ng:     &lt;--- this is latest message on node 1 - the message is not complete so either system was not able to log anything due to load/hang <br>Jul 09 10:07:43 corosync [MAIN  ] Corosync Cluster Engine ('1.4.7'): started and ready to provide service.  &lt;--- this is corosync starting so very likely after reboot<br><br><br>- 추가적으로 해당 시점의 sar데이터를 분석한 결과, 문제가 발생하는 시점 전으로 갑작스러운 workload 부하가 있었던 것으로 보이고 또한 이 현상으로 paging activity가 상당히 증가하는 것으로 보이며, 이러한 현상이 순간적으로 시스템이 클러스터와의 통신을 해야하는 시점에 영향을 주었을 가능성도 배제할 수 없는 상황입니다.<br><br>12:00:01 AM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff<br>09:18:01 AM     48.12  18412.90   4759.02      0.00   2773.17      0.00      0.00      0.00      0.00<br>09:19:01 AM     47.70   5475.92   8696.18      0.00   2630.79      0.00      0.00      0.00      0.00<br>09:20:01 AM     48.09  53044.41   3946.41      0.00   6380.83      0.00   7254.27   3627.13     50.00  &lt;----<br>======================<br>* 향후 동일한 현상 대응을 위해 필요한 검토사항<br><br>1. 현재 interrunpt가 골고루 분배되어 처리할 수 있도록 irqbalance 기능을 활성화<br>2. totem token timeout 변경 5초 -&gt; 10초 <br>현재 totem token는 5000 ms(5초)로 설정되어 있는 상태입니다. 특별한 구조상의 이유가 있었을 것으로 보이나, 기본 RHEL6에서 token timout 기본값은 10초임에 따라, 현재 5초의 설정을 10초로 변경하는 것에 대해서 검토해 보시는 것에 대해서 제안드립니다.<br>======================<br>결론적으로,<br>- dssalp01 노드가 리부팅이 된 원인은 두 노드간에 원활한 통신이 되지 않는 것으로 보이는 클러스터 구성의 조건에 영향을 받아서 dssalp02노드로 부터의 펜싱에 의해서 리부팅이 된 것으로 보이며,<br>- 당시 dssalp01노드는 알수없는 이유로부터의 시스템 hang 또는 갑작스러운 과도한 workload로 인하여 시스템이 hang과 같은 현상으로 발생했을 것으로 추정됩니다.<br>- 그리고 이러한 추정에서 향후 고려가 필요한 것으로는 token의 timeout을 현재 5초에서 10초로의 수정 그리고 irqbalance로 현재 하나의 cpu에 쏠리는 interrupt를 해소하는 것에 대해서 겁토해 보시는 것을 제안드립니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-07-12T13:19:09Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HTCagIAH"><br>======================<br><b>생성계정 : 이, 주호</b><br><b>생성날짜 : 2016-07-12T23:25:37Z</b><br><b>마지막 답변자 : 이, 주호</b><br><b>마지막 수정 일자 : 2016-07-12T23:25:37Z</b><br><br>. HP perf tool 로 현재 성능 데이트를 쌓고 있는데, 해당 Data 확인 시 CPU Priority queque 가 2개 노드 모두 높은 상태이고 1호기도 지속적으로 증가하고 있는 것으로 보입니다. 관련하여 원인 및 OS hang 유발과 관련이 있는지 확인이 필요해 보입니다. (SAP DS 업무 구동 중)<br><br>We are using HP perf tool on this two nodes. When I confirm that performance data,  I can see high values of CPU Priority Queue and continually increasing this value.<br>I wonder what cause of this situation and how to fix it. Also it need to check relation between OS hang and High value of CPU Priority Queue.<br><br><publishedDate>2016-07-12T23:25:37Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HSyIiIAL"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-07-12T02:01:59Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-07-12T02:01:58Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>현재 본 케이스와 관련되어 로그들을 다양하게 분석하는데 시간이 소요되고 있습니다.<br>분석을 하는데로 바로 정리하여 업데이트 드리도록 하겠습니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-07-12T02:01:58Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HSiFfIAL"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-07-11T01:09:28Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-07-11T01:09:28Z</b><br><br>안녕하세요,<br>Red Hat Technical Account Manager 한진구 입니다.<br><br>우선 보내주신 sosreport를 검토하고 다시 업데이트 드리도록 하겠습니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-07-11T01:09:28Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br>   - Sat Jul 9 09:20:32 KST<br>2) This system is a node1 of 2 node HA with pacemaker.<br>3) Kdump service has configured, but vmcore file is not found after &quot;dssalp01&quot; system rebooting.<br><br>Need a analysis of root cause.<br>What's the root cause?<br><br>-----------------------------------------------------------------------------------------------<br>SYSTEM INFO - dssalp01<br>-----------------------------------------------------------------------------------------------<br># sar<br>09:20:01        all      8.85      0.00      1.46      0.02      0.00     89.68<br>Average:        all      0.46      0.00      0.47      0.01      0.00     99.06<br><br>09:28:05          LINUX RESTART<br><br>09:29:01        CPU     %user     %nice   %system   %iowait    %steal     %idle<br>09:30:01        all      0.29      0.00      0.62      0.12      0.00     98.97<br>09:31:01        all      4.09      0.00      0.70      0.05      0.00     95.16<br>======================<br><br># cat /var/log/messages<br>Jul  9 03:07:03 dssalp01 rhsmd: In order for Subscription Manager to provide your system with updates, your system must be registered with the Customer Portal. Please enter your Red Hat login to ensure your system is up-to-date.<br>Jul  9 09:28:17 dssalp01 kernel: imklog 5.8.10, log source = /proc/kmsg started.<br>Jul  9 09:28:17 dssalp01 rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;5.8.10&quot; x-pid=&quot;9083&quot; x-info=&quot;http://www.rsyslog.com&quot;] start<br><br>-----------------------------------------------------------------------------------------------<br>SYSTEM INFO - dssalp02<br>-----------------------------------------------------------------------------------------------<br># cat /var/log/messages<br><br>Jul  9 09:20:32 dssalp02 corosync[133378]:   [TOTEM ] A processor failed, forming new configuration.<br>Jul  9 09:20:33 dssalp02 corosync[133378]:   [QUORUM] Members[1]: 2<br>Jul  9 09:20:33 dssalp02 corosync[133378]:   [TOTEM ] A processor joined or left the membership and a new membership was formed.<br>Jul  9 09:20:33 dssalp02 crmd[133636]:   notice: crm_update_peer_state: cman_event_callback: Node dssalp01-HB[1] - state is now lost (was member)<br>Jul  9 09:20:33 dssalp02 crmd[133636]:  warning: match_down_event: No match for shutdown action on dssalp01-HB<br>Jul  9 09:20:33 dssalp02 crmd[133636]:   notice: peer_update_callback: Stonith/shutdown of dssalp01-HB not matched<br>Jul  9 09:20:33 dssalp02 pacemakerd[133625]:   notice: crm_update_peer_state: cman_event_callback: Node dssalp01-HB[1] - state is now lost (was member)<br>Jul  9 09:20:33 dssalp02 corosync[133378]:   [CPG   ] chosen downlist: sender r(0) ip(192.168.25.102) r(1) ip(42.1.231.102) ; members(old:2 left:1)<br>Jul  9 09:20:33 dssalp02 crmd[133636]:   notice: do_state_transition: State transition S_IDLE -&gt; S_INTEGRATION [ input=I_NODE_JOIN cause=C_FSA_INTERNAL origin=check_join_state ]<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:   notice: crm_update_peer_state: st_peer_update_callback: Node dssalp01-HB[1] - state is now lost (was member)<br>Jul  9 09:20:33 dssalp02 corosync[133378]:   [MAIN  ] Completed service synchronization, ready to provide service.<br>Jul  9 09:20:33 dssalp02 attrd[133634]:   notice: attrd_local_callback: Sending full refresh (origin=crmd)<br>Jul  9 09:20:33 dssalp02 attrd[133634]:   notice: attrd_trigger_update: Sending flush op to all hosts for: shutdown (0)<br>Jul  9 09:20:33 dssalp02 crmd[133636]:  warning: match_down_event: No match for shutdown action on dssalp01-HB<br>Jul  9 09:20:33 dssalp02 crmd[133636]:   notice: peer_update_callback: Stonith/shutdown of dssalp01-HB not matched<br>Jul  9 09:20:33 dssalp02 cib[133631]:   notice: crm_update_peer_state: cib_peer_update_callback: Node dssalp01-HB[1] - state is now lost (was member)<br>Jul  9 09:20:33 dssalp02 cib[133631]:   notice: crm_reap_dead_member: Removing dssalp01-HB/1 from the membership list<br>Jul  9 09:20:33 dssalp02 cib[133631]:   notice: reap_crm_member: Purged 1 peers with id=1 and/or uname=(null) from the membership cache<br>Jul  9 09:20:33 dssalp02 kernel: dlm: closing connection to node 1<br>Jul  9 09:20:33 dssalp02 attrd[133634]:   notice: attrd_trigger_update: Sending flush op to all hosts for: probe_complete (true)<br>Jul  9 09:20:33 dssalp02 fenced[133434]: fencing node dssalp01-HB<br>Jul  9 09:20:33 dssalp02 attrd[133634]:   notice: attrd_trigger_update: Sending flush op to all hosts for: pingd (10)<br>Jul  9 09:20:33 dssalp02 fence_pcmk[21748]: Requesting Pacemaker fence dssalp01-HB (reset)<br>Jul  9 09:20:33 dssalp02 stonith_admin[21749]:   notice: crm_log_args: Invoked: stonith_admin --reboot dssalp01-HB --tolerance 5s --tag cman<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:   notice: handle_request: Client stonith_admin.cman.21749.eeb2c632 wants to fence (reboot) 'dssalp01-HB' with device '(any)'<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:   notice: initiate_remote_stonith_op: Initiating remote operation reboot for dssalp01-HB: 377332a8-8d80-480b-8329-d5489c67df1b (0)<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:   notice: can_fence_host_with_device: kdump_stonith can fence (reboot) dssalp01-HB: static-list<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:   notice: can_fence_host_with_device: ipmilan_stonith1 can fence (reboot) dssalp01-HB: static-list<br>Jul  9 09:20:33 dssalp02 stonith-ng[133632]:  warning: stonith_device_execute: Agent 'fence_kdump' does not advertise support for 'reboot', performing 'off' action instead<br>Jul  9 09:20:33 dssalp02 fence_kdump[21751]: waiting for message from '192.168.25.101'<br>Jul  9 09:22:33 dssalp02 stonith-ng[133632]:   notice: stonith_action_async_done: Child process 22470 performing action 'off' timed out with signal 15<br>Jul  9 09:22:33 dssalp02 stonith-ng[133632]:    error: log_operation: Operation 'reboot' [22470] (call 2 from stonith_admin.cman.21749) for host 'dssalp01-HB' with device 'kdump_stonith' returned: -62 (Timer expired)<br>Jul  9 09:22:33 dssalp02 stonith-ng[133632]:   notice: process_remote_stonith_exec: Call to kdump_stonith for dssalp01-HB on behalf of stonith_admin.cman.21749@dssalp02-HB: Timer expired (-62)<br>Jul  9 09:23:02 dssalp02 stonith-ng[133632]:   notice: log_operation: Operation 'reboot' [23032] (call 2 from stonith_admin.cman.21749) for host 'dssalp01-HB' with device 'ipmilan_stonith1' returned: 0 (OK)<br>Jul  9 09:23:02 dssalp02 stonith-ng[133632]:   notice: process_remote_stonith_exec: Call to ipmilan_stonith1 for dssalp01-HB on behalf of stonith_admin.cman.21749@dssalp02-HB: OK (0)<br>Jul  9 09:23:02 dssalp02 stonith-ng[133632]:  warning: get_xpath_object: No match for //@st_delegate in /st-reply<br>Jul  9 09:23:02 dssalp02 stonith-ng[133632]:   notice: remote_op_done: Operation reboot of dssalp01-HB by dssalp02-HB for stonith_admin.cman.21749@dssalp02-HB.377332a8: OK<br>Jul  9 09:23:02 dssalp02 stonith-ng[133632]:   notice: remote_op_done: Operation reboot of dssalp01-HB by dssalp02-HB for crmd.133636@dssalp02-HB.dce7b578: OK<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Peer dssalp01-HB was terminated (reboot) by dssalp02-HB for dssalp02-HB: OK (ref=377332a8-8d80-480b-8329-d5489c67df1b) by client stonith_admin.cman.21749<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Notified CMAN that 'dssalp01-HB' is now fenced<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Confirmed CMAN fencing event for 'dssalp01-HB'<br>...<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Peer dssalp01-HB was terminated (reboot) by dssalp02-HB for dssalp02-HB: OK (ref=dce7b578-3457-4828-acbb-c4e9e5e15771) by client crmd.133636<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Notified CMAN that 'dssalp01-HB' is now fenced<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: tengine_stonith_notify: Confirmed CMAN fencing event for 'dssalp01-HB'<br>Jul  9 09:23:02 dssalp02 crmd[133636]:   notice: run_graph: Transition 5467 (Complete=1, Pending=0, Fired=0, Skipped=14, Incomplete=1, Source=/var/lib/pacemaker/pengine/pe-warn-6.bz2): Stopped<br>Jul  9 09:23:02 dssalp02 fenced[133434]: fence dssalp01-HB success</issue><cep>false</cep><folderName>ERP-SAP-ASCS_ERS</folderName></case>