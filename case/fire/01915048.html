======================<br><b>생성계정 : support os</b><br><b>생성날짜 : 2017-08-21T05:39:39Z</b><br><b>마지막 답변자 : Jay Shin</b><br><b>마지막 수정 일자 : 2017-08-27T23:05:29Z</b><br><b>id : 500A000000Y2on4IAB</b><br>======================<br><br><b><font size=15>
제목  : linux shutdown 에 관련된 문의
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>해당 서버가 재부팅 되여 분석 요청 드립니다.<br>로그상 특별한 내용이 보이지 않음.<br><br>Aug 17 10:59:32 slilwasp02 scagent: scagent was started host=42.1.52.77, pid=69630<br>Aug 17 22:38:12 slilwasp02 scagent: scagent was started host=42.1.52.77, pid=50024<br>Aug 18 00:06:30 slilwasp02 scagent: scagent was started host=42.1.52.77, pid=61710<br>---------------재부팅 됨.----------------------<br>Aug 18 01:23:01 slilwasp02 kernel: imklog 5.8.10, log source = /proc/kmsg started.<br>Aug 18 01:23:01 slilwasp02 rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;5.8.10&quot; x-pid=&quot;4098&quot; x-info=&quot;http://www.rsyslog.com&quot;] start<br>Aug 18 01:23:01 slilwasp02 kernel: Initializing cgroup subsys cpuset<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>rhel6.5<br><br>언제 문제가 발생했습니까? 이러한 문제가 자주 발생합니까? 반복적으로 발생합니까? 특정 시간에 발생합니까?<br><br>.<br><br>해결 기간이나 업무에 미치는 영향에 대한 정보를 제공해 주시겠습니까?<br><br>.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 6.5</b><br><b>타입  : Other</b><br><b>계정 번호  : 1596892</b><br><b>심각도  : 4 (Low)</b><br><hostname>slilwasp02</hostname><enhancedSLA>false</enhancedSLA><contactIsPartner>false</contactIsPartner><tags/><br><br><comment id="a0aA000000KScb9IAD"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2017-08-27T23:05:26Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2017-08-27T23:05:26Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>먼저, 본 기술 문의가 해결되어 다행입니다.<br><br>만약 본 기술 문의와 관련하여 추가 질문이 있으시다면 언제든지 본 기술 문의를 재개하실 수 있습니다.<br><br>기술 문의가 처리 완료되면 *고객 설문조사* 메일이 발송됩니다. 고객님께서 남기신 의견은 보다 나은 서비스를 위해 지속적으로 반영될 것입니다.<br>향후 기술 지원 서비스의 품질 향상을 위해, 소중한 시간을 내어 주시면 대단히 감사드리겠습니다.<br><br>감사합니다.<br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>GSS, Asia Pacific, Red Hat Inc<br><br><publishedDate>2017-08-27T23:05:26Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000KSNaoIAH"><br>======================<br><b>생성계정 : os, support</b><br><b>생성날짜 : 2017-08-25T08:13:33Z</b><br><b>마지막 답변자 : os, support</b><br><b>마지막 수정 일자 : 2017-08-25T08:13:33Z</b><br><br>네 종료해도 될것같습니다.<br><br><publishedDate>2017-08-25T08:13:33Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000KSJocIAH"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2017-08-24T23:13:51Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2017-08-24T23:13:50Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 입니다.<br><br>본 케이스와 연관되어 더 궁금한 사항이 있거나 추가적인 지원이 필요하신가요?<br><br>본 안내 후 일주일 이내에 별다른 답변이 없다면 자동으로 종료 상태가 된다는 것을 알려 드립니다.<br><br>만약 추가적인 지원이 필요하다면, 연락 부탁드립니다.<br><br>감사합니다.<br><br>Jay Shin<br>Technical Support Engineer<br>GSS, Asia Pacific, Red Hat Inc<br><br><publishedDate>2017-08-24T23:13:50Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000KRd49IAD"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2017-08-22T23:11:48Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2017-08-22T23:11:48Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>확인 감사합니다.<br><br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>Email: jaeshin@redhat.com <br><br>Red Hat, Asia-Pacific Pty Ltd <br>Website: www.redhat.com<br><br><publishedDate>2017-08-22T23:11:48Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000KRM8ZIAX"><br>======================<br><b>생성계정 : os, support</b><br><b>생성날짜 : 2017-08-22T00:54:16Z</b><br><b>마지막 답변자 : os, support</b><br><b>마지막 수정 일자 : 2017-08-22T00:54:16Z</b><br><br>분석내용 전달하였습니다.<br>추가 문의사항 있으면 업데이트 하도록 하겠습니다.<br><br><publishedDate>2017-08-22T00:54:16Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000KRLkNIAX"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2017-08-22T00:04:41Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2017-08-22T00:04:41Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>      KERNEL: /cores/retrace/repos/kernel/x86_64/usr/lib/debug/lib/modules/2.6.32-431.el6.x86_64/vmlinux<br>    DUMPFILE: /cores/retrace/tasks/471224585/crash/vmcore  [PARTIAL DUMP]<br>        CPUS: 20<br>        DATE: Thu Aug 17 16:17:22 2017<br>      UPTIME: 79 days, 12:10:55<br>LOAD AVERAGE: 0.87, 0.69, 0.35<br>       TASKS: 950<br>    NODENAME: slilwasp02<br>     RELEASE: 2.6.32-431.el6.x86_64<br>     VERSION: #1 SMP Sun Nov 10 22:19:54 EST 2013<br>     MACHINE: x86_64  (2599 Mhz)<br>      MEMORY: 127.9 GB<br>       PANIC: &quot;general protection fault: 0000 [#1] SMP &quot;<br>         PID: 5451<br>     COMMAND: &quot;seosd&quot;<br>        TASK: ffff881065f76080  [THREAD_INFO: ffff881067750000]<br>         CPU: 0<br>       STATE: TASK_RUNNING (PANIC)<br><br>crash&gt; bt<br>PID: 5451   TASK: ffff881065f76080  CPU: 0   COMMAND: &quot;seosd&quot;<br> #0 [ffff881067751a10] machine_kexec at ffffffff81038f3b<br> #1 [ffff881067751a70] crash_kexec at ffffffff810c5d92<br> #2 [ffff881067751b40] oops_end at ffffffff8152b510<br> #3 [ffff881067751b70] die at ffffffff81010e0b<br> #4 [ffff881067751ba0] do_general_protection at ffffffff8152b012<br> #5 [ffff881067751bd0] general_protection at ffffffff8152a7e5<br>    [exception RIP: _spin_lock+0xe]<br>    RIP: ffffffff8152a2fe  RSP: ffff881067751c88  RFLAGS: 00010296<br>    RAX: 0000000000010000  RBX: 0000000000000012  RCX: 00000000028472bd<br>    RDX: 0000000000000000  RSI: 0000000000000110  RDI: 088c230300000262<br>    RBP: ffff881067751c88   R8: 0000000000000000   R9: ffff881067751de4<br>    R10: 0000000000000000  R11: 0000000000000100  R12: ffff881067751ce8<br>    R13: ffff881067751ca8  R14: ffff882061bdc000  R15: 0000000000000000<br>    ORIG_RAX: ffffffffffffffff  CS: 0010  SS: 0018<br> #6 [ffff881067751c90] SEOS_procserver_setsess at ffffffffa0241659 [seos]<br> #7 [ffff881067751d20] SEOS_syscall_v1 at ffffffffa0238c93 [seos]<br> #8 [ffff881067751d40] _SEOS_syscall_ at ffffffffa022149e [seos]<br> #9 [ffff881067751d90] SEOS_vsysc_ioctl at ffffffffa022c563 [seos]<br>#10 [ffff881067751e10] proc_reg_unlocked_ioctl at ffffffff811f34b8<br>#11 [ffff881067751e60] vfs_ioctl at ffffffff8119db42<br>#12 [ffff881067751ea0] do_vfs_ioctl at ffffffff8119e00a<br>#13 [ffff881067751f30] sys_ioctl at ffffffff8119e261<br>#14 [ffff881067751f80] system_call_fastpath at ffffffff8100b072<br>    RIP: 0000003f474e0907  RSP: 00007fff5f2d9d60  RFLAGS: 00000293<br>    RAX: 0000000000000010  RBX: ffffffff8100b072  RCX: 0000003f47557785<br>    RDX: 00007fff5f2da5d0  RSI: 00000000c0305902  RDI: 0000000000000005<br>    RBP: 00007fff5f2da630   R8: 0000000000000000   R9: 00007f5a9ebef8b6<br>    R10: 0000000000000000  R11: 0000000000000203  R12: 0000000000000000<br>    R13: 00007fff5f2dad40  R14: 0000000000000015  R15: 000000000000a4fe<br>    ORIG_RAX: 0000000000000010  CS: 0033  SS: 002b<br><br>The kernel crashed as invalid pointer to spinlock was passed from 3rd party SEOS_procserver_setsess function:<br><br>crash&gt; dis -rl ffffffff8152a2fe<br>/usr/src/debug/kernel-2.6.32-431.el6/linux-2.6.32-431.el6.x86_64/kernel/spinlock.c: 137<br>0xffffffff8152a2f0 &lt;_spin_lock&gt;:<br>push   %rbp<br>0xffffffff8152a2f1 &lt;_spin_lock+0x1&gt;:<br>mov    %rsp,%rbp<br>0xffffffff8152a2f4 &lt;_spin_lock+0x4&gt;:<br>nopl   0x0(%rax,%rax,1)<br>/usr/src/debug/kernel-2.6.32-431.el6/linux-2.6.32-431.el6.x86_64/arch/x86/include/asm/spinlock.h: 127<br>0xffffffff8152a2f9 &lt;_spin_lock+0x9&gt;:<br>mov    $0x10000,%eax<br>0xffffffff8152a2fe &lt;_spin_lock+0xe&gt;:<br>lock xadd %eax,(%rdi) &lt;&lt;---- invalid address<br><br>    RDX: 0000000000000000  RSI: 0000000000000110  RDI: 088c230300000262<br><br>crash&gt; kmem 088c230300000262<br>kmem: cannot determine page for 88c230300000262<br>88c230300000262: physical address not found in mem map<br><br>SEOS vendor should be contacted to find out why the bad spinlock address was passed.<br><br>vmcore 분석에 따르면, spinlock 에 대한 함수가 타사 모듈인 seos 에서 시작되었으며, <br>잘못된 spinlock 주소를 전달받아 시스템이 패닉된 것을 확인할 수 있습니다.<br><br>따라서, SEOS 업체에 본 문제를 의뢰하여 추가 분석을 진행하시는 것을 권고드립니다.<br>혹은 SEOS 모듈을 제거한 상태에서 동일 문제가 발생한다면, 문제 발생시 수집된 vmcore 를 다시 올려주시기 바랍니다.<br><br>만약 본 이슈와 관련하여 추가적인 문의 사항이 있으실 경우 연락 주시기 바랍니다.<br><br>감사합니다.<br><br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>Email: jaeshin@redhat.com <br><br>Red Hat, Asia-Pacific Pty Ltd <br>Website: www.redhat.com<br><br><publishedDate>2017-08-22T00:04:41Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IsdZYIAZ"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2017-08-21T07:26:16Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2017-08-21T07:26:16Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>DMIDECODE<br>  BIOS:<br>    Vend: Dell Inc.    Vers: 1.5.4    Date: 10/002/2015    BIOS Rev: 1.5<br>  System:<br>    Prod: PowerEdge R730<br>  CPU:<br>    2 of 2 CPU sockets populated, 10 cores/10 threads per CPU<br>    20 total cores, 20 total threads<br>    Vers: Intel(R) Xeon(R) CPU E5-2660 v3 @ 2.60GHz<br>  Memory:<br>    Total: 131072 MiB (128 GiB)<br><br>OS<br>  Hostname: slilwasp02<br>  Distro:   [redhat-release] Red Hat Enterprise Linux Server release 6.5 (Santiago)<br>  Kernel:<br>    Booted kernel:  2.6.32-431.el6.x86_64<br>    Booted kernel cmdline:<br>      ro root=/dev/mapper/vg00-lvol01 intel_iommu=on amd_iommu=on rd_NO_LUKS LANG=en_US.UTF-8 rd_LVM_LV=vg00/lvol01 rd_NO_MD SYSFONT=latarcyrheb-sun16 <br>      rd_LVM_LV=vg00/lvol00 crashkernel=137M@0M  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet<br>    Taint-check: 1  (see https://access.redhat.com/solutions/40594)<br>       0  PROPRIETARY_MODULE: Proprietary module has been loaded<br>    - - - - - - - - - - - - - - - - - - -<br>  Sys time:  Fri Aug 18 14:35:16 KST 2017<br>  Boot time: Fri Aug 18 01:22:01 KST 2017  (epoch: 1502986921)<br>  Uptime:    13:13,  1 user<br>  LoadAvg:   [20 CPU] 0.33 (2%), 0.20 (1%), 0.16 (1%)<br>  /proc/stat:<br>    procs_running: 1   procs_blocked: 0    processes [Since boot]: 2026290<br>    cpu [Utilization since boot]:<br>      us 0%, ni 0%, sys 0%, idle 100%, iowait 0%, irq 0%, sftirq 0%, steal 0%<br><br>KDUMP CONFIG<br>  kexec-tools rpm version:<br>    kexec-tools-2.0.0-273.el6.x86_64<br>  Service enablement:<br>    kdump  0:off  1:off  2:off  3:on  4:on  5:on  6:off<br>  kdump initrd/initramfs:<br>    5183098 Jan  6  2016 initrd-2.6.32-431.el6.x86_64kdump.img<br>  Memory reservation config:<br>    /proc/cmdline { crashkernel=137M@0M }<br>  Actual memory reservation per /proc/iomem:<br>      03000000-0b8fffff : Crash kernel<br>  kdump.conf:<br>    path /CRASH<br>    core_collector makedumpfile -c --message-level 1 -d 31<br>  kdump.conf &quot;path&quot; available space:<br>    System MemTotal (uncompressed core size) { 125.93 GiB }<br>    Available free space on target path's fs { 16.79 GiB }  (fs=/CRASH)<br>  Panic sysctls:<br>    kernel.sysrq [bitmask] =  &quot;0&quot;  (disallowed)<br>    kernel.panic [secs] =  0  (no autoreboot on panic)<br>    kernel.hung_task_panic =  0<br>    kernel.panic_on_oops =  1<br>    kernel.panic_on_io_nmi =  0<br>    kernel.panic_on_unrecovered_nmi =  0<br>    kernel.panic_on_stackoverflow =  <br>    kernel.softlockup_panic =  0<br>    kernel.unknown_nmi_panic =  0<br>    kernel.nmi_watchdog =  1<br>    vm.panic_on_oom [0-2] =  0  (no panic)<br><br>PS CHECK<br>  Total number of threads/processes: <br>    975 / 384<br>  Top users of CPU &amp; MEM: <br>    USER  %CPU   %MEM  RSS <br>    root  15.7%  0.1%  0.73 GiB<br>  Uninteruptible sleep threads/processes (0/0): <br>    [None]<br>  Defunct zombie threads/processes (0/0): <br>    [None]<br>  Top CPU-using processes: <br>    USER  PID     %CPU  %MEM  VSZ-MiB  RSS-MiB  TTY    STAT  START  TIME  COMMAND  <br>    root  113941  11.3  0.0   421      127      pts/0  S+    14:35  0:02  /usr/bin/python /usr/sbin/sosreport <br>    root  115684  2.0   0.0   13       1        pts/0  R+    14:35  0:00  /bin/ps auxwww <br>    root  6408    0.7   0.0   228      42       ?      S&lt;l   01:23  6:10  /opt/perf/bin/perfd <br>    root  6302    0.7   0.0   44       15       ?      S&lt;s   01:23  6:17  /opt/perf/bin/scopeux <br>    root  4617    0.4   0.0   51       1        ?      Ss    01:23  3:42  /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf <br>    root  5708    0.3   0.0   54       13       ?      S&lt;    01:23  2:58  /usr/seos/bin/seosd <br>    root  6841    0.2   0.0   625      15       ?      Sl    01:23  2:19  /opt/OV/lbin/perf/coda <br>    root  6610    0.1   0.0   643      8        ?      Sl    01:23  0:58  /opt/OV/bin/ovbbccb -nodaemon <br>    root  99      0.0   0.0   0        0        ?      S     01:22  0:00  [events/16] <br>    root  98      0.0   0.0   0        0        ?      S     01:22  0:00  [events/15] <br>  Top MEM-using processes: <br>    USER  PID     %CPU  %MEM  VSZ-MiB  RSS-MiB  TTY    STAT  START  TIME  COMMAND  <br>    root  6444    0.0   0.1   3120     171      ?      Sl    01:23  0:44  /opt/dell/srvadmin/sbin/dsm_om_connsvcd -run <br>    root  113941  11.3  0.0   421      127      pts/0  S+    14:35  0:02  /usr/bin/python /usr/sbin/sosreport <br>    root  4593    0.0   0.0   2791     111      ?      Ssl   01:23  0:27  /usr/lib/Acronis/BackupAndRecovery/mms <br>    root  6408    0.7   0.0   228      42       ?      S&lt;l   01:23  6:10  /opt/perf/bin/perfd <br>    root  4123    0.0   0.0   1171     31       ?      Sl    01:22  0:29  /opt/opsware/agent/bin/python /opt/opsware/agent/pylibs/shadowbot/daemonbot.pyc --conf <br>    root  5996    0.0   0.0   1041     22       ?      Ssl   01:23  0:16  /opt/dell/srvadmin/sbin/dsm_sa_datamgrd <br>    root  4603    0.0   0.0   1112     18       ?      Ssl   01:23  0:00  /usr/lib/Acronis/ARSM/arsm <br>    root  6137    0.0   0.0   455      17       ?      Ss    01:23  0:00  /opt/dell/srvadmin/sbin/dsm_sa_datamgrd <br>    root  6781    0.0   0.0   494      16       ?      Sl    01:23  0:20  /opt/OV/lbin/eaagt/opcmona <br>    root  6841    0.2   0.0   625      15       ?      Sl    01:23  2:19  /opt/OV/lbin/perf/coda <br><br>filename:       /lib/modules/2.6.32-431.el6.x86_64/extra/snapapi26.ko<br>supported:      external<br>version:        0.7.85<br><br>scsi0 : LSI SAS based MegaRAID driver<br>megasas:span 0 rowDataSize 1<br>megasas:span 0 rowDataSize 5<br>scsi 0:0:0:0: Direct-Access     DELL     PERC H730 Mini   4.25 PQ: 0 ANSI: 5<br>scsi 0:0:1:0: Direct-Access     DELL     PERC H730 Mini   4.25 PQ: 0 ANSI: 5<br>scsi 0:2:0:0: Direct-Access     DELL     PERC H730 Mini   4.25 PQ: 0 ANSI: 5<br>scsi 0:2:1:0: Direct-Access     DELL     PERC H730 Mini   4.25 PQ: 0 ANSI: 5<br><br>Aug  9 02:03:13 slilwasp02 kernel: INFO: task jbd2/dm-2-8:3482 blocked for more than 120 seconds.<br>Aug  9 02:03:13 slilwasp02 kernel:      Tainted: P           ---------------    2.6.32-431.el6.x86_64 #1<br>Aug  9 02:03:13 slilwasp02 kernel: &quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot; disables this message.<br>Aug  9 02:03:13 slilwasp02 kernel: jbd2/dm-2-8   D 0000000000000012     0  3482      2 0x00000000<br>Aug  9 02:03:13 slilwasp02 kernel: ffff881067981d20 0000000000000046 0000000000016840 0000000000016840<br>Aug  9 02:03:13 slilwasp02 kernel: ffff8810693fa800 0000000000016840 0000000000016840 ffff8810663a9540<br>Aug  9 02:03:13 slilwasp02 kernel: ffff8810663a9af8 ffff881067981fd8 000000000000fbc8 ffff8810663a9af8<br>Aug  9 02:03:13 slilwasp02 kernel: Call Trace:<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffff8109b5ce&gt;] ? prepare_to_wait+0x4e/0x80<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffffa008e80f&gt;] jbd2_journal_commit_transaction+0x19f/0x1500 [jbd2]<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffff810096f0&gt;] ? __switch_to+0xd0/0x320<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffff8108412c&gt;] ? lock_timer_base+0x3c/0x70<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffff8109b2a0&gt;] ? autoremove_wake_function+0x0/0x40<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffffa0094a48&gt;] kjournald2+0xb8/0x220 [jbd2]<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffff8109b2a0&gt;] ? autoremove_wake_function+0x0/0x40<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffffa0094990&gt;] ? kjournald2+0x0/0x220 [jbd2]<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffff8109aef6&gt;] kthread+0x96/0xa0<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffff8100c20a&gt;] child_rip+0xa/0x20<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffff8109ae60&gt;] ? kthread+0x0/0xa0<br>Aug  9 02:03:13 slilwasp02 kernel: [&lt;ffffffff8100c200&gt;] ? child_rip+0x0/0x20<br>...<br>Feb 24 02:02:45 slilwasp02 kernel: INFO: task jbd2/dm-2-8:3500 blocked for more than 120 seconds.<br>Feb 24 02:02:45 slilwasp02 kernel:      Tainted: P           ---------------    2.6.32-431.el6.x86_64 #1<br>Feb 24 02:02:45 slilwasp02 kernel: &quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot; disables this message.<br>Feb 24 02:02:45 slilwasp02 kernel: jbd2/dm-2-8   D 0000000000000005     0  3500      2 0x00000000<br>Feb 24 02:02:45 slilwasp02 kernel: ffff88106789db30 0000000000000046 0000000000000000 ffffffffa000169d<br>Feb 24 02:02:45 slilwasp02 kernel: ffff88106789daa0 ffffffff810149b9 ffff88106789dae0 0000000000000286<br>Feb 24 02:02:45 slilwasp02 kernel: ffff881065d81af8 ffff88106789dfd8 000000000000fbc8 ffff881065d81af8<br>Feb 24 02:02:45 slilwasp02 kernel: Call Trace:<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffffa000169d&gt;] ? __map_bio+0xad/0x140 [dm_mod]<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff810149b9&gt;] ? read_tsc+0x9/0x20<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff810a70a1&gt;] ? ktime_get_ts+0xb1/0xf0<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8111f930&gt;] ? sync_page+0x0/0x50<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff815280a3&gt;] io_schedule+0x73/0xc0<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8111f96d&gt;] sync_page+0x3d/0x50<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff81528b6f&gt;] __wait_on_bit+0x5f/0x90<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8111fba3&gt;] wait_on_page_bit+0x73/0x80<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8109b320&gt;] ? wake_bit_function+0x0/0x50<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff81135bf5&gt;] ? pagevec_lookup_tag+0x25/0x40<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8111ffcb&gt;] wait_on_page_writeback_range+0xfb/0x190<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8112008f&gt;] filemap_fdatawait+0x2f/0x40<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffffa008ee59&gt;] jbd2_journal_commit_transaction+0x7e9/0x1500 [jbd2]<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff810096f0&gt;] ? __switch_to+0xd0/0x320<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff81084d2b&gt;] ? try_to_del_timer_sync+0x7b/0xe0<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffffa0094a48&gt;] kjournald2+0xb8/0x220 [jbd2]<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8109b2a0&gt;] ? autoremove_wake_function+0x0/0x40<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffffa0094990&gt;] ? kjournald2+0x0/0x220 [jbd2]<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8109aef6&gt;] kthread+0x96/0xa0<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8100c20a&gt;] child_rip+0xa/0x20<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8109ae60&gt;] ? kthread+0x0/0xa0<br>Feb 24 02:02:45 slilwasp02 kernel: [&lt;ffffffff8100c200&gt;] ? child_rip+0x0/0x20<br>...<br>Jun 27 02:02:28 slilwasp02 kernel: INFO: task jbd2/dm-2-8:3499 blocked for more than 120 seconds.<br>Jun 27 02:02:28 slilwasp02 kernel:      Tainted: P           ---------------    2.6.32-431.el6.x86_64 #1<br>Jun 27 02:02:28 slilwasp02 kernel: &quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot; disables this message.<br>Jun 27 02:02:28 slilwasp02 kernel: jbd2/dm-2-8   D 000000000000000c     0  3499      2 0x00000000<br>Jun 27 02:02:28 slilwasp02 kernel: ffff88106728fb30 0000000000000046 ffff88106728fac0 ffffffffa000169d<br>Jun 27 02:02:28 slilwasp02 kernel: ffff88106728faa0 ffffffff810149b9 ffff88106728fae0 0000000000000286<br>Jun 27 02:02:28 slilwasp02 kernel: ffff88106495d098 ffff88106728ffd8 000000000000fbc8 ffff88106495d098<br>Jun 27 02:02:28 slilwasp02 kernel: Call Trace:<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffffa000169d&gt;] ? __map_bio+0xad/0x140 [dm_mod]<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff810149b9&gt;] ? read_tsc+0x9/0x20<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff810a70a1&gt;] ? ktime_get_ts+0xb1/0xf0<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8111f930&gt;] ? sync_page+0x0/0x50<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff815280a3&gt;] io_schedule+0x73/0xc0<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8111f96d&gt;] sync_page+0x3d/0x50<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff81528b6f&gt;] __wait_on_bit+0x5f/0x90<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8111fba3&gt;] wait_on_page_bit+0x73/0x80<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8109b320&gt;] ? wake_bit_function+0x0/0x50<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff81135bf5&gt;] ? pagevec_lookup_tag+0x25/0x40<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8111ffcb&gt;] wait_on_page_writeback_range+0xfb/0x190<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff81267020&gt;] ? submit_bio+0x70/0x120<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8112008f&gt;] filemap_fdatawait+0x2f/0x40<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffffa008ee59&gt;] jbd2_journal_commit_transaction+0x7e9/0x1500 [jbd2]<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff810096f0&gt;] ? __switch_to+0xd0/0x320<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff81084d2b&gt;] ? try_to_del_timer_sync+0x7b/0xe0<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffffa0094a48&gt;] kjournald2+0xb8/0x220 [jbd2]<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8109b2a0&gt;] ? autoremove_wake_function+0x0/0x40<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffffa0094990&gt;] ? kjournald2+0x0/0x220 [jbd2]<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8109aef6&gt;] kthread+0x96/0xa0<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8100c20a&gt;] child_rip+0xa/0x20<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8109ae60&gt;] ? kthread+0x0/0xa0<br>Jun 27 02:02:28 slilwasp02 kernel: [&lt;ffffffff8100c200&gt;] ? child_rip+0x0/0x20<br><br>$ cat proc/cmdline <br>ro root=/dev/mapper/vg00-lvol01 intel_iommu=on amd_iommu=on rd_NO_LUKS LANG=en_US.UTF-8 rd_LVM_LV=vg00/lvol01 rd_NO_MD SYSFONT=latarcyrheb-sun16 rd_LVM_LV=vg00/lvol00 crashkernel=137M@0M  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet<br><br><br>sosreport 를 확인해보았으며 아래 시각에 journal 디바이스에 행이 발생되었습니다.<br> - 2016년 8월  9일 화요일 02시경<br> - 2017년 2월 24일 금요일 02시경<br> - 2017년 6월 27일 화요일 02시경<br><br>02시 02분 경에 동일하게 문제가 발생되는 점에 주목해볼 필요가 있으며, 02시에 어떤 작업이 발생하는지도 확인이 필요합니다.<br><br>jbd2 트랜젝션에 행이 발생하는 경우, ioscheduler 를 deadline 으로 설정하는 것으로 문제가 완화될 수 있는지 확인해주시기 바랍니다.<br><br>Using the Deadline IO Scheduler <br>https://access.redhat.com/solutions/32376<br><br>vmcore 는 분석이 되는대로 결과 안내하도록 하겠습니다.<br><br>만약 본 이슈와 관련하여 추가적인 문의 사항이 있으실 경우 연락 주시기 바랍니다.<br><br>감사합니다.<br><br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>Email: jaeshin@redhat.com <br><br>Red Hat, Asia-Pacific Pty Ltd <br>Website: www.redhat.com<br><br><publishedDate>2017-08-21T07:26:16Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IsdX8IAJ"><br>======================<br><b>생성계정 : os, support</b><br><b>생성날짜 : 2017-08-21T07:24:13Z</b><br><b>마지막 답변자 : os, support</b><br><b>마지막 수정 일자 : 2017-08-21T07:24:13Z</b><br><br>dropdox에 vmcore.sillwasp02 로 kdump 파일 올렸습니다.<br>확인 바랍니다.<br><br><publishedDate>2017-08-21T07:24:13Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000IsdC8IAJ"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2017-08-21T06:52:51Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2017-08-21T06:52:51Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>올려주신 vmcore-dmesg.txt 를 확인한 결과 시스템에 Acronis 백업 모듈이 탑재되었으며,<br>크래시 콜트레이스를 보면, ioctl 시스템콜 수행시에 seos 모듈이 관련되어 수행되었던 것으로 확인됩니다.<br><br>&lt;4&gt;snapapi26: module license 'Proprietary' taints kernel.<br>&lt;4&gt;Disabling lock debugging due to kernel taint<br>&lt;6&gt;snapapi_init(modprobe,4740): Snapapi(v.0.7.85) init OK. Session size 13680.<br>...<br>&lt;6&gt;snumbd_open_blk(udisks-part-id,139357): Disable access (1003,4590)...<br>&lt;7&gt;snumbdctl_release(service_process,95582): OK s=ffff881064432800<br>&lt;4&gt;general protection fault: 0000 [#1] SMP<br>&lt;4&gt;last sysfs file: /sys/devices/system/cpu/online<br>&lt;4&gt;CPU 0<br>&lt;4&gt;Modules linked in: snumbd26(P)(U) vfat fat usb_storage mpt3sas mpt2sas scsi_transport_sas raid_class mptctl mptbase ipmi_devintf dell_rbu seos(P)(U) snapapi26(P)(U) bonding 8021q garp stp llc ipv6 uinput microcode iTCO_wdt iTCO_vendor_support dcdbas power_meter shpchp sg tg3 ptp pps_core lpc_ich mfd_core ext4 jbd2 mbcache sr_mod cdrom sd_mod crc_t10dif ahci megaraid_sas wmi dm_mirror dm_region_hash dm_log dm_mod [last unloaded: scsi_wait_scan]<br>&lt;4&gt;<br>&lt;4&gt;Pid: 5451, comm: seosd Tainted: P           ---------------    2.6.32-431.el6.x86_64 #1 Dell Inc. PowerEdge R730/0H21J3<br>&lt;4&gt;RIP: 0010:[&lt;ffffffff8152a2fe&gt;]  [&lt;ffffffff8152a2fe&gt;] _spin_lock+0xe/0x30<br>&lt;4&gt;RSP: 0018:ffff881067751c88  EFLAGS: 00010296<br>&lt;4&gt;RAX: 0000000000010000 RBX: 0000000000000012 RCX: 00000000028472bd<br>&lt;4&gt;RDX: 0000000000000000 RSI: 0000000000000110 RDI: 088c230300000262<br>&lt;4&gt;RBP: ffff881067751c88 R08: 0000000000000000 R09: ffff881067751de4<br>&lt;4&gt;R10: 0000000000000000 R11: 0000000000000100 R12: ffff881067751ce8<br>&lt;4&gt;R13: ffff881067751ca8 R14: ffff882061bdc000 R15: 0000000000000000<br>&lt;4&gt;FS:  00007f5a9ecf2720(0000) GS:ffff880060600000(0000) knlGS:0000000000000000<br>&lt;4&gt;CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033<br>&lt;4&gt;CR2: 00007f0c4b9002d0 CR3: 0000001064860000 CR4: 00000000001407f0<br>&lt;4&gt;DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000<br>&lt;4&gt;DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400<br>&lt;4&gt;Process seosd (pid: 5451, threadinfo ffff881067750000, task ffff881065f76080)<br>&lt;4&gt;Stack:<br>&lt;4&gt; ffff881067751d18 ffffffffa0241659 0000000000000018 ffff881067751de4<br>&lt;4&gt;&lt;d&gt; 00000101ffffffff ffffffffffffffff ffffffff00000104 ffffffffffffffff<br>&lt;4&gt;&lt;d&gt; ffffffffffffffff ffffffffffffffff ffffffffffffffff 0000010fffffffff<br>&lt;4&gt;Call Trace:<br>&lt;4&gt; [&lt;ffffffffa0241659&gt;] SEOS_procserver_setsess+0x99/0x180 [seos]<br>&lt;4&gt; [&lt;ffffffffa0238c93&gt;] SEOS_syscall_v1+0x783/0x8e0 [seos]<br>&lt;4&gt; [&lt;ffffffffa022149e&gt;] _SEOS_syscall_+0x8e/0x3f0 [seos]<br>&lt;4&gt; [&lt;ffffffffa022c563&gt;] SEOS_vsysc_ioctl+0x123/0x160 [seos]<br>&lt;4&gt; [&lt;ffffffff811f34b8&gt;] proc_reg_unlocked_ioctl+0x78/0x100<br>&lt;4&gt; [&lt;ffffffff8119db42&gt;] vfs_ioctl+0x22/0xa0<br>&lt;4&gt; [&lt;ffffffff8119e00a&gt;] do_vfs_ioctl+0x3aa/0x580<br>&lt;4&gt; [&lt;ffffffff8119e261&gt;] sys_ioctl+0x81/0xa0<br>&lt;4&gt; [&lt;ffffffff8100b072&gt;] system_call_fastpath+0x16/0x1b<br>&lt;4&gt;Code: e5 0f 1f 44 00 00 fa 66 0f 1f 44 00 00 f0 81 2f 00 00 00 01 74 05 e8 12 45 d6 ff c9 c3 55 48 89 e5 0f 1f 44 00 00 b8 00 00 01 00 &lt;f0&gt; 0f c1 07 0f b7 d0 c1 e8 10 39 c2 74 0e f3 90 0f b7 17 eb f5<br>&lt;1&gt;RIP  [&lt;ffffffff8152a2fe&gt;] _spin_lock+0xe/0x30<br>&lt;4&gt; RSP &lt;ffff881067751c88&gt;<br><br>본 시스템 패닉은 ioctl 시스템 콜 함수 수행도중에 seos 모듈에 의한 시스템 콜 후킹에 의한<br>seos 모듈 함수가 수행되었으며, _spin_lock 함수가 호출 도중에 시스템이 패닉된 것을 확인할 수 있습니다.<br><br>따라서, 본 문제는 seos 모듈과의 연관성이 높은 것으로 보이고, 해당 모듈 제조업체에 추가 분석을 의뢰해볼 필요가 있습니다.<br>또한, 저희 레드햇이 분석할 부분이 있는지 확인해보기 위해, sosreport 와 패닉 당시에 생성된 vmcore 를 올려주시기 바랍니다.<br><br>만약 본 이슈와 관련하여 추가적인 문의 사항이 있으실 경우 연락 주시기 바랍니다.<br><br>감사합니다.<br><br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>Email: jaeshin@redhat.com <br><br>Red Hat, Asia-Pacific Pty Ltd <br>Website: www.redhat.com<br><br><publishedDate>2017-08-21T06:52:51Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br>