======================<br><b>생성계정 : support os</b><br><b>생성날짜 : 2016-10-20T06:30:46Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2016-12-08T11:01:28Z</b><br><b>id : 500A000000VX8amIAD</b><br>======================<br><br><b><font size=15>
제목  : [삼성화재][ERP 가동][pmsclp01,pmsclp02]  이중화 구성시 서비스 망 절제후 pingd에 의한 서비스 전환시간 16분 지연 이유
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>고객 정보 (필수) - 실제 레드햇 서브스크립션을 소유하고 시스템에 사용 중인 엔드 유저<br>    - 성함(직급) :손향준 사원<br><br>    - 회사명(부서명) : 금융시스템그룹(금융/서비스)/삼성SDS<br>    - 전화번호 :02-509-0318<br>    - 메일주소 :h2014.son@samsung.com<br><br>* 파트너 정보 (옵션) - 실제 고객의 시스템을 유지보수하는 업체<br>    - 성함(직급) :이승훈 수석보<br>    - 회사명(부서명) : 타임게이트(os팀)<br>    - 전화번호 :010-5493-0769<br>    - 메일주소 :sh.lee@time-gate.com<br><br>*  문제 설명 (Description)<br>   - 증상 : heartbeat 이중화 구성된 시스템에서 서비스망 절제시 pings 데몬이 서비스 절제 감지후 서비스 전환까지 16분 소요됨<br>   - 발생 시점 : 서비스망 절제시<br>   - 발생 빈도 : 일시적<br>   - 문의 내용(기대 답변) :<br> <br>heartbeat 망이 동작하고 서비스 망과  fence망은  둘다 절제 되었을 경우<br>pingd 에서 실제 서비스를 올리는 시간까지 기대보다 많은 시간이 소요됩니다.<br><br>sosreport 는 추가 첨부로 올려드리겠습니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>계정 번호  : 1596892</b><br><b>심각도  : 3 (Normal)</b><br><br><br><folderNumber>74173</folderNumber><br><comment id="a0aA000000IIGWxIAP"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2016-11-22T02:19:51Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2016-11-22T02:19:51Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>먼저, 답변이 늦은점에 대하여 사과의 말씀 드립니다.<br>해당 이슈에 대한 답변은 아래와 같습니다.<br><br># 2016.01.18 - Red Hat for HA ( HeartBeat )<br>192.168.25.31   pmsclp01-HB<br>192.168.25.32   pmsclp02-HB<br><br><br># 2016.01.18 - Red Hat for HA ( Service )<br>42.1.231.31 pmsclp01<br>42.1.231.32 pmsclp02<br><br>사용하는 인터페이스<br><br>BOOTPROTO=none<br>NAME=bond0<br>DEVICE=bond0<br>DEVICETYPE=Bond<br>ONBOOT=yes<br>IPADDR=42.1.231.32<br>NETMASK=255.255.255.0<br>GATEWAY=42.1.231.1<br>BONDING_OPTS=&quot;mode=1 miimon=100&quot;<br><br><br>BOOTPROTO=none<br>NAME=bond2<br>DEVICE=bond2<br>DEVICETYPE=Bond<br>ONBOOT=yes<br>IPADDR=192.168.25.32<br>NETMASK=255.255.255.0<br>BONDING_OPTS=&quot;mode=1 miimon=100&quot;<br><br><br>* 이슈 발생시 서비스 네트워크가 다운이 되었으며 핫빗 네트워크 통신은 정상이기 때문에 팬싱 이슈가 발생되지 않음<br>======================<br>* Pingd 가 clone 으로 설정되었으며 양 노드 전부 동일한 IP를 ping함<br>* 이슈 발생시 양 노드가 Pingd IP와 통신 불가 <br><br><br>      &lt;clone id=&quot;rsc_ping-clone&quot;&gt;<br>        &lt;primitive class=&quot;ocf&quot; id=&quot;rsc_ping&quot; provider=&quot;pacemaker&quot; type=&quot;ping&quot;&gt;<br>          &lt;instance_attributes id=&quot;rsc_ping-instance_attributes&quot;&gt;<br>            &lt;nvpair id=&quot;rsc_ping-instance_attributes-multiplier&quot; name=&quot;multiplier&quot; value=&quot;10&quot;/&gt;<br>            &lt;nvpair id=&quot;rsc_ping-instance_attributes-host_list&quot; name=&quot;host_list&quot; value=&quot;42.1.231.1&quot;/&gt;<br>          &lt;/instance_attributes&gt;<br>          &lt;operations&gt;<br>            &lt;op id=&quot;rsc_ping-start-interval-0s&quot; interval=&quot;0s&quot; name=&quot;start&quot; timeout=&quot;60&quot;/&gt;<br>            &lt;op id=&quot;rsc_ping-stop-interval-0s&quot; interval=&quot;0s&quot; name=&quot;stop&quot; timeout=&quot;20&quot;/&gt;<br>            &lt;op id=&quot;rsc_ping-monitor-interval-10&quot; interval=&quot;10&quot; name=&quot;monitor&quot; timeout=&quot;60&quot;/&gt;<br>          &lt;/operations&gt;<br>        &lt;/primitive&gt;<br>        &lt;meta_attributes id=&quot;rsc_ping-clone-meta_attributes&quot;/&gt;<br>      &lt;/clone&gt;<br>======================<br><br>* 설정상 vip1은 노드 1에, vip2는 노드 2 에서 기동되는것을 prefer 함<br><br><br>      &lt;rsc_location id=&quot;location-rsc_vip1&quot; rsc=&quot;rsc_vip1&quot;&gt;<br>        &lt;rule boolean-op=&quot;or&quot; id=&quot;location-rsc_vip1-rule&quot; score=&quot;-INFINITY&quot;&gt;<br>          &lt;expression attribute=&quot;pingd&quot; id=&quot;location-rsc_vip1-rule-expr&quot; operation=&quot;lt&quot; value=&quot;1&quot;/&gt;<br>          &lt;expression attribute=&quot;pingd&quot; id=&quot;location-rsc_vip1-rule-expr-1&quot; operation=&quot;not_defined&quot;/&gt;<br>        &lt;/rule&gt;<br>      &lt;/rsc_location&gt;<br>      &lt;rsc_location id=&quot;location-rsc_vip1-pmsclp01-HB-10&quot; node=&quot;pmsclp01-HB&quot; rsc=&quot;rsc_vip1&quot; score=&quot;10&quot;/&gt;<br>      &lt;rsc_location id=&quot;location-grp1-pmsclp01-HB-10&quot; node=&quot;pmsclp01-HB&quot; rsc=&quot;grp1&quot; score=&quot;10&quot;/&gt;<br>      &lt;rsc_location id=&quot;const_ipmilan1&quot; node=&quot;pmsclp01-HB&quot; rsc=&quot;ipmilan_stonith1&quot; score=&quot;-INFINITY&quot;/&gt;<br>      &lt;rsc_location id=&quot;const_ipmilan2&quot; node=&quot;pmsclp02-HB&quot; rsc=&quot;ipmilan_stonith2&quot; score=&quot;-INFINITY&quot;/&gt;<br>      &lt;rsc_location id=&quot;location-rsc_vip2&quot; rsc=&quot;rsc_vip2&quot;&gt;<br>        &lt;rule boolean-op=&quot;or&quot; id=&quot;location-rsc_vip2-rule&quot; score=&quot;-INFINITY&quot;&gt;<br>          &lt;expression attribute=&quot;pingd&quot; id=&quot;location-rsc_vip2-rule-expr&quot; operation=&quot;lt&quot; value=&quot;1&quot;/&gt;<br>          &lt;expression attribute=&quot;pingd&quot; id=&quot;location-rsc_vip2-rule-expr-1&quot; operation=&quot;not_defined&quot;/&gt;<br>        &lt;/rule&gt;<br>      &lt;/rsc_location&gt;<br>      &lt;rsc_location id=&quot;location-rsc_vip2-pmsclp02-HB-10&quot; node=&quot;pmsclp02-HB&quot; rsc=&quot;rsc_vip2&quot; score=&quot;10&quot;/&gt;<br><br><br>* 다만 서비스 네트워크가 복귀된후 vip1이 노드 2로 relocate 되었습니다.<br><br>Oct 18 15:41:07 [90393] pmsclp01      attrd:     info: attrd_peer_update:<br>Setting pingd[pmsclp01-HB]: 10 -&gt; 0 from pmsclp01-HB<br>Oct 18 15:41:12 [90390] pmsclp01        cib:     info: cib_perform_op:<br>Diff: --- 0.104.39 2<br>Oct 18 15:41:12 [90390] pmsclp01        cib:     info: cib_perform_op:<br>Diff: +++ 0.104.40 (null)<br>Oct 18 15:41:12 [90390] pmsclp01        cib:     info: cib_perform_op:<br>+  /cib:  @num_updates=40<br>Oct 18 15:41:12 [90390] pmsclp01        cib:     info: cib_perform_op:<br>+  /cib/status/node_state[@id='1']/transient_attributes[@id='1']/instance_attributes[@id='status-1']/nvpair[@id='status-1-pingd']:  @value=0<br>Oct 18 15:41:12 [90390] pmsclp01        cib:     info: cib_process_request:<br>Completed cib_modify operation for section status: OK (rc=0, origin=pmsclp02-HB/attrd/7, version=0.104.40)<br>Oct 18 15:41:12 [90395] pmsclp01       crmd:     info: abort_transition_graph:<br>Transition aborted by status-1-pingd, pingd=0: Transient attribute change (modify cib=0.104.40, source=abort_unless_down:319, path=/cib/status/node_state[@id='1']/transient_attributes[@id='1']/instance_attributes[@id='status-1']/nvpair[@id='status-1-pingd'], 1)<br>Oct 18 15:41:12 [90395] pmsclp01       crmd:   notice: do_state_transition:<br>State transition S_IDLE -&gt; S_POLICY_ENGINE [ input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph ]<br>Oct 18 15:41:12 [90394] pmsclp01    pengine:     info: determine_online_status_fencing:<br>Node pmsclp01-HB is active<br><br><br>* 해당 이슈는 노드 2가 먼저 pingd IP와 통신이 가능하여 노드 2에서 기동되어 발생된 이슈인것으로 보입니다.<br><br><br>감사합니다.<br><br><publishedDate>2016-11-22T02:19:51Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IHIr8IAH"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2016-11-16T02:08:12Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2016-11-16T02:08:12Z</b><br><br>안녕하세요.<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>현재 해당 이슈에 대하여 유럽쪽 엔지니어분도 함께 분석해 주시고 있습니다만 <br>아직 추가적인 확인사항이 없으십니다.<br><br>팬싱 작업은 핫빗 체킹에 실패될 경우 발생하게 되며 해당 이슈와 같이 서비스망과 <br>팬싱망이 절체될 경우에는 팬싱 작업이 실행이되지 않습니다. 다만 해당 이슈에서<br>리소스가 failover된 원인이 확인이 되지 않고 있습니다.<br><br>새로운 이슈이다보니 원인 분석에 다소 시간이 걸리고 있습니다.<br>최대한 빨리 이슈 발생 원인을 확인하도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-11-16T02:08:12Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000ICMLYIA5"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2016-11-11T06:11:51Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2016-11-11T06:11:51Z</b><br><br>안녕하세요.<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>Q1&gt; HA에서 Fail-Over를 수행하는데, Fail-over가 수행의 원인이되는 HA의 이벤트가 무엇인지  확인이 필요합니다.<br><br>현재 로그상 아래와 같은 시각에 리소스가 모든 노드에서 실행이 될수 없음을 알리는 메시지가 기록 되었지만 기타 로그가<br>확인이 되지 않아 원인 분석이 어려움이 있습니다. 해당 부분에 대하여 해외엔지니어들과 재차 분석후 업데이트 드리도록 <br>하겠습니다.<br><br>   9 Oct 18 15:41:21 [90394] pmsclp01    pengine:     info: rsc_merge_weights:   rsc_vip1: Rolling back scores from rsc_ascs1<br>   8 Oct 18 15:41:21 [90394] pmsclp01    pengine:     info: native_color:    Resource rsc_vip1 cannot run anywhere<br>   7 Oct 18 15:41:21 [90394] pmsclp01    pengine:     info: native_color:    Resource rsc_ascs1 cannot run anywhere<br>   6 Oct 18 15:41:21 [90394] pmsclp01    pengine:     info: native_color:    Resource rsc_vip2 cannot run anywhere<br><br><br>Q2&gt; 클러스터 그룹에 Fencing 장치가 Multi-Level( 1차 : kdump, 2차 : ipmi )로 구성되어 있습니다. <br>        여러 가지의 Fencing 장치를 설정한 상황에서 IPMI와같이 Power-Fencing이 반드시 정상인 상태여야만 Fail-Over가 이루어지게 되는 것인지, 확인이 필요합니다.<br><br>Multi-Level 구성에서 어느 레벨에서 fencing 이 성공하면 리소스가 failover 하게 됩니다. <br>즉 현재 설정에 따르면 kdump가 성공, 혹은 kdump가 실패시 IPMI가 성공하면 failover 됩니다.<br><br>감사합니다.<br><br><publishedDate>2016-11-11T06:11:51Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IC7yDIAT"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2016-11-10T07:55:24Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2016-11-10T07:55:24Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>현재 해당 이슈에 대하여 이상한 점이 확인되어 해외 엔지니어분들과 함께 분석중에 있으며 관련 정보가 확인되는대로 업데이트 드리도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-11-10T07:55:24Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IBpS0IAL"><br>======================<br><b>생성계정 : Kim, Seung-Pil</b><br><b>생성날짜 : 2016-11-09T07:16:32Z</b><br><b>마지막 답변자 : Kim, Seung-Pil</b><br><b>마지막 수정 일자 : 2016-11-09T07:16:32Z</b><br><br>안녕하세요.<br><br>이전에 주신 답변에 추가로 확인이 필요한 사항이 있습니다.<br><br>서비스 네트워크 실패에대한 감시를 pingd 리소스를 이용하여 수행하고 있는데,<br>문제가 발생한 당시( 2016년10월18일 15시24분 경 ~ 2016년10월18일 15시 44분 경,  KST기준 ) 클러스터 리소스인 pingd에서 실패를 감지한 로그가 없는 것 같습니다.<br><br>Q1&gt; HA에서 Fail-Over를 수행하는데, Fail-over가 수행의 원인이되는 HA의 이벤트가 무엇인지  확인이 필요합니다.<br><br>Q2&gt; 클러스터 그룹에 Fencing 장치가 Multi-Level( 1차 : kdump, 2차 : ipmi )로 구성되어 있습니다. <br>        여러 가지의 Fencing 장치를 설정한 상황에서 IPMI와같이 Power-Fencing이 반드시 정상인 상태여야만 Fail-Over가 이루어지게 되는 것인지, 확인이 필요합니다.<br>======================<br>아래 로그는, 문제 발생 당시 Fail-Over가 시작되는 시점까지의 클러스터 1번 노드에서 /var/log/messages에 기록되는 syslog관련 로그 입니다.<br>###########################################################################################<br><br>Oct 18 15:35:57 pmsclp01 crmd[90395]:  notice: State transition S_IDLE -&gt; S_POLICY_ENGINE [ input=I_PE_CALC cause=C_TIMER_POPPED origin=crm_timer_popped ]<br>Oct 18 15:35:57 pmsclp01 pengine[90394]:  notice: Calculated Transition 6438: /var/lib/pacemaker/pengine/pe-input-573.bz2<br>Oct 18 15:35:57 pmsclp01 crmd[90395]:  notice: Transition 6438 (Complete=0, Pending=0, Fired=0, Skipped=0, Incomplete=0, Source=/var/lib/pacemaker/pengine/pe-input-573.bz2): Complete<br>Oct 18 15:35:57 pmsclp01 crmd[90395]:  notice: State transition S_TRANSITION_ENGINE -&gt; S_IDLE [ input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd ]<br>Oct 18 15:41:12 pmsclp01 crmd[90395]:  notice: State transition S_IDLE -&gt; S_POLICY_ENGINE [ input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph ]<br>Oct 18 15:41:12 pmsclp01 pengine[90394]:  notice: Move    rsc_vip1#011(Started pmsclp01-HB -&gt; pmsclp02-HB)<br>Oct 18 15:41:12 pmsclp01 pengine[90394]:  notice: Move    rsc_ascs1#011(Started pmsclp01-HB -&gt; pmsclp02-HB)<br>Oct 18 15:41:12 pmsclp01 pengine[90394]:  notice: Calculated Transition 6439: /var/lib/pacemaker/pengine/pe-input-574.bz2<br>###########################################################################################<br><br>아래 로그는, 문제 발생 당시 Fail-Over가 시작되는 시점까지의 클러스터 1번 노드에서 /var/log/messages에 기록되는 관리자가 작성한 감시용 스크립트에서 생성한 로그 입니다.<br>*****************************************************************************************************************<br>Oct 18 15:25:21 pmsclp01 fence_ipmilan: Connection timed out<br>Oct 18 15:25:48 pmsclp01 fence_ipmilan: Connection timed out<br>Oct 18 15:25:48 pmsclp01 root: FAILED CHECKING FENCE DEVICE : CHECK FENCE DEVICE( 42.1.240.108 ) - [ Invalid Status ] or [ Incorrect Login credentials ]<br>Oct 18 15:26:48 pmsclp01 root: FAILED CHECKING FENCE DEVICE : FENCE DEVICE( 42.1.240.108 ) is UNREACHABLE.<br>Oct 18 15:30:21 pmsclp01 fence_ipmilan: Connection timed out<br>Oct 18 15:30:48 pmsclp01 fence_ipmilan: Connection timed out<br>Oct 18 15:30:48 pmsclp01 root: FAILED CHECKING FENCE DEVICE : CHECK FENCE DEVICE( 42.1.240.108 ) - [ Invalid Status ] or [ Incorrect Login credentials ]<br>Oct 18 15:31:48 pmsclp01 root: FAILED CHECKING FENCE DEVICE : FENCE DEVICE( 42.1.240.108 ) is UNREACHABLE.<br>Oct 18 15:35:21 pmsclp01 fence_ipmilan: Connection timed out<br>Oct 18 15:35:48 pmsclp01 fence_ipmilan: Connection timed out<br>Oct 18 15:35:48 pmsclp01 root: FAILED CHECKING FENCE DEVICE : CHECK FENCE DEVICE( 42.1.240.108 ) - [ Invalid Status ] or [ Incorrect Login credentials ]<br>Oct 18 15:36:48 pmsclp01 root: FAILED CHECKING FENCE DEVICE : FENCE DEVICE( 42.1.240.108 ) is UNREACHABLE.<br>Oct 18 15:40:21 pmsclp01 fence_ipmilan: Connection timed out<br>Oct 18 15:40:48 pmsclp01 fence_ipmilan: Connection timed out<br>Oct 18 15:40:48 pmsclp01 root: FAILED CHECKING FENCE DEVICE : CHECK FENCE DEVICE( 42.1.240.108 ) - [ Invalid Status ] or [ Incorrect Login credentials ]<br>Oct 18 15:40:54 pmsclp01 root: FAILED CHECKING FENCE DEVICE : FENCE DEVICE( 42.1.240.108 ) is UNREACHABLE.<br>Oct 18 15:40:57 pmsclp01 root: FAILED CHECKING FENCE DEVICE : FENCE NETWORK( 42.1.231.1 ) is UNREACHABLE.<br>*****************************************************************************************************************<br><br>지원에 미리 감사 드립니다.<br>고맙습니다.<br><br>(Huang, Ying에 회신)<br>&gt; 안녕하세요,<br>&gt; <br>&gt; Red Hat Global Support Services를 이용해주셔서 감사합니다.<br>&gt; <br>&gt; 클러스터는 한쪽 노드에 이슈가 발생될 경우 정상적인 노드에서 이슈가 발생된 노드에 팬싱 신호를 보내게 되며<br>&gt; 해당 팬싱 작업이 정상적으로 실행된후 다른 노드로 서비스를 이동하게 됩니다.<br>&gt; 이는 이슈가 발생된 서버가 자원을 사용하고 있어 기타 노드에서 서비스를 기동하는것이 실패되는것을 방지하기 위합니다.<br>&gt; <br>&gt; 따라서 해당 케이스 처럼 팬싱 망이 복구된후 서비스가 정상적으로 페어오버 작업을 진행하게 됩니다.<br>&gt; <br>&gt; 감사합니다.<br><br><publishedDate>2016-11-09T07:16:32Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000I9OocIAF"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2016-10-31T06:03:12Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2016-10-31T06:03:12Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>클러스터는 한쪽 노드에 이슈가 발생될 경우 정상적인 노드에서 이슈가 발생된 노드에 팬싱 신호를 보내게 되며<br>해당 팬싱 작업이 정상적으로 실행된후 다른 노드로 서비스를 이동하게 됩니다.<br>이는 이슈가 발생된 서버가 자원을 사용하고 있어 기타 노드에서 서비스를 기동하는것이 실패되는것을 방지하기 위합니다.<br><br>따라서 해당 케이스 처럼 팬싱 망이 복구된후 서비스가 정상적으로 페어오버 작업을 진행하게 됩니다.<br><br>감사합니다.<br><br><publishedDate>2016-10-31T06:03:12Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000I9Lv3IAF"><br>======================<br><b>생성계정 : os, support</b><br><b>생성날짜 : 2016-10-30T13:08:22Z</b><br><b>마지막 답변자 : os, support</b><br><b>마지막 수정 일자 : 2016-10-30T13:08:22Z</b><br><br>올려드린 sosreport 의 로그를 보시면<br><br><br>Oct 18 15:25:21 pmsclp01 fence_ipmilan     : Connection timed out<br><br>로그가 발생합니다. 이 당시 상황이 서비스 망과 fenceing 망 이 모두 문제가 발생하여 통신이 불가 하던 상태였습니다.<br><br>이후 Oct 18 15:41:12 부터  서비스 아이피가 클러스터 2번 노드로 이동한 것이 보입니다.<br>여기서 16분이란 질문을 드린것입니다.<br><br>이 시점이 서비스망 과 펜싱망 네트워크가 복구 된것 으로 보입니다.<br><br>그렇다면 서비스망과 펜싱망이 동시에 문제가 발생시 클러스터는 서비스망 이나 펜싱만에 복구 될때까지 아무런 동작을 못하는것인지요?<br><br>서비스망과 펜싱망이 문제가 발생시 클러스터가 동작하는 메카니즘을 알고싶습니다.<br><br><publishedDate>2016-10-30T13:08:22Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HzGsiIAF"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2016-10-21T07:10:22Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2016-10-21T07:10:22Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>테스트를 진행한 시점이 어떻게 되는지요?<br>지연이 16분 되는 현상은 어떻게 확인하신것인가요?<br>또한 테스트를 어떻게 진행한 것인지 확인 부탁드립니다. (예를 들어 pmsclp02의 서비스 망 케이블 절제)<br><br>감사합니다.<br><br><publishedDate>2016-10-21T07:10:22Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000Hz2q2IAB"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2016-10-20T08:25:07Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2016-10-20T08:25:07Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>좀 더 상세한 원인 분석을 위하여 이슈 발생 시점 명시 및 두 노드의 sosreport를 케이스에 업로드 부탁드립니다.<br><br>감사합니다.<br><br><publishedDate>2016-10-20T08:25:07Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br>    - 성함(직급) :손향준 사원<br><br>    - 회사명(부서명) : 금융시스템그룹(금융/서비스)/삼성SDS<br>    - 전화번호 :02-509-0318<br>    - 메일주소 :h2014.son@samsung.com<br><br>* 파트너 정보 (옵션) - 실제 고객의 시스템을 유지보수하는 업체<br>    - 성함(직급) :이승훈 수석보<br>    - 회사명(부서명) : 타임게이트(os팀)<br>    - 전화번호 :010-5493-0769<br>    - 메일주소 :sh.lee@time-gate.com<br><br>*  문제 설명 (Description)<br>   - 증상 : heartbeat 이중화 구성된 시스템에서 서비스망 절제시 pings 데몬이 서비스 절제 감지후 서비스 전환까지 16분 소요됨<br>   - 발생 시점 : 서비스망 절제시<br>   - 발생 빈도 : 일시적<br>   - 문의 내용(기대 답변) :<br> <br>heartbeat 망이 동작하고 서비스 망과  fence망은  둘다 절제 되었을 경우<br>pingd 에서 실제 서비스를 올리는 시간까지 기대보다 많은 시간이 소요됩니다.<br><br>sosreport 는 추가 첨부로 올려드리겠습니다.</issue><cep>false</cep><folderName>ERP-ALL</folderName></case>