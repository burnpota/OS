======================<br><b>생성계정 : 우택 심</b><br><b>생성날짜 : 2016-02-04T05:40:16Z</b><br><b>마지막 답변자 : JINKOO HAN</b><br><b>마지막 수정 일자 : 2016-03-07T02:03:41Z</b><br><b>id : 500A000000TStiuIAD</b><br>======================<br><br><b><font size=15>
제목  : kernel: XFS (dm-22): xfs_log_force: error -5 returned. 에러 문의
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요. <br><br>금주 SAN 스토리지 가용성 테스트를 진행 중에 있는데요,<br><br>어제 스토리지 컨트롤러 절체 테스트 중 아래와 같은 심각한 XFS 관련 에러가 떨어지면서 해당 볼륨이 마운트 된 디렉토리에 접근이 안되는 문제가 발생하였습니다.<br><br>로그를 확인한 결과 2016-02-24 09:50 전후로 발생하였으며, multipath 및 LVM 상태는 문제가 없어 보였으나, 실제 디렉토리에 접근 후 ls 명령으로 파일을 볼때 I/O 에러가 발생하는 현상이 발생하였습니다.<br><br>로그 내용과 몇 가지 정보를 수집하였으며, sosreport 및 shutdown 시 생성 된 vmcore 는 외부 반출이 당장 힘들어 dropbox 에 별도로 업로드 하고 코멘트 추가로 달도록 하겠습니다.<br><br>문의 드리고자 하는 내용은 문제 발생에 대한 원인 분석도 있지만 <br><br>1. Hitachi Storage GAD 환경에서 컨트롤러 절체 테스트 시 SCSI LUN 단절로 인한 문제<br>2. multipath 환경에서 버그<br>3. XFS 파일시스템 자체 버그<br><br>가능성이 있는지 확인하고 싶습니다.<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>이번 문제는 물리시스템 27ea 중 특정 ECC 업무 중 3노드에서만 발생하였으며, <br><br>스토리지 컨트롤러 절체 시 SAP AP 를 설치 중이라 I/O 부하가 발생되고 있었습니다.<br><br>스토리지 가용성 테스트 과정을 살펴보면 아래와 같이 진행 되었습니다.<br>* (A 컨트롤러 : 원장 / B 컨트롤러 : 이중화)<br><br>1. 2016-02-03 A 컨트롤러 Down -&gt; path 절반 offline<br>2. 2016-02-03 B 컨트롤러 Active 넘어 옴<br>3. 2016-02-03 A 컨트롤러 Up -&gt; path 정상으로 원복 (19:00 경)<br>4. 2016-02-04 B 컨트롤러 데이터 -&gt; A 컨트롤러 영역으로 역복제 (Sync)<br>5. 2016-02-04 A 컨트롤러 Active Role Change -&gt; 이때 장애 발생<br><br>언제 문제가 발생했습니까? 이러한 문제가 자주 발생합니까? 반복적으로 발생합니까? 특정 시간에 발생합니까?<br><br>스토리지 컨트롤러 절체 과정에서 발생되는 현상이며, <br><br>추가적으로 관련 데이터를 업데이트 하겠습니다.<br><br>감사합니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 3 (Normal)</b><br><enhancedSLA>false</enhancedSLA><contactIsPartner>false</contactIsPartner><tags/><br><br><comment id="a0aA000000GdBoLIAV"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-03-07T02:03:38Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-03-07T02:03:38Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>약 4주간 본 케이스에 추가 업데이트가 없어서 본 케이스를 Close하도록 하겠습니다.<br><br>본 케이스가 Close되더라도 추가문의사항이 있으시면 해당 케이스를 &quot;Re-open&quot;하셔도 되고, 새로운 문의사항은 새로운 케이스를 오픈하시면 해당 케이스를 통해서 지원하도록 하겠습니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-03-07T02:03:38Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GXr7SIAT"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-02-15T04:31:38Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-02-15T04:31:38Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>Feb 4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>Feb 4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 Sense Key : Illegal Request [current]<br>Feb 4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 Add. Sense: Logical unit not supported<br><br>문의주신 내용에 대한 설명은 일전에 한 번 설명을 드렸으며, 다시 설명을 아래와 같이 다시 한 번 드립니다.<br><br><br>우선 해당 메시지는 SCSI Layer에서 발생하는 에러이며, 해당 메시지는 SCSI에서 Storage와 상태 정보를 확인하는 과정(Health-check 등)에서 발생하는 메시지 입니다.<br><br>현재 메시시는 Storage와의 연결상태가 현재 정상적이지 못하다는 의미로 해석이되며, 이러한 Sense Key가 발생할 경우에는 일반적으로 스토리지 벤더 쪽으로 당시의 스토리지 상태 또는 스토리지와의 연결에 관련된 (HBA, SAN Switch 및 Cable  등)에 대한 점검을 요하는 상태입니다.<br><br>하지만 현재 테스트를 하는 과정에서 발생한 점을 감안한다면, 해당 메시지는 SCSI Layer에서 스토리지와의 통신시에 현재 스토리지가 정상적으로 동작하지 못하고 있는 것으로 추정되는 메시지 입니다.<br><br>업무에 참고하시기 바라며, 더 정확한 것은 당시 Storage의 상태가 어떤 상태였고 실제로 정상적인 동작을 하고 있는상태인지에 대한 여부를 하드웨어 벤더를 통해서 확인하시기 바랍니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-02-15T04:31:38Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GXXuqIAH"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-02-13T14:53:37Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-02-13T14:53:37Z</b><br><br>안녕하세요.<br><br>답변 주신 내용 중 <br><br>Feb 4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>Feb 4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 Sense Key : Illegal Request [current]<br>Feb 4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 Add. Sense: Logical unit not supported<br><br>항목에 대해 SCSI가 스토리와의 통신가운데 발생하는 것으로 말씀하셨는데요,<br><br>그렇다면 위 메세지가 나올 수 있는 상황 그리고 메세지가 의미하는 정확한 의미를 알고 싶습니다.<br><br>이번 문제의 볼륨 중 문제가 되었던 SAP LUN 중 이중화 Controller 에서 비롯 된 LUN 만 위의 에러 메세지가 발생하였습니다.<br><br>확인 부탁 드립니다.<br><br>감사합니다.<br><br><publishedDate>2016-02-13T14:53:37Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GX8wUIAT"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-02-11T08:50:07Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-02-11T10:53:32Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>현재 유선으로 통화를 했듯이, 본 케이스는 다른 케이스(#01578530)의 원인으로 발생한 것으로 보입니다.<br>또한 추가 문의주신 내용도 다른 케이스의 방향에 해당하는 내용으로 해당 케이스를 통해서 처리할 수 있도록 하겠습니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-02-11T08:50:07Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GX7yrIAD"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-02-11T06:24:44Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-02-11T06:24:44Z</b><br><br>안녕하세요.<br><br>PECCAL01SL 기준으로 multiapth SAP100G001 볼륨에 대해 시간대 별 로그 기록을 추적해 보니 아래와 같은 결과가 나왔습니다.<br><br>SCSI 2:0:1:0 , 3:0:1:0 =&gt; 원장 Controller<br>SCSI 2:0:0:0 , 3:0:0:0 =&gt; 이중화 Controller<br><br>- SCSI 2:0:1:0 , 3:0:1:0 -&gt; Feb 3 16:10:49 최초 Link Down 및 dev removed<br>- SCSI 2:0:0:0 , 3:0:0:0 -&gt; Feb 4 09:48:56 GAD Role Change 후 FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE  및  logical unit not supported 에러 발생<br>- SCSI 3:0:1:0 -&gt; Feb 4 10:26:19 LUN Recovery (수동으로 scsi-rescan 추정)<br><br>위의 볼륨 상태 외에 SCSI 2:0:1:0 볼륨은 아예 복원이 이루어 지지 않고 loss 된 걸로 보고 있습니다.<br>그리고 Hitachi GAD 의 Role Change 할 시점에 SCSI 2:0:1:0 과 3:0:1:0 LUN 은 Recovery 가 안된 상태에서 진행이 된 걸로 보입니다.<br><br>Q1)<br>현재 multipath 의 설정 no_path_retry fail 로 되어 있는데요, GAD Role Change 시 I/O 에 약간의 Delay 가 생긴다면, <br>이때 나머지 LUN 도 offline 으로 감지되어 이번 에러가 나올 수 있는지 연관 관계에 대해서도 문의 드립니다.<br><br>Q2)<br>no_path_retry 에 설정한 값이 5라고 한다면, retry interval은 어떠한 기준으로 값이 계산되는지 문의 드립니다.<br>( GAD Role Change 시 발생하는 I/O delay에 대한 버퍼를 목적으로 설정한다고 가정 )<br><br>감사합니다.<br><br><publishedDate>2016-02-11T06:24:44Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GATMWIA5"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-02-05T12:11:05Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-02-05T12:11:05Z</b><br><br>안녕하세요. 보다 정확한 분석을 위해 sosreport 및 /var/log 파일을 dropbox 에 업로드 했습니다.<br><br>파일명은 아래와 같습니다.<br><br>01578254_PECCAL01SL_log.tar.gz <br>01578254_sosreport-PECCAL01SL-20160204103403.tar.xz<br>01578254_PECCAL02SL_log.tar.gz <br>01578254_sosreport-PECCAL02SL-20160204103337.tar.xz<br><br>확인 부탁 드립니다.<br><br>감사합니다.<br><br><publishedDate>2016-02-05T12:11:05Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GAOWrIAP"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-02-05T02:10:03Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-02-05T02:10:03Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>자세한 상황 설명에 대해서 감사합니다.<br><br>&quot;여러 SAN Lun 으로 묶여진 VG 중 일부 (/usr/sap 쪽 볼륨)만 I/O Error 가 발생했다는 것&quot; 부분에서, 앞서 이야기 드린 것 처럼, 현재 장애는 SCSI Layer에서 발생한 것입니다. 어떤 타이밍 이슈 또는 스토리지 내부에서의 이슈에 의해서 SCSI 통신에 에러가 발생된 것이로, 그로 인하여 해당 로그를 출력한 것입니다.<br><br>Feb  4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>Feb  4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 Sense Key : Illegal Request [current]<br>Feb  4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 Add. Sense: Logical unit not supported<br><br><br>일반적으로 SCSI Layer의 이슈는 OS에서 알기는 어렵습니다. 왜냐하면 SCSI가 스토리와의 통신가운데 발생하는 것이 때문에 특별한 로그가 없을 가능성이 높습니다. 스토리지 벤더에서 이러한 Sense Key정보와 함께 로그를 함께 의뢰하여 기술지원을 받는 것을 권고드리며, 추가적으로 sosreport와 vmcore를 올려주시면 추가적으로 관련된 이슈에 관련되어 혹시 어떤 정보와 이슈가 있는지 기술지원을 하도록 하겠습니다.<br>======================<br>새해 복 많이 받으세요~<br>감사합니다.<br><br><publishedDate>2016-02-05T02:10:03Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GAFonIAH"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-02-04T14:28:59Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-02-04T14:28:59Z</b><br><br>안녕하세요.<br><br>문제가 발생했던 히스토리를 좀 더 업데이트 해 보면 아래와 같습니다.<br><br>* (A 컨트롤러 : 원장 / B 컨트롤러 : 이중화)<br>1. 원장 A 컨트롤러 Down (Multipath 2path 중 1 path 단절)<br>2. A 컨트롤러가 Down 되었으므로, 이중화 B 컨트롤러가 Primary 권한 가져옴<br>3. 원장 A 컨트롤러 Up<br>4. 이중화 B 컨트롤러 쪽 데이터를 원장 A 컨트롤러 쪽 영역에 Resync. (sync 가 완료되면 이때 단절 된 1 Path 가 활성화 됨)<br>5. 이중화 B 컨트롤러의 Primary 권한을 A 컨트롤러에 Role Change<br><br>4번 작업 Resync 가 아마도 2월3일 새벽에 정상적으로 종료가 되어 자동으로 단절 된 1 Path 가 Active 되었으리라 추측되는데, <br><br>문제는 ECC 업무 중 3 노드에서만 장애가 감지되었으며, 특이한 점은 여러 SAN Lun 으로 묶여진 VG 중 일부 (/usr/sap 쪽 볼륨)만 I/O Error 가 발생했다는 것 입니다.<br><br>아직 sosreport 와 vmcore  파일을 올리지 못했는데, 내일 중으로 업로드 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-02-04T14:28:59Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GABJVIA5"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-02-04T06:41:44Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-02-04T06:41:43Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>우선 보내주신 데이터를 확인해 본 결과를 아래와 같이 공유 드립니다.<br><br>우선 Storage단에서 Controller를 옮겨오고 Sync 후에 Role Change 작업시에 스토리단에 이슈가 있었던 것으로 유추됩니다.<br><br>1. 2016-02-03 A 컨트롤러 Down -&gt; path 절반 offline<br>2. 2016-02-03 B 컨트롤러 Active 넘어 옴<br>3. 2016-02-03 A 컨트롤러 Up -&gt; path 정상으로 원복 (19:00 경)<br>4. 2016-02-04 B 컨트롤러 데이터 -&gt; A 컨트롤러 영역으로 역복제 (Sync)<br>5. 2016-02-04 A 컨트롤러 Active Role Change -&gt; 이때 장애 발생<br><br>이유인 즉, 아래 보시는 것 처럼, Sense Key: Illegal Request [current] 가 발생하고 있으며 즉, SCSI layer에서의 응답이 스토리지와 정상적이지 못함에따라 해당 Sense Key가 발생한 것으로 유추됩니다.<br><br>Feb  4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>Feb  4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 Sense Key : Illegal Request [current]<br>Feb  4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 Add. Sense: Logical unit not supported<br>Feb  4 09:48:37 PECCAL02SL kernel: sd 3:0:0:0: [sdah] tag#0 CDB: Write(10) 2a 00 09 a0 59 06 00 00 03 00<br>Feb  4 09:48:37 PECCAL02SL kernel: blk_update_request: I/O error, dev sdah, sector 161503494<br>Feb  4 09:48:37 PECCAL02SL kernel: device-mapper: multipath: Failing path 66:16.<br>Feb  4 09:48:37 PECCAL02SL kernel: blk_update_request: I/O error, dev dm-1, sector 161503494<br>Feb  4 09:48:37 PECCAL02SL kernel: blk_update_request: I/O error, dev dm-1, sector 161503494<br><br><br>SAP100G001 (360060e8007c7fb000030c7fb00001003) dm-1 HITACHI ,OPEN-V<br>size=100G features='0' hwhandler='0' wp=rw<br>`-+- policy='service-time 0' prio=1 status=active<br>  |- 2:0:0:0  sdai 66:32  active ready running<br>  |- 2:0:1:0  sdad 65:208 active ready running<br>  |- 3:0:0:0  sdah 66:16  active ready running   &lt;&lt;------- <br>  `- 3:0:1:0  sdaf 65:240 active ready running<br>======================<br>이에따라, 관련 파일시스템이 umount 된 것으로 보입니다. storage단에서 Active Role Change가 된 이후 정상적으로 동작하고 있는지 여부에 대해서 스토리지 벤더에 문의하여 주시기 바랍니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-02-04T06:41:43Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GAAwRIAX"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-02-04T05:56:21Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-02-04T05:56:21Z</b><br><br>안녕하세요,<br>Red Hat Technical Account Manager 한진구 입니다.<br><br>현재 올려주신 케이스에 대해서 검토를 시작하도록 하겠습니다.<br><br>그리고.. 현재 설정된 Severity를 2에서 3으로 조절하도록 하겠습니다.<br>Severity가 조절되더라도 본 케이스는 제가 담당할 예정입니다.<br><br><br>업무에 참고하시기 바랍니다.<br><br>감사합니다.<br><br><publishedDate>2016-02-04T05:56:21Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GAApLIAX"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-02-04T05:41:37Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-02-04T05:41:37Z</b><br><br>수집한 로그 데이터 TEXT 파일을 첨부합니다.<br><br>sosreport 와 vmcore 는 dropbox 에 업로드 하겠습니다.<br><br><publishedDate>2016-02-04T05:41:37Z</publishedDate><createdByType>Customer</createdByType><br>======================<br></comments><br><br>금주 SAN 스토리지 가용성 테스트를 진행 중에 있는데요,<br><br>어제 스토리지 컨트롤러 절체 테스트 중 아래와 같은 심각한 XFS 관련 에러가 떨어지면서 해당 볼륨이 마운트 된 디렉토리에 접근이 안되는 문제가 발생하였습니다.<br><br>로그를 확인한 결과 2016-02-24 09:50 전후로 발생하였으며, multipath 및 LVM 상태는 문제가 없어 보였으나, 실제 디렉토리에 접근 후 ls 명령으로 파일을 볼때 I/O 에러가 발생하는 현상이 발생하였습니다.<br><br>로그 내용과 몇 가지 정보를 수집하였으며, sosreport 및 shutdown 시 생성 된 vmcore 는 외부 반출이 당장 힘들어 dropbox 에 별도로 업로드 하고 코멘트 추가로 달도록 하겠습니다.<br><br>문의 드리고자 하는 내용은 문제 발생에 대한 원인 분석도 있지만 <br><br>1. Hitachi Storage GAD 환경에서 컨트롤러 절체 테스트 시 SCSI LUN 단절로 인한 문제<br>2. multipath 환경에서 버그<br>3. XFS 파일시스템 자체 버그<br><br>가능성이 있는지 확인하고 싶습니다.</issue><environment>이번 문제는 물리시스템 27ea 중 특정 ECC 업무 중 3노드에서만 발생하였으며, <br><br>스토리지 컨트롤러 절체 시 SAP AP 를 설치 중이라 I/O 부하가 발생되고 있었습니다.<br><br>스토리지 가용성 테스트 과정을 살펴보면 아래와 같이 진행 되었습니다.<br>* (A 컨트롤러 : 원장 / B 컨트롤러 : 이중화)<br><br>1. 2016-02-03 A 컨트롤러 Down -&gt; path 절반 offline<br>2. 2016-02-03 B 컨트롤러 Active 넘어 옴<br>3. 2016-02-03 A 컨트롤러 Up -&gt; path 정상으로 원복 (19:00 경)<br>4. 2016-02-04 B 컨트롤러 데이터 -&gt; A 컨트롤러 영역으로 역복제 (Sync)<br>5. 2016-02-04 A 컨트롤러 Active Role Change -&gt; 이때 장애 발생</environment><periodicityOfIssue>스토리지 컨트롤러 절체 과정에서 발생되는 현상이며, <br><br>추가적으로 관련 데이터를 업데이트 하겠습니다.<br><br>감사합니다.</periodicityOfIssue><cep>false</cep></case>