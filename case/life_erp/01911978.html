======================<br><b>생성계정 : jimin kim</b><br><b>생성날짜 : 2017-08-16T03:04:58Z</b><br><b>마지막 답변자 : Ying Huang</b><br><b>마지막 수정 일자 : 2017-09-05T10:08:10Z</b><br><b>id : 500A000000Y6awFIAR</b><br>======================<br><br><b><font size=15>
제목  : systemd-sysctl.service 적용 관련 문의
</font></b><br><br>======================<br><b>사전문의<br></b><br>안녕하세요<br><br>SDS 김지민 선임입니다.<br><br>systemd-sysctl.service 적용 관련 문의를 드리려고 합니다.<br><br>NAS를 사용하고 있는 서버에서 NAS 업체로 부터 아래와 같이 <br>sunrpc.tcp_max_slot_table_entries = 128 값 적용을 권고받아서 적용을 하고 rebooting을 하였습니다.<br> <br>root@DECCCL02SL /etc/sysctl.d # grep sunrpc ./99-sysctl.conf<br>sunrpc.tcp_max_slot_table_entries = 128<br>아래와 같이 파라미터 값이 OS에는 적용은 되어있는 상태인데<br>root@DECCCL02SL /etc/sysctl.d # sysctl -a | grep -i sunrpc.tcp_max<br>sunrpc.tcp_max_slot_table_entries = 128<br><br>실제로 부팅 과정에서 보면 먼저 NFS 영역이 mount가 된 후 나중에 파라미터가 적용되는 것 처럼 보여서 실제로 해당 권고 받은 값이 정상적으로 적용이 되었는지 확인하는 방법에 대해서 문의드리려고 합니다.<br><br>root@DECCCL02SL /sysadmin/work/170816 # grep -E &quot;mount|sysctl&quot; ./systemd-analyze.lst<br>           462ms CRASH.mount<br>           356ms usr-sap.mount<br>           198ms oracle.mount<br>            83ms boot.mount<br>            83ms APP.mount<br>            75ms usr-sap-REC-ERS55.mount<br>            74ms sapmnt-REC.mount                        ← NFS mount<br>            73ms SAPP.mount                                     ← NFS mount<br>            73ms usr-sap-trans.mount                      ← NFS mount<br>            69ms usr-sap-REC-ASCS50.mount     ← NFS mount<br>            60ms home.mount<br>            36ms var.mount<br>            20ms proc-fs-nfsd.mount<br>            17ms sysadmin.mount<br>             5ms sys-kernel-debug.mount<br>             4ms dev-hugepages.mount<br>             4ms var-lib-nfs-rpc_pipefs.mount<br>             3ms proc-sys-fs-binfmt_misc.mount<br>             3ms systemd-sysctl.service                        ← 파라미터 적용 시점?<br>             2ms dev-mqueue.mount<br>             2ms systemd-remount-fs.service<br>             1ms sys-fs-fuse-connections.mount<br>             1ms sys-kernel-config.mount<br><br>전체 systemd-analyz 리스트도 첨부합니다.<br><br>root@DECCCL02SL /sysadmin/work/170816 # cat systemd-analyze.lst<br>         15.020s network.service<br>         10.118s hp-ams.service<br>          3.394s ntpdate.service<br>          2.789s plymouth-quit-wait.service<br>          2.788s plymouth-quit.service<br>          1.578s opsware-agent.service<br>          1.135s hpsmhd.service<br>           683ms kdump.service<br>           668ms systemd-udev-settle.service<br>           561ms corosync.service<br>           462ms CRASH.mount<br>           356ms usr-sap.mount<br>           339ms pcsd.service<br>           277ms netbackup.service<br>           232ms dev-sda2.device<br>           198ms oracle.mount<br>           187ms hp-health.service<br>           168ms lvm2-activation-early.service<br>           101ms sapinit.service<br>            83ms boot.mount<br>            83ms APP.mount<br>            83ms systemd-journal-flush.service<br>            76ms systemd-random-seed.service<br>            75ms usr-sap-REC-ERS55.mount<br>            74ms sapmnt-REC.mount<br>            73ms SAPP.mount<br>            73ms usr-sap-trans.mount<br>            70ms hp-asrd.service<br>            69ms usr-sap-REC-ASCS50.mount<br>            60ms home.mount<br>            57ms vxpbx_exchanged.service<br>            36ms var.mount<br>            35ms systemd-udevd.service<br>            35ms rpc-statd.service<br>            32ms systemd-vconsole-setup.service<br>            32ms polkit.service<br>            30ms lvm2-activation.service<br>            30ms lvm2-activation-net.service<br>            25ms dev-disk-by\x2duuid-c5e4ac32\x2d0e97\x2d45da\x2d8740\x2dec0b1f4ede14.swap<br>            24ms systemd-fsck@dev-disk-by\x2duuid-7627fb94\x2d2ffd\x2d4f0c\x2daa0f\x2de59e2cd6f83a.service<br>            23ms systemd-update-utmp.service<br>            23ms multipathd.service<br>            23ms systemd-fsck@dev-disk-by\x2duuid-c0ce4270\x2d65a0\x2d433c\x2da4b8\x2d6e3d7d2b1405.service<br>            21ms rc-local.service<br>            20ms proc-fs-nfsd.mount<br>            20ms systemd-udev-trigger.service<br>            17ms systemd-fsck@dev-LLDECCSAPVG-usr_sap_REC_ERS55.service<br>            17ms iptables.service<br>            17ms sysadmin.mount<br>            16ms lvm2-pvscan@8:6.service<br>            16ms ontunev4.service<br>            14ms systemd-fsck@dev-LLDECCSAPVG-APP.service<br>            14ms cpupower.service<br>            14ms systemd-tmpfiles-clean.service<br>            14ms systemd-fsck@dev-vg0-sysadmin.service<br>            13ms systemd-tmpfiles-setup-dev.service<br>            13ms sysstat.service<br>            13ms plymouth-start.service<br>            13ms rsyslog.service<br>            12ms plymouth-read-write.service<br>            12ms rhel-dmesg.service<br>            12ms systemd-fsck@dev-LLDECCSAPVG-oracle.service<br>            12ms systemd-fsck@dev-vg0-home.service<br>            12ms gssproxy.service<br>            12ms systemd-fsck@dev-LLDECCSAPVG-usr_sap.service<br>            11ms GMAgent.service<br>            11ms systemd-fsck-root.service<br>            10ms systemd-fsck@dev-vg9-CRASH.service<br>             9ms rhel-readonly.service<br>             7ms systemd-journald.service<br>             7ms xinetd.service<br>             6ms rpc-statd-notify.service<br>             6ms systemd-logind.service<br>             6ms systemd-binfmt.service<br>             5ms lvm2-pvscan@253:0.service<br>             5ms systemd-tmpfiles-setup.service<br>             5ms sys-kernel-debug.mount<br>             5ms lvm2-pvscan@253:3.service<br>             5ms ntpd.service<br>             4ms dev-hugepages.mount<br>             4ms var-lib-nfs-rpc_pipefs.mount<br>             4ms rhel-import-state.service<br>             3ms systemd-readahead-replay.service<br>             3ms proc-sys-fs-binfmt_misc.mount<br>             3ms lvm2-pvscan@253:2.service<br>             3ms systemd-sysctl.service<br>             3ms kmod-static-nodes.service<br>             3ms lvm2-pvscan@253:1.service<br>             2ms microcode.service<br>             2ms dev-mqueue.mount<br>             2ms systemd-remount-fs.service<br>             2ms systemd-readahead-collect.service<br>             2ms rpcbind.service<br>             2ms nfs-config.service<br>             1ms systemd-update-utmp-runlevel.service<br>             1ms sys-fs-fuse-connections.mount<br>             1ms sys-kernel-config.mount<br>             1ms systemd-user-sessions.service<br>           900us systemd-readahead-done.service<br>           776us blk-availability.service<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>타입  : Other</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 3 (Normal)</b><br><hostname>DECCCL02SL</hostname><br><br><br><comment id="a0aA000000IsdalIAB"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2017-08-21T07:27:50Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2017-08-21T07:27:49Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>&gt; 아래와 같이  /proc/sys/sunrpc/tcp_max_slot_table_entries 결과만 설정된 값으로 확인이 되면 <br>&gt; https://access.redhat.com/solutions/69275 내용과 관련된 문제 사항은 없다고 확인하면 되는지 문의드리려고 합니다.<br><br>네, 상기 파일로 적용 여부를 확인하시면 됩니다.<br><br>감사합니다.<br><br><publishedDate>2017-08-21T07:27:49Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IscJ2IAJ"><br>======================<br><b>생성계정 : kim, jimin</b><br><b>생성날짜 : 2017-08-21T05:11:16Z</b><br><b>마지막 답변자 : kim, jimin</b><br><b>마지막 수정 일자 : 2017-08-21T05:11:16Z</b><br><br>안녕하세요 <br><br>답변감사드립니다.<br><br>추가로 아래는 6버전의 redhat OS에서 제가 문의드린 내역과 동일한 설정이되어있는 서버인데요.<br><br>아래와 같이  /proc/sys/sunrpc/tcp_max_slot_table_entries 결과만 설정된 값으로 확인이 되면 <br>https://access.redhat.com/solutions/69275 내용과 관련된 문제 사항은 없다고 확인하면 되는지 문의드리려고 합니다.<br><br>서버쪽 확인 내역입니다.<br><br>root@PDSSAL01SL / # cat /proc/sys/sunrpc/tcp_max_slot_table_entries<br>128<br><br>root@PDSSAL01SL / # cat /etc/redhat-release<br>Red Hat Enterprise Linux Server release 6.5 (Santiago)<br>root@PDSSAL01SL / # uname -a<br>Linux PDSSAL01SL 2.6.32-431.66.1.el6.x86_64 #1 SMP Fri Oct 2 13:15:53 EDT 2015 x86_64 x86_64 x86_64 GNU/Linux<br><br>root@PDSSAL01SL / # tail -15 /etc/sysctl.conf<br>kernel.shmmax = 102005473280<br>kernel.shmall = 6375342080<br><br>### 201707 advice from HITACHI for NAS ###<br>sunrpc.tcp_max_slot_table_entries = 128<br><br>### PISA ###<br>kernel.numa_balancing = 0<br>kernel.numa_balancing_scan_delay_ms = 1000<br>kernel.numa_balancing_scan_period_max_ms = 60000<br>kernel.numa_balancing_scan_period_min_ms = 1000<br>kernel.numa_balancing_scan_size_mb = 256<br>kernel.numa_balancing_settle_count = 4<br>net.core.netdev_max_backlog = 8192<br><br><publishedDate>2017-08-21T05:11:16Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000Isb50IAB"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2017-08-21T01:41:06Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2017-08-21T01:41:06Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>RHEL7 버전에서는 관련 문서가 없는것으로 확인되며 저희 환경에서 테스트할 때<br>부팅시 sysctl에 설정된 sunrpc 관련 값이 정상적으로 적용되는것으로<br>확인됩니다.<br><br>감사합니다.<br><br><publishedDate>2017-08-21T01:41:06Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IsMwTIAV"><br>======================<br><b>생성계정 : kim, jimin</b><br><b>생성날짜 : 2017-08-18T13:00:47Z</b><br><b>마지막 답변자 : kim, jimin</b><br><b>마지막 수정 일자 : 2017-08-18T13:00:47Z</b><br><br>안녕하세요 <br><br>제가  RHEL5/6 버전이기는 하지만 아래 내용을 보고서 질문을 드렸었는데요.<br><br>대략적인 내용은 booting시에 sunrpc kernel module이 적재된 후에 sysctl 값이 적용이되어야한다는 내용같은데요. <br>https://access.redhat.com/solutions/69275 <br><br>혹시 RHEL7 버전에서는 해당 관련 문제가 없는 것인지 문의드리려고 합니다.<br><br>제가 처음에 질문을 자세히 잘 못드렸던 것 같습니다.<br><br><publishedDate>2017-08-18T13:00:47Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000KNK2YIAX"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2017-08-18T03:34:05Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2017-08-18T03:34:05Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>파라미터 명이 잘못 안내되었습니다. 죄송합니다.<br><br>아래의 결과를 확인해 보시면 됩니다.<br>말씀주신 설정 적용 여부ㅡㄴ 아래의 파일 출력결과를 확인해 보셔야 합니다.<br># cat /proc/sys/sunrpc/tcp_max_slot_table_entries<br><br>테스트 결과에 의하면 상기 출력결과가 정상적으로 적용 되었다면 NFS 파일시스템 사용에<br>문제가 없는것으로 확인됩니다.<br><br>감사합니다.<br><br><publishedDate>2017-08-18T03:34:05Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000KNJSfIAP"><br>======================<br><b>생성계정 : kim, jimin</b><br><b>생성날짜 : 2017-08-18T01:37:21Z</b><br><b>마지막 답변자 : kim, jimin</b><br><b>마지막 수정 일자 : 2017-08-18T01:37:21Z</b><br><br>안녕하세요 <br><br>알려주신 내역으로 해당 서버에서 수행했을 때 결과는 아래와 같이 보이는데요.<br><br>root@DECCCL02SL /root # cat /proc/sys/sunrpc/tcp_slot_table_entries<br>2<br>128이 설정값인데 /proc/sys/sunrpc/tcp_slot_table_entries의 결과 값이 어떤 값인지 문의드리려고 합니다.<br><br>추가로 booting 순서에서 NAS 영역을 mount 후에 해당 파라미터가 적용되는 것 처럼 보여서<br>sunrpc.tcp_max_slot_table_entries = 128 파라미터가 NAS 영역의 mount 전이나 후에 설정이 되어도 상관이 없는 파라미터인지 문의드리려고 합니다.<br><br><publishedDate>2017-08-18T01:37:21Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000K9tNGIAZ"><br>======================<br><b>생성계정 : Huang, Ying</b><br><b>생성날짜 : 2017-08-16T06:12:33Z</b><br><b>마지막 답변자 : Huang, Ying</b><br><b>마지막 수정 일자 : 2017-08-16T06:12:33Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해 주셔서 감사합니다.<br><br>설정 하신 파라미터가 정상적으로 적용되었는지는 아래 파일 출력 결과를 확인해 보실수 있으십니다.<br><br># cat /proc/sys/sunrpc/tcp_slot_table_entries<br><br>감사합니다.<br><br><publishedDate>2017-08-16T06:12:33Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br>