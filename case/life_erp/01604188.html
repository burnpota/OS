======================<br><b>생성계정 : 우택 심</b><br><b>생성날짜 : 2016-03-21T12:03:02Z</b><br><b>마지막 답변자 : 우택 심</b><br><b>마지막 수정 일자 : 2016-05-23T06:04:35Z</b><br><b>id : 500A000000Tt1nKIAR</b><br>======================<br><br><b><font size=15>
제목  : [BZ] ksoftirqd/0 CPU 100% 점유 이슈 문의
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요.<br><br>VMWare 가상화 환경 Pacemaker Cluster 서비스 노드에서 ksoftirqd/0 프로세스가 CPU core 100% 점유하는 문제가 발견되었습니다.<br><br>시스템 로그상에 아래와 같은 메세지가 지속적으로 발생하고 있습니다.<br><br>Mar 21 14:55:18 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.230003<br>Mar 21 14:55:48 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.139999<br>Mar 21 14:56:01 SLPEAICL01 CROND[54582]: (root) CMD (/usr/lib64/sa/sa1 1 1)<br>Mar 21 14:56:18 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.150002<br>Mar 21 14:56:48 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.089996<br>Mar 21 14:57:01 SLPEAICL01 CROND[54623]: (root) CMD (/usr/lib64/sa/sa1 1 1)<br>Mar 21 14:57:18 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.120003<br>Mar 21 14:57:48 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.070000<br><br>Mar 21 14:58:01 SLPEAICL01 CROND[54674]: (root) CMD (/usr/lib64/sa/sa1 1 1)<br>Mar 21 14:58:01 SLPEAICL01 CROND[54676]: (pcp) CMD ( /usr/libexec/pcp/bin/pmie_check -C)<br><br>Mar 21 14:58:16 SLPEAICL01 kernel: INFO: rcu_sched detected stalls on CPUs/tasks: { 0} (detected by 1, t=80523604 jiffies, g=16963688, c=16963687, q=0)<br>Mar 21 14:58:16 SLPEAICL01 kernel: sending NMI to all CPUs:<br>Mar 21 14:58:16 SLPEAICL01 kernel: NMI backtrace for cpu 1<br>Mar 21 14:58:16 SLPEAICL01 kernel: CPU: 1 PID: 55234 Comm: fence_vmware_so Tainted: P        W  OE  ------------   3.10.0-327.el7.x86_64 #1<br>Mar 21 14:58:16 SLPEAICL01 kernel: Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 09/21/2015<br>Mar 21 14:58:16 SLPEAICL01 kernel: task: ffff88047523d080 ti: ffff8804752a0000 task.ti: ffff8804752a0000<br>Mar 21 14:58:16 SLPEAICL01 kernel: RIP: 0010:[&lt;ffffffff81058d5a&gt;]  [&lt;ffffffff81058d5a&gt;] native_write_msr_safe+0xa/0x10<br>Mar 21 14:58:16 SLPEAICL01 kernel: RSP: 0000:ffff88081e623d78  EFLAGS: 00000046<br>Mar 21 14:58:16 SLPEAICL01 kernel: RAX: 0000000000000400 RBX: 0000000000000001 RCX: 0000000000000830<br>Mar 21 14:58:16 SLPEAICL01 kernel: RDX: 0000000000000001 RSI: 0000000000000400 RDI: 0000000000000830<br>Mar 21 14:58:16 SLPEAICL01 kernel: RBP: ffff88081e623d78 R08: ffffffff81a658e0 R09: 00000000000266a7<br>Mar 21 14:58:16 SLPEAICL01 kernel: R10: 61206f7420494d4e R11: 3a73555043206c6c R12: ffffffff81a658e0<br>Mar 21 14:58:16 SLPEAICL01 kernel: R13: 0000000000000001 R14: 000000000000a022 R15: 0000000000000002<br>Mar 21 14:58:16 SLPEAICL01 kernel: FS:  00007f34d689b740(0000) GS:ffff88081e620000(0000) knlGS:0000000000000000<br>Mar 21 14:58:16 SLPEAICL01 kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033<br>Mar 21 14:58:16 SLPEAICL01 kernel: CR2: 00007f34d68b5000 CR3: 0000000479f2b000 CR4: 00000000001407e0<br>Mar 21 14:58:16 SLPEAICL01 kernel: DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000<br>Mar 21 14:58:16 SLPEAICL01 kernel: DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400<br>Mar 21 14:58:16 SLPEAICL01 kernel: Stack:<br>Mar 21 14:58:16 SLPEAICL01 kernel: ffff88081e623dc8 ffffffff8104fa22 0000000000000096 0000000000000002<br>Mar 21 14:58:16 SLPEAICL01 kernel: 000800001e623da8 0000000000000001 0000000000000001 0000000000000080<br>Mar 21 14:58:16 SLPEAICL01 kernel: ffff88081e62df80 ffffffff819a6880 ffff88081e623dd8 ffffffff8104fac3<br>Mar 21 14:58:16 SLPEAICL01 kernel: Call Trace:<br>Mar 21 14:58:16 SLPEAICL01 kernel: &lt;IRQ&gt;<br>Mar 21 14:58:16 SLPEAICL01 kernel:<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8104fa22&gt;] __x2apic_send_IPI_mask+0xb2/0xe0<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8104fac3&gt;] x2apic_send_IPI_mask+0x13/0x20<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8104b2ad&gt;] arch_trigger_all_cpu_backtrace+0x11d/0x130<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8112695d&gt;] rcu_check_callbacks+0x5bd/0x610<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff810e0620&gt;] ? tick_sched_handle.isra.14+0x60/0x60<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8108e8c7&gt;] update_process_times+0x47/0x80<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff810e05e5&gt;] tick_sched_handle.isra.14+0x25/0x60<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff810e0661&gt;] tick_sched_timer+0x41/0x70<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff810a9d42&gt;] __hrtimer_run_queues+0xd2/0x260<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff810aa2e0&gt;] hrtimer_interrupt+0xb0/0x1e0<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8164721c&gt;] ? call_softirq+0x1c/0x30<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff81049537&gt;] local_apic_timer_interrupt+0x37/0x60<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff81647e8f&gt;] smp_apic_timer_interrupt+0x3f/0x60<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8164655d&gt;] apic_timer_interrupt+0x6d/0x80<br>Mar 21 14:58:16 SLPEAICL01 kernel: &lt;EOI&gt;<br>Mar 21 14:58:16 SLPEAICL01 kernel: Code:<br>Mar 21 14:58:16 SLPEAICL01 kernel: 00 55 89 f9 48 89 e5 0f 32 31 c9 89 c0 48 c1 e2 20 89 0e 48 09 c2 48 89 d0 5d c3 66 0f 1f 44 00 00 55 89 f0 89 f9 48 89 e5 0f 30 &lt;31&gt; c0 5d c3 66 90 55 89 f9 48 89 e5 0f 33 89 c0 48 c1 e2 20 48<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>문제는 클러스터 리소스를 관리하는 crm resource manager 에서 아래와 같이 CPU High load 를 감지하는데요, <br><br>Mar 21 14:55:18 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.230003<br>Mar 21 14:55:48 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.139999<br><br>이와 관련이 되었는지는 확실하지 않지만 Resource 가 SLPEAICL02-HB 로 Failover 되었습니다.<br><br>버그 여부를 확인 부탁 드립니다.<br><br>감사합니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 3 (Normal)</b><br><enhancedSLA>false</enhancedSLA><contactIsPartner>false</contactIsPartner><tags><tag><name>pacemaker</name></tag></tags><br><comment id="a0aA000000H95kxIAB"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-05-23T06:04:22Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-05-23T06:04:22Z</b><br><br>안녕하세요.<br><br>우선 rcupdate 관련 파라미터를 모두 적용하였으며, VMware 환경의 경우 VM의 VMCI 옵션도 Disable 처리 하였습니다.<br><br>모니터링 후 향 후 비슷한 문제가 다시 발생하면 재 오픈 하도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-05-23T06:04:22Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000H4L4HIAV"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-05-04T06:34:07Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-05-04T06:34:07Z</b><br><br>안녕하세요.<br><br>본 이슈와 관련하여 VMWare 에서도 동시에 분석을 진행하였는데요,<br><br>아래와 같은 답변을 받았습니다. 확인 부탁드립니다.<br><br>====================================================================<br><br>보내주신 리눅스 가상머신의 Messages 파일을 확인한 결과 아래와 같이 system crash는 3월 20일 16:40:12부터 매 3분 간격으로  나타납니다. 문제가 고객님의 주장처럼 3월 21일에 처음 발생한 것은 아닌 것으로 보입니다.<br>동일 시간대의 vmkernel log, hostd log  그리고  가상머신의 vmware 로그를 확인하였으나 이슈의 설명에 도움이 될 기록을 확인할 수 없었습니다.<br><br>아래 기록에서는 주로<br><br>    cc1<br>    corosync<br>    fence_vmware_so<br>    ksoftirqd/0<br>    lrmd<br>    swapper/0<br>    swapper/1<br><br>명령들이  NMI dump시에 나타나는 명령들입니다. VMCI와 직접적인 관련성을 입증할 만한 기록은 확인하지 못하였습니다.<br><br>VMware에서는 해당 가상머신의  vmtools 에 대해서 추가적으로 확인하고자 합니다.<br><br>* vmtoolsd -v 명령 실행 결과와<br>* /etc/vmware-tools/locations 파일을<br><br>보내주시기 바랍니다. (클러스터로 구성된 가상머신 모두에서)<br><br>문제의 가상머신은 다른 가상머신과 Red Hat Cluster로 구성된 것으로 짐작됩니다. Redhead Cluster구성이 정확한지 해당 업체에 확인 부탁드립니다. <br>(예를 들면, https://access.redhat.com/solutions/158873 에 대한 점검과 같은)<br><br>Redhat에서 진행중인 SR의 업데이트 부탁 드립니다.<br><br>추가로 가상머신의 구성파일에서 CPU 구성을 보면 아래와 같습니다.<br><br>    numvcpus = &quot;2&quot;<br>    cpuid.coresPerSocket = &quot;2&quot;<br><br>이것은 2 core / 1 socket  vCPU 구성입니다.<br><br>rc_sched detected stalls on CPUs/tasks 가 나타나면서 sending NMI to all CPUs가 나타난 유사 사례에서   nosmp 를 지정하여 해결하였다는 검색 결과가 있습니다. Red Hat 엔지니어와 상의하여 nosmp 적용을 검토해 보시기 바랍니다.<br><br><publishedDate>2016-05-04T06:34:07Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GxxEOIAZ"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-04-26T00:35:28Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-04-26T00:35:28Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>VMCI와 관련되어 패치가 현재 진행중에 있으며 현재 QA상태에 있습니다.<br><br>향후, 특이사항이 있으면 업데이트 하도록 하겠습니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-04-26T00:35:28Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000Gx5UMIAZ"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-04-22T08:02:25Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-04-22T08:02:24Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>본 케이스와 관련되어 업데이트 사항이 있으시면 업데이트 바랍니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-04-22T08:02:24Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GvJJcIAN"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-04-14T05:12:54Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-04-14T05:12:54Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>1. 우선 해당 케이스(#01613154)에도 답변을 드렸듯이, open-vm-tools 버젼 업데이트는 ESXi 버젼에 종속적이 아닌 저희 제품 Red Hat Enterprise Linux 버젼에 종속적입니다.<br><br>2. 현재 RHEL7은 해당 이슈 vmci 와 관련된 것에 대한 RHEL7 은 현재 QA단계로 향후 커널업데이트가 필요한 상황입니다.<br><br>3. 참고로 현재 사용중인 open-vm-tools의 최신 버젼은 9.10.2-4.el7 이고, 현재 사용중인 것으로 알고 있습니다. 추가 업데이트를 작업이 내부적으로 확인되지 않습니다.<br><br>4. 즉, 해당 이슈는 VMCI 기능이 켜짐에 따라 발생한 것으로 kernel안에 VMware에서 넣은 모듈 업데이트는 곧 이뤄질 예정이며, 이에 대한 workaround는 VMware Host에서 해당 기능을 turn off하는 것을 권장하고 있습니다.<br><br>5. 이전에 VMware의 VMCI 기능을 끄는 것으로 회의에서 결정했던 것으로 기억을 하고 있습니다. 왜 다시 해당 기능이 켜져있는지에 대한 확인이 필요하며, 추가적으로 당시 VMware에서도 해당 기능의 default는 turn off를 권고한다고 하였습니다. 그럼에 따라 해당 이슈에 대한 추적 및 확인이 필요해 보입니다.<br><br>6. 또한 해당 케이스의 로그만을 기반으로 했을때 해당 이슈로 인하여 커널에 문제가 발생한 것으로 보임에 따라 해당 시스템의 재부팅 또한 필요하고 해당 기능을 끄는 것을 권고 드립니다. (이번 회의결과와 같이 VMCI가 필요없는 경우...)<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-04-14T05:12:54Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GvISxIAN"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-04-14T02:47:19Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-04-14T02:47:19Z</b><br><br>안녕하세요.<br><br>VMCI 관련 문의를 VMWare 쪽에도 문의 하였으나,<br><br>RHEL7 에 기본 포함되어 있는 open-vm-tools 의 업데이트와 관련된 답변을 받았습니다.<br><br>https://access.redhat.com/support/cases/#/case/01613154 케이스에 보시는 것 처럼<br><br>현재 VMWare 가 ESXi 6.0u1 → ESXi6.0u1b → ESXi 6.0u2 단계로 업데이트 되었는데요,<br><br>저희 open-vm-tools 도 이에 맞춰 업데이트가 필요한지 여부를 확인해야 할 것 같습니다.<br><br><publishedDate>2016-04-14T02:47:19Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000DjYlaIAF"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-04-12T05:37:37Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-04-12T05:37:37Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br><br>넵!! 협의 후, 업데이트 주시기 바랍니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-04-12T05:37:37Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000Gq6uBIAR"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-04-12T03:53:06Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-04-12T03:53:06Z</b><br><br>안녕하세요.<br><br>프로젝트 팀 내부적으로 협의 후 다시 추가로 코멘트 하도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-04-12T03:53:06Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GpgLJIAZ"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-04-11T02:34:41Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-04-11T02:34:40Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>우선 해당 이슈는 RHEL7에 설치된 모듈이 동작하면서 발생했던 이슈로 현재 RHEL7의 패치는 QA단계에 있는 상태입니다.<br><br>그런데 해당 VMware vShhere 패치가 어떤 역할을 하는지는 저희가 정확하게 알수는 없으나, 현재 보여지는 최초 로그는 이전의 VMCI 기능이 켜져있을때 모듈에서 발생하던 에러와 동일한 call trace를 가지고 있습니다.<br><br>Mar 20 16:36:12 SLPEAICL01 kernel: BUG: scheduling while atomic: swapper/0/0/0x10000100<br>Mar 20 16:36:12 SLPEAICL01 kernel: Modules linked in: rpcsec_gss_krb5 nfsv4 dns_resolver nfsv3 nfs fscache RedCastle(POE) iptable_filter vmw_vsock_vmci_transport vsock coretemp crc32_pclmul ghash_clmulni_intel p<br>pdev vmw_balloon aesni_intel lrw gf128mul glue_helper ablk_helper cryptd pcspkr sg vmw_vmci i2c_piix4 shpchp dm_mod parport_pc parport nfsd auth_rpcgss nfs_acl lockd grace sunrpc binfmt_misc ip_tables xfs libcrc32c sr_mod cdrom ata_generic pata_acpi sd_mod crc_t10dif crct10dif_generic crct10dif_pclmul crct10dif_common vmwgfx drm_kms_helper ata_piix ttm crc32c_intel serio_raw drm i2c_core vmxnet3 libata vmw_pvscsi<br>Mar 20 16:36:12 SLPEAICL01 kernel: CPU: 0 PID: 0 Comm: swapper/0 Tainted: P           OE  ------------   3.10.0-327.el7.x86_64 #1<br>Mar 20 16:36:12 SLPEAICL01 kernel: Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 09/21/2015<br>Mar 20 16:36:12 SLPEAICL01 kernel: ffffffff8193c000 fe2e802f374bb4f0 ffff88081e603bb8 ffffffff816351f1<br>Mar 20 16:36:12 SLPEAICL01 kernel: ffff88081e603bc8 ffffffff8162f322 ffff88081e603c28 ffffffff8163a7ad<br>Mar 20 16:36:12 SLPEAICL01 kernel: ffffffff81951440 ffffffff8193ffd8 ffffffff8193ffd8 ffffffff8193ffd8<br>Mar 20 16:36:12 SLPEAICL01 kernel: Call Trace:<br>Mar 20 16:36:12 SLPEAICL01 kernel: &lt;IRQ&gt;  [&lt;ffffffff816351f1&gt;] dump_stack+0x19/0x1b<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8162f322&gt;] __schedule_bug+0x4d/0x5b<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8163a7ad&gt;] __schedule+0x7cd/0x900<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810b5ea6&gt;] __cond_resched+0x26/0x30<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8163abaa&gt;] _cond_resched+0x3a/0x50<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8163abef&gt;] wait_for_completion+0x2f/0x170<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810b8a66&gt;] ? try_to_wake_up+0x1b6/0x300<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81124820&gt;] ? __call_rcu+0x2c0/0x2c0<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810a26ab&gt;] wait_rcu_gp+0x5b/0x80<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810a2630&gt;] ? ftrace_raw_output_rcu_utilization+0x50/0x50<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810af028&gt;] ? __wake_up_common+0x58/0x90<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff811240cb&gt;] synchronize_sched+0x3b/0x50<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa03a99d0&gt;] vmci_event_unsubscribe+0x70/0xb0 [vmw_vmci]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa041a611&gt;] vmci_transport_destruct+0x21/0xe0 [vmw_vsock_vmci_transport]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa03ff867&gt;] vsock_sk_destruct+0x17/0x60 [vsock]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81514bdf&gt;] __sk_free+0x1f/0x170<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81514d51&gt;] sk_free+0x21/0x30<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa041b2bb&gt;] vmci_transport_recv_stream_cb+0x1fb/0x2e0 [vmw_vsock_vmci_transport]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa03a8f1c&gt;] vmci_datagram_invoke_guest_handler+0xbc/0xf0 [vmw_vmci]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa03a9e6f&gt;] vmci_dispatch_dgs+0xcf/0x230 [vmw_vmci]   &lt;&lt;&lt;--------------------------------------<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8108495d&gt;] tasklet_action+0x7d/0x140<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81084b0f&gt;] __do_softirq+0xef/0x280<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8164721c&gt;] call_softirq+0x1c/0x30<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81016fc5&gt;] do_softirq+0x65/0xa0<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81084ea5&gt;] irq_exit+0x115/0x120<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81647db8&gt;] do_IRQ+0x58/0xf0<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8163d0ed&gt;] common_interrupt+0x6d/0x6d<br>Mar 20 16:36:12 SLPEAICL01 kernel: &lt;EOI&gt;  [&lt;ffffffff81058e96&gt;] ? native_safe_halt+0x6/0x10<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8101dbcf&gt;] default_idle+0x1f/0xc0<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8101e4d6&gt;] arch_cpu_idle+0x26/0x30<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810d6305&gt;] cpu_startup_entry+0x245/0x290<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81624e07&gt;] rest_init+0x77/0x80<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81a8d057&gt;] start_kernel+0x429/0x44a<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81a8ca37&gt;] ? repair_env_string+0x5c/0x5c<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81a8c120&gt;] ? early_idt_handlers+0x120/0x120<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81a8c5ee&gt;] x86_64_start_reservations+0x2a/0x2c<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81a8c742&gt;] x86_64_start_kernel+0x152/0x175<br><br><br>해당 vShere Host에서 해당 기능을 사용하지 않게 하는 기능인지에 대해서 VMware 측에 한 번 확인해주시기 바라며, 참고로 아래 첨부한 VMware의 문서상에서도 현재 RHEL7에서는 문제가 해결되지 않은 것으로 보입니다.<br><br>이부분에 대해서 해당 Vendor로 확인 바랍니다.<br><br><br>~~~<br>Currently, there is no resolution for RHEL 7 operating systems.<br><br><br>RHEL 7:<br><br>&lt;Stacktrace&gt;<br>[201414.815949] &lt;IRQ&gt; [&lt;ffffffff815e19ba&gt;] dump_stack+0x19/0x1b<br>[201414.815961] [&lt;ffffffff815dbfe9&gt;] __schedule_bug+0x4d/0x5b<br>[201414.815966] [&lt;ffffffff815e718b&gt;] __schedule+0x78b/0x790<br>[201414.815970] [&lt;ffffffff815e71b9&gt;] schedule+0x29/0x70<br>[201414.815975] [&lt;ffffffff815e50b9&gt;] schedule_timeout+0x209/0x2d0<br>[201414.815981] [&lt;ffffffff8108ec58&gt;] ? __wake_up_common+0x58/0x90<br>[201414.815985] [&lt;ffffffff81090a24&gt;] ? __wake_up+0x44/0x50<br>[201414.815990] [&lt;ffffffff815e76e6&gt;] wait_for_completion+0x116/0x170<br>[201414.815995] [&lt;ffffffff81097700&gt;] ? wake_up_state+0x20/0x20<br>[201414.816001] [&lt;ffffffff810ff6a0&gt;] ? __call_rcu+0x2c0/0x2c0<br>[201414.816008] [&lt;ffffffff810826ab&gt;] wait_rcu_gp+0x5b/0x80<br>[201414.816012] [&lt;ffffffff81082630&gt;] ? ftrace_raw_output_rcu_utilization+0x50/0x50<br>[201414.816016] [&lt;ffffffff8108ec58&gt;] ? __wake_up_common+0x58/0x90<br>[201414.816020] [&lt;ffffffff810fef5b&gt;] synchronize_sched+0x3b/0x50<br>[201414.816027] [&lt;ffffffffa031a9d0&gt;] vmci_event_unsubscribe+0x70/0xb0 [vmw_vmci]<br>[201414.816032] [&lt;ffffffffa032f611&gt;] vmci_transport_destruct+0x21/0xe0<br>[vmw_vsock_vmci_transport]<br>[201414.816037] [&lt;ffffffffa03a0867&gt;] vsock_sk_destruct+0x17/0x60 [vsock]<br>[201414.816044] [&lt;ffffffff814bb73f&gt;] __sk_free+0x1f/0x170<br>[201414.816048] [&lt;ffffffff814bb8b1&gt;] sk_free+0x21/0x30<br>[201414.816052] [&lt;ffffffffa03302bb&gt;] vmci_transport_recv_stream_cb+0x1fb/0x2e0<br>[vmw_vsock_vmci_transport]<br>[201414.816058] [&lt;ffffffff810bd9a4&gt;] ? tick_program_event+0x24/0x30<br>[201414.816063] [&lt;ffffffffa0319f1c&gt;] vmci_datagram_invoke_guest_handler+0xbc/0xf0<br>[vmw_vmci]<br>[201414.816069] [&lt;ffffffffa031ae6f&gt;] vmci_dispatch_dgs+0xcf/0x230 [vmw_vmci]<br>[201414.816075] [&lt;ffffffff81066eae&gt;] tasklet_action+0x6e/0x110<br>&lt;/Stacktrace&gt;<br><br>(Refer to https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2142110 )<br>~~~<br>======================<br>감사합니다.<br><br><publishedDate>2016-04-11T02:34:40Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GpfWaIAJ"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-04-10T23:57:13Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-04-10T23:57:13Z</b><br><br>안녕하세요. <br><br>버전 확인해 본 결과 아래 정보가 운영계에 설치되어 있습니다.<br><br>vmware ESXi 6.0.0 build 3380124 (update 1B)<br><br><publishedDate>2016-04-10T23:57:13Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GpRsVIAV"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-04-08T07:33:29Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-04-08T07:33:29Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>오전에 유선으로 통화드린 내용에 대해서 확인 후, 업데이트 바랍니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-04-08T07:33:29Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GpBqkIAF"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-04-07T12:07:06Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-04-07T12:07:06Z</b><br><br>안녕하세요.<br><br>확인 해 본 결과 현재 운영 시스템에서 작동하는 VMWare 는 과거 이슈가 되었던 VMCI 문제는 패치가 된 버전으로 확인되었습니다.<br><br>감사합니다.<br><br><publishedDate>2016-04-07T12:07:06Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000Gmov4IAB"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-04-01T04:42:18Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-04-01T04:42:17Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>넵.. 확인 후, 이상이 있을 경우 관련 정보를 업데이트 바랍니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-04-01T04:42:17Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GmmaHIAR"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-04-01T00:59:18Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-04-01T00:59:18Z</b><br><br>안녕하세요.<br><br>현재 VMWare Version 에서는 VMCI 관련 이슈가 해결된 버전으로 설치 된 것으로 알고 있는데요,<br><br>정확히 확인 해 보고 다시 Reply 하도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-04-01T00:59:18Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GlzDVIAZ"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-03-29T01:32:38Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-03-29T01:32:38Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>우선 softirq의 utilization의 원인을 분석하기 위해서는 perf 데이터라든지 vmcore 데이터 수집이 당시에 필요합니다.<br>기존에 softirq와 관련되 버그가 있기는 있었으나, 현재 사용하는 버젼이 해당 패치가 반영된 버젼이며 그 패턴이 기존 알려진 버그와는 조금 상이함에 따라 동일하기 보다는 다시 해당 이슈에 대한 investigation이 필요한 상황입니다.<br><br>그런데 보내주신 로그를 볼때, 아래와 같은 로그가 제일 먼저 시작하는 것을 확인하였습니다.<br><br>Mar 20 16:36:12 SLPEAICL01 kernel: BUG: scheduling while atomic: swapper/0/0/0x10000100<br>Mar 20 16:36:12 SLPEAICL01 kernel: Modules linked in: rpcsec_gss_krb5 nfsv4 dns_resolver nfsv3 nfs fscache RedCastle(POE) iptable_filter vmw_vsock_vmci_transport vsock coretemp crc32_pclmul ghash_clmulni_intel p<br>pdev vmw_balloon aesni_intel lrw gf128mul glue_helper ablk_helper cryptd pcspkr sg vmw_vmci i2c_piix4 shpchp dm_mod parport_pc parport nfsd auth_rpcgss nfs_acl lockd grace sunrpc binfmt_misc ip_tables xfs libcrc32c sr_mod cdrom ata_generic pata_acpi sd_mod crc_t10dif crct10dif_generic crct10dif_pclmul crct10dif_common vmwgfx drm_kms_helper ata_piix ttm crc32c_intel serio_raw drm i2c_core vmxnet3 libata vmw_pvscsi<br>Mar 20 16:36:12 SLPEAICL01 kernel: CPU: 0 PID: 0 Comm: swapper/0 Tainted: P           OE  ------------   3.10.0-327.el7.x86_64 #1<br>Mar 20 16:36:12 SLPEAICL01 kernel: Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 09/21/2015<br>Mar 20 16:36:12 SLPEAICL01 kernel: ffffffff8193c000 fe2e802f374bb4f0 ffff88081e603bb8 ffffffff816351f1<br>Mar 20 16:36:12 SLPEAICL01 kernel: ffff88081e603bc8 ffffffff8162f322 ffff88081e603c28 ffffffff8163a7ad<br>Mar 20 16:36:12 SLPEAICL01 kernel: ffffffff81951440 ffffffff8193ffd8 ffffffff8193ffd8 ffffffff8193ffd8<br>Mar 20 16:36:12 SLPEAICL01 kernel: Call Trace:<br>Mar 20 16:36:12 SLPEAICL01 kernel: &lt;IRQ&gt;  [&lt;ffffffff816351f1&gt;] dump_stack+0x19/0x1b<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8162f322&gt;] __schedule_bug+0x4d/0x5b<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8163a7ad&gt;] __schedule+0x7cd/0x900<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810b5ea6&gt;] __cond_resched+0x26/0x30<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8163abaa&gt;] _cond_resched+0x3a/0x50<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8163abef&gt;] wait_for_completion+0x2f/0x170<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810b8a66&gt;] ? try_to_wake_up+0x1b6/0x300<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81124820&gt;] ? __call_rcu+0x2c0/0x2c0<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810a26ab&gt;] wait_rcu_gp+0x5b/0x80<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810a2630&gt;] ? ftrace_raw_output_rcu_utilization+0x50/0x50<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810af028&gt;] ? __wake_up_common+0x58/0x90<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff811240cb&gt;] synchronize_sched+0x3b/0x50<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa03a99d0&gt;] vmci_event_unsubscribe+0x70/0xb0 [vmw_vmci]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa041a611&gt;] vmci_transport_destruct+0x21/0xe0 [vmw_vsock_vmci_transport]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa03ff867&gt;] vsock_sk_destruct+0x17/0x60 [vsock]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81514bdf&gt;] __sk_free+0x1f/0x170<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81514d51&gt;] sk_free+0x21/0x30<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa041b2bb&gt;] vmci_transport_recv_stream_cb+0x1fb/0x2e0 [vmw_vsock_vmci_transport]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa03a8f1c&gt;] vmci_datagram_invoke_guest_handler+0xbc/0xf0 [vmw_vmci]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa03a9e6f&gt;] vmci_dispatch_dgs+0xcf/0x230 [vmw_vmci]<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8108495d&gt;] tasklet_action+0x7d/0x140<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81084b0f&gt;] __do_softirq+0xef/0x280<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8164721c&gt;] call_softirq+0x1c/0x30<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81016fc5&gt;] do_softirq+0x65/0xa0<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81084ea5&gt;] irq_exit+0x115/0x120<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81647db8&gt;] do_IRQ+0x58/0xf0<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8163d0ed&gt;] common_interrupt+0x6d/0x6d<br>Mar 20 16:36:12 SLPEAICL01 kernel: &lt;EOI&gt;  [&lt;ffffffff81058e96&gt;] ? native_safe_halt+0x6/0x10<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8101dbcf&gt;] default_idle+0x1f/0xc0<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff8101e4d6&gt;] arch_cpu_idle+0x26/0x30<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff810d6305&gt;] cpu_startup_entry+0x245/0x290<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81624e07&gt;] rest_init+0x77/0x80<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81a8d057&gt;] start_kernel+0x429/0x44a<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81a8ca37&gt;] ? repair_env_string+0x5c/0x5c<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81a8c120&gt;] ? early_idt_handlers+0x120/0x120<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81a8c5ee&gt;] x86_64_start_reservations+0x2a/0x2c<br>Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffff81a8c742&gt;] x86_64_start_kernel+0x152/0x175<br><br><br>&gt; Mar 20 16:36:12 SLPEAICL01 kernel: [&lt;ffffffffa03a8f1c&gt;] vmci_datagram_invoke_guest_handler+0xbc/0xf0 [vmw_vmci]<br>&gt; Mar 20 16:36:12 SLPEAICL01 kernel: BUG: scheduling while atomic: swapper/0/0/0x10000100<br><br>위의 패던의 로그는 현재 커널안에서 어떤 문제가 발생을 시작했다는 것을 알 수 있습니다. 그리고 해당 이슈는 일전에 VMware의 이슈와 동일한 패턴으로 의심이 되며, 해당 문제가 발생한 이후로는 커널이 정상적으로 동작할 것이라 기대하지 못합니다.<br><br>즉, 한편으로는 해당 이슈로 인하여 softirq 라든지 cpu 사용율이 높아질 수 짐의 원인이 될수도 있는 상황입니다.<br><br><br>우선 이전 workaround로 vmware에서 설정하였던 부분에 대한 확인을 하여 주시기 바랍니다.<br><br>* To disable VMCI<br>Edit the .vmx file and change the value of vmci0.present to &quot;FALSE&quot; and comment out vmci0 lines.<br><br>vi &lt;server_name&gt;.vmx <br>vmci0.present = &quot;FALSE&quot; <br>#vmci0.pciSlotNumber = &quot;32&quot; <br>#vmci0.id = &quot;1868206774&quot;<br><br><br>참고로 VMware관련된 링크도 첨부하여 드립니다.<br>- https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2142110<br>======================<br>감사합니다.<br><br><publishedDate>2016-03-29T01:32:38Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000Glar7IAB"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-03-25T08:37:17Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-03-25T08:37:17Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>현재 관련된 로그 및 데이터들을 확인하고 몇가지 확인하는데 시간이 소요되고 있으며, 몇 가지 테스트가 필요하여 화요일쯤(3/29) 답변이 가능할 것 같습니다.<br><br>업무에 참고하여 주시기 바랍니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-03-25T08:37:17Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GlI4vIAF"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-03-24T07:19:52Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-03-24T07:19:51Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>보내주신 데이터를 확인중에 있으며, 확인 후 업데이트 드리도록 하겟습니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-03-24T07:19:51Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GktPYIAZ"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-03-23T07:53:02Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-03-23T07:53:02Z</b><br><br>안녕하세요.<br><br>dropbox.redhat.com 에 sosreport-SLPEAICL02-20160322200917.tar.xz 파일 업로드 하였습니다.<br><br>감사합니다.<br><br><publishedDate>2016-03-23T07:53:02Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GkaBYIAZ"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-03-22T05:42:37Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-03-22T05:42:37Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>분석을 위해서 추가로 2번째 노드의 sosreport도 업데이트 바랍니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-03-22T05:42:37Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GkZWLIA3"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-03-22T04:00:08Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-03-22T04:00:08Z</b><br><br>안녕하세요,<br>Red Hat Technical Account Manager 한진구 입니다.<br><br>문의주신 내용을 검토 후, 업데이튿 드리겠습니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-03-22T04:00:08Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GkOwbIAF"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-03-21T12:04:29Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-03-21T12:04:29Z</b><br><br>dropbox.redhat.com/incoming 에 sosreport-SLPEAICL01-20160321151728.tar.xz 파일을 업로드 하였습니다.<br><br>감사합니다.<br><br><publishedDate>2016-03-21T12:04:29Z</publishedDate><createdByType>Customer</createdByType><br>======================<br></comments><br><br>VMWare 가상화 환경 Pacemaker Cluster 서비스 노드에서 ksoftirqd/0 프로세스가 CPU core 100% 점유하는 문제가 발견되었습니다.<br><br>시스템 로그상에 아래와 같은 메세지가 지속적으로 발생하고 있습니다.<br><br>Mar 21 14:55:18 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.230003<br>Mar 21 14:55:48 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.139999<br>Mar 21 14:56:01 SLPEAICL01 CROND[54582]: (root) CMD (/usr/lib64/sa/sa1 1 1)<br>Mar 21 14:56:18 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.150002<br>Mar 21 14:56:48 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.089996<br>Mar 21 14:57:01 SLPEAICL01 CROND[54623]: (root) CMD (/usr/lib64/sa/sa1 1 1)<br>Mar 21 14:57:18 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.120003<br>Mar 21 14:57:48 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.070000<br><br>Mar 21 14:58:01 SLPEAICL01 CROND[54674]: (root) CMD (/usr/lib64/sa/sa1 1 1)<br>Mar 21 14:58:01 SLPEAICL01 CROND[54676]: (pcp) CMD ( /usr/libexec/pcp/bin/pmie_check -C)<br><br>Mar 21 14:58:16 SLPEAICL01 kernel: INFO: rcu_sched detected stalls on CPUs/tasks: { 0} (detected by 1, t=80523604 jiffies, g=16963688, c=16963687, q=0)<br>Mar 21 14:58:16 SLPEAICL01 kernel: sending NMI to all CPUs:<br>Mar 21 14:58:16 SLPEAICL01 kernel: NMI backtrace for cpu 1<br>Mar 21 14:58:16 SLPEAICL01 kernel: CPU: 1 PID: 55234 Comm: fence_vmware_so Tainted: P        W  OE  ------------   3.10.0-327.el7.x86_64 #1<br>Mar 21 14:58:16 SLPEAICL01 kernel: Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 09/21/2015<br>Mar 21 14:58:16 SLPEAICL01 kernel: task: ffff88047523d080 ti: ffff8804752a0000 task.ti: ffff8804752a0000<br>Mar 21 14:58:16 SLPEAICL01 kernel: RIP: 0010:[&lt;ffffffff81058d5a&gt;]  [&lt;ffffffff81058d5a&gt;] native_write_msr_safe+0xa/0x10<br>Mar 21 14:58:16 SLPEAICL01 kernel: RSP: 0000:ffff88081e623d78  EFLAGS: 00000046<br>Mar 21 14:58:16 SLPEAICL01 kernel: RAX: 0000000000000400 RBX: 0000000000000001 RCX: 0000000000000830<br>Mar 21 14:58:16 SLPEAICL01 kernel: RDX: 0000000000000001 RSI: 0000000000000400 RDI: 0000000000000830<br>Mar 21 14:58:16 SLPEAICL01 kernel: RBP: ffff88081e623d78 R08: ffffffff81a658e0 R09: 00000000000266a7<br>Mar 21 14:58:16 SLPEAICL01 kernel: R10: 61206f7420494d4e R11: 3a73555043206c6c R12: ffffffff81a658e0<br>Mar 21 14:58:16 SLPEAICL01 kernel: R13: 0000000000000001 R14: 000000000000a022 R15: 0000000000000002<br>Mar 21 14:58:16 SLPEAICL01 kernel: FS:  00007f34d689b740(0000) GS:ffff88081e620000(0000) knlGS:0000000000000000<br>Mar 21 14:58:16 SLPEAICL01 kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033<br>Mar 21 14:58:16 SLPEAICL01 kernel: CR2: 00007f34d68b5000 CR3: 0000000479f2b000 CR4: 00000000001407e0<br>Mar 21 14:58:16 SLPEAICL01 kernel: DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000<br>Mar 21 14:58:16 SLPEAICL01 kernel: DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400<br>Mar 21 14:58:16 SLPEAICL01 kernel: Stack:<br>Mar 21 14:58:16 SLPEAICL01 kernel: ffff88081e623dc8 ffffffff8104fa22 0000000000000096 0000000000000002<br>Mar 21 14:58:16 SLPEAICL01 kernel: 000800001e623da8 0000000000000001 0000000000000001 0000000000000080<br>Mar 21 14:58:16 SLPEAICL01 kernel: ffff88081e62df80 ffffffff819a6880 ffff88081e623dd8 ffffffff8104fac3<br>Mar 21 14:58:16 SLPEAICL01 kernel: Call Trace:<br>Mar 21 14:58:16 SLPEAICL01 kernel: &lt;IRQ&gt;<br>Mar 21 14:58:16 SLPEAICL01 kernel:<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8104fa22&gt;] __x2apic_send_IPI_mask+0xb2/0xe0<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8104fac3&gt;] x2apic_send_IPI_mask+0x13/0x20<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8104b2ad&gt;] arch_trigger_all_cpu_backtrace+0x11d/0x130<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8112695d&gt;] rcu_check_callbacks+0x5bd/0x610<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff810e0620&gt;] ? tick_sched_handle.isra.14+0x60/0x60<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8108e8c7&gt;] update_process_times+0x47/0x80<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff810e05e5&gt;] tick_sched_handle.isra.14+0x25/0x60<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff810e0661&gt;] tick_sched_timer+0x41/0x70<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff810a9d42&gt;] __hrtimer_run_queues+0xd2/0x260<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff810aa2e0&gt;] hrtimer_interrupt+0xb0/0x1e0<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8164721c&gt;] ? call_softirq+0x1c/0x30<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff81049537&gt;] local_apic_timer_interrupt+0x37/0x60<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff81647e8f&gt;] smp_apic_timer_interrupt+0x3f/0x60<br>Mar 21 14:58:16 SLPEAICL01 kernel: [&lt;ffffffff8164655d&gt;] apic_timer_interrupt+0x6d/0x80<br>Mar 21 14:58:16 SLPEAICL01 kernel: &lt;EOI&gt;<br>Mar 21 14:58:16 SLPEAICL01 kernel: Code:<br>Mar 21 14:58:16 SLPEAICL01 kernel: 00 55 89 f9 48 89 e5 0f 32 31 c9 89 c0 48 c1 e2 20 89 0e 48 09 c2 48 89 d0 5d c3 66 0f 1f 44 00 00 55 89 f0 89 f9 48 89 e5 0f 30 &lt;31&gt; c0 5d c3 66 90 55 89 f9 48 89 e5 0f 33 89 c0 48 c1 e2 20 48</issue><environment>문제는 클러스터 리소스를 관리하는 crm resource manager 에서 아래와 같이 CPU High load 를 감지하는데요, <br><br>Mar 21 14:55:18 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.230003<br>Mar 21 14:55:48 SLPEAICL01 crmd[67294]:  notice: High CPU load detected: 82.139999<br><br>이와 관련이 되었는지는 확실하지 않지만 Resource 가 SLPEAICL02-HB 로 Failover 되었습니다.<br><br>버그 여부를 확인 부탁 드립니다.<br><br>감사합니다.</environment><cep>false</cep></case>