======================<br><b>생성계정 : 우택 심</b><br><b>생성날짜 : 2016-04-01T01:26:27Z</b><br><b>마지막 답변자 : Jack, Jong Young Moon</b><br><b>마지막 수정 일자 : 2016-05-02T05:09:55Z</b><br><b>id : 500A000000U61sxIAB</b><br>======================<br><br><b><font size=15>
제목  : LVM/XFS 파일시스템 마운트 실패 문의
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요.<br><br>이미 사용하고 있는 200G LV xfs 볼륨을 remove 한 후 100G 2개 LV xfs 로 분리하는 작업을 하는 중, <br><br>특정 디렉토리의 Mount point 가 계속해서 mount 하자마자 즉시 unmount 되는 현상이 발견 되었습니다.<br><br>간략히 작업 내역을 요약하자면 아래와 같습니다.<br><br>이미 사용하고 있는 /usr/sap/PQU (200G) 볼륨을 /usr/sap/PUQ(100G) , /usr/sap/NQU(100G) 나누는 작업 임.<br><br>1. 기존 PQU umount 및 신규 생성 할 NQU 디렉토리 생성<br>mkdir -p /usr/sap/NQU<br>fuser -kcu /usr/sap/PQU<br>umount /usr/sap/PQU<br><br>2. 기존 PQU LV 볼륨 제거 및 100G 2개로 나눠 신규 생성. (mkfs.xfs 수행)<br>lvremove /dev/LLQUOSAPVG/usr_sap_PQU<br>lvcreate -n usr_sap_PQU -L 100G LLQUOSAPVG<br>lvcreate -n usr_sap_NQU -L 100G LLQUOSAPVG<br>mkfs.xfs /dev/LLQUOSAPVG/usr_sap_PQU<br>mkfs.xfs /dev/LLQUOSAPVG/usr_sap_NQU<br><br>3. 기존 VG Name 변경<br>vgrename LLQUOSAPVG LLPQUOSAPVG<br>vi /etc/fstab (VG Name 수정)<br>mount -a<br><br>디렉토리 구조는 아래와 같습니다.<br><br>/usr/sap -&gt; DEV : /dev/LLQUOSAPVG/usr_sap<br>/usr/sap/PQU -&gt; DEV : /dev/LLQUOSAPVG/usr_sap_PQU<br>/usr/sap/NQU -&gt; DEV : /dev/LLQUOSAPVG/usr_sap_NQU<br><br>VG Rename 을 하는 시점에 /usr/sap 은 기존 VG Name 으로 mount 되어 있었습니다.<br><br>문제는 신규로 다시 생성한 PQU/NQU 를 마운트를 시도해 보니,<br><br>PQU Monut 과정에서 아래와 같은 로그가 남으면서 Mount 가 계속해서 실패가 되었습니다.<br><br># tail /var/log/messages<br>...<br>Kernel: XFS (dm-1): Mounting V4 Filesystem<br>Kernel: XFS (dm-1): Ending clean mount<br>Kernel: XFS (dm-1): Umounting Filesystem<br><br>* 디렉토리 stat 정보<br>root@PQUOAL03SL / # stat /usr/sap/PQU<br>  File: '/usr/sap/PQU'<br>  Size: 6               Blocks: 0          IO Block: 4096   directory<br>Device: fd49h/64841d    Inode: 131         Links: 2<br>Access: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)<br>Access: 2016-02-27 17:33:32.236357399 +0900<br>Modify: 2016-01-20 11:24:52.396631682 +0900<br>Change: 2016-03-31 17:15:57.235454550 +0900<br> Birth: -<br><br>root@PQUOAL03SL / # stat /usr/sap/NQU<br>  File: '/usr/sap/NQU'<br>  Size: 6               Blocks: 0          IO Block: 4096   directory<br>Device: fd03h/64771d    Inode: 128         Links: 2<br>Access: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)<br>Access: 1970-01-01 09:00:00.000000000 +0900<br>Modify: 2016-03-31 17:11:34.436324000 +0900<br>Change: 2016-03-31 17:11:34.436324000 +0900<br> Birth: -<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>리부팅을 통해 정상적으로 Mount 는 되었으나, <br><br>운영 중 vgrename 을 할 때 위와 같은 문제가 발생할 수 있는지 궁금합니다.<br><br>작업 절차 상 모든 VG volume 을 umount 하고 vg rename 을 했어야 하는 걸로 판단이 되는데, <br><br>vgrename 을 총 6대를 작업하였으나, 2대는 정상적으로 Mount 가 되었습니다.<br><br>작업 절차의 문제인지, LVM 등의 오류인지 확인 부탁 드립니다.<br><br>sosreport 는 dropbox 에 별도로 업로드 하겠습니다.<br><br>감사합니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 3 (Normal)</b><br>======================<br><comment id="a0aA000000H3PpkIAF"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-05-02T05:09:52Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-05-02T05:09:52Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>본 케이스과 관련하여 지난 오랫동안 추가 업데이트가 없어 케이스를 종료처리 하도록 하겠습니다.<br>만약 추가 문의가 있으실 경우 다시 오픈하실 수 있으며, 앞으로도 Red Hat 제품과 관련하여 문제가<br>발생하시거나 기술지원이 필요하시면, 언제든지 새로은 케이스를 통해 지원 받으실 수 있습니다.<br><br>감사합니다.<br><br><publishedDate>2016-05-02T05:09:52Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GyIH2IAN"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-04-27T07:15:08Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-04-27T07:15:08Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>본 케이스와 관련하여 오랫동안 업데이트가 없어 보입니다. 혹시 현재 이슈가 어떻게 진행 되고 있으신가요?<br>만약 현재 이슈와 관련한 추가 문의사항이 있으시다면, 언제든지 케이스에 comment 를 남겨주시거나 연락<br>주십시오.<br><br>감사합니다.<br><br><publishedDate>2016-04-27T07:15:08Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GvxSQIAZ"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-04-18T07:24:43Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-04-18T07:24:43Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>지난주에 유선상으로 말씀드린것과 같이 금일 다시 한번 더 이슈를 재현을 해보았지만, 이전의 VG 이름이<br>그대로 남아 있는 문제 이외에는 정상적으로 mount 가 되었고, 리부팅 이후에 올바르게 모두 mount 가<br>되어져서 이슈재현을 하지 못했습니다.<br><br>그래서, 본 케이스는 더 이상 지원이 어려울거 같습니다. 다만, 향후에 이슈가 만약 재현이 된다면 아래의<br>[ 진단단계 ] 로 원인분석이 가능하오니, 향후에 활용하셔서 새롭게 기술문의하실때 같이 업로드 해주시길<br>부탁드립니다.<br><br><br>[ 진단단계 ]<br><br>가) 아래의 pvs, vgs, lvs 가 상세한 로그를 남길 수 있는 명령의 출력내용을 케이스에 업로드 해주십시오.<br><br>  $ pvs -vvvv &amp;&gt; pvs.txt<br>  $ vgs -vvvv &amp;&gt; vgs.txt<br>  $ lvs -vvvv &amp;&gt; lvs.txt<br><br><br>나) 아래의 lvdump 와 vm-save-metadata-device-cache.sh 를 실행한 출력내용을 케이스에 업로드해주십시오.<br>$ lvmdump -am 또는 vm-save-metadata-device-cache.sh<br><br>  * 상세내용는 아래의 문서[1]을 참고<br><br>  [1] How do I debug an LVM problem?<br>  - https://access.redhat.com/node/53838<br><br><br>다) mount 가 되지 않은 파일시스템에 아래의 절차들을 적용하고 난 뒤 mount 를 시도해서 이슈재현 하시고 난 뒤<br>   남겨진 로그와 sosreport 를 케이스에 업로드 해주십시오.<br>   <br>   1) 문제의 파일시스템에 dd 로 읽기 테스트<br>   $ dd if=&lt;device&gt; of=/tmp/image bs=1M<br><br>   2) 위의 디바이스에 쓰기 테스트<br>   $ dd if=/tmp/image of=&lt;device&gt; bs=1M<br><br><br>   3) 만약, device 가 read-only 모드라면 쓰기가 실패할것이고, 쓰기가 성공했다면 파일시스템이 거주하는<br>      LV 에서 같은 테스트가 필요할 것입니다.<br><br><br>   $ dd if=/dev/mapper/vgA-Creative of=/tmp/dd-lvm.out bs=1M count=10<br>   $ dd if=/tmp/dd-lvm.out of=/dev/mapper/vgA-Creative bs=1M count=10<br><br><br>   4) strace 로 mount 를 추적한 결과를 수집해서 케이스에 업로드 해주십시오.<br>   $ strace -o mount.strace mount /raid1<br><br><br>   5) 그 이후에, 해당 문제의 파일시스템 내부에서 어떠한 동작을 하는지 살펴보기 위해서 debugfs<br>      설정하여 출력내용과 로그를 수집해서 케이스에 업로드 해주십시오.<br><br>   $ mount -t debugfs nodev /sys/kernel/debug<br>   $ cd /sys/kernel/debug/tracing<br>   $ echo 0 &gt; tracing_on<br>   $ echo &gt; trace<br>   $ echo function &gt; current_tracer<br>   $ grep mount available_filter_functions &gt; set_ftrace_filter<br>   $ grep xfs available_filter_functions &gt;&gt; set_ftrace_filter<br>   $ echo 1 &gt; tracing_on ; mount /raid1 ; echo 0 &gt; tracing_on<br>   $ cat trace &gt; /tmp/ftrace.out<br><br>   [2] Unable to repair XFS filesystem<br>   - https://access.redhat.com/solutions/1135573<br><br><br>감사합니다.<br><br><publishedDate>2016-04-18T07:24:43Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000Gvd1lIAB"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-04-15T07:47:00Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-04-15T07:47:00Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>심우택 차장님, 유선상으로 말씀을 드린것과 같이 다시 한번 더 재현시도를 해보았는데 기존의 마운트된 VG 이름이<br>변경되지 않은 이상한 점이 존재했으나, 정상적으로 모두 마운트된것을 확인하였습니다.<br><br>다시 한번 더 재현해보고 난 뒤에 연락드리도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-04-15T07:47:00Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GvN48IAF"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-04-14T10:55:30Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-04-14T10:55:30Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>에러내용을 보고, 내부자료를 검색을 해보았으나 마땅한 사례나 지식기반 문서를 찾지 못한 상황입니다. 내부에서 좀 더 확인후에 업데이를 남기도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-04-14T10:55:30Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000Gq6u1IAB"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-04-12T03:52:14Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-04-12T03:52:14Z</b><br><br>안녕하세요. <br><br>내용을 확인 해 보니 비슷한 시나리오로 판단 됩니다.<br><br>재현하신 상황에서도 비슷하게 mount 가 실패하였는데, 이러한 현상 원인이 과정 상의 문제인지 확인 부탁 드립니다.<br><br>감사합니다.<br><br><publishedDate>2016-04-12T03:52:14Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GphX8IAJ"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-04-11T06:29:18Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-04-11T06:55:10Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support service 를 이용해주셔서 감사합니다.<br><br>이전에 안내를 드린것과 같이 말씀하신 이슈를 내부에서 VM 을 통해서 재현을 해보았는데, 직면하신 문제와 동일한지<br>확인이 필요 하오니, 아래의 재현단계를 보시고 피드백 부탁드립니다.<br><br>- 재현단계<br><br>최초 VG 명 / 크기      :  vg00 / 31G<br>최초 생성된 LV 명 / 크기 :  lv01 / 15G , lv02 / 15G<br>변경 VG 명            :  vg01 <br>변경 LV 명 / 크기      : lv02 / 7G , lv03 / 7G<br>마운트 디렉토리         : /jtest/sap , /jtest/sap/PEQ, /jtest/sap/MUQ<br><br><br>01) LVM 구성될 디스크 크기 확인<br>[root@localhost ~]# fdisk -l<br><br>~~ 생략<br>Disk /dev/sdb: 33.3 GB, 33285996544 bytes, 65011712 sectors<br>Units = sectors of 1 * 512 = 512 bytes<br>Sector size (logical/physical): 512 bytes / 512 bytes<br>I/O size (minimum/optimal): 512 bytes / 512 bytes<br><br>~~ 생략<br><br><br>02) 디스크 파티셔닝<br><br>[root@localhost ~]# fdisk /dev/sdb<br>Welcome to fdisk (util-linux 2.23.2).<br><br>Changes will remain in memory only, until you decide to write them.<br>Be careful before using the write command.<br><br>Device does not contain a recognized partition table<br>Building a new DOS disklabel with disk identifier 0x1220ac70.<br><br>Command (m for help): p<br><br>Disk /dev/sdb: 33.3 GB, 33285996544 bytes, 65011712 sectors<br>Units = sectors of 1 * 512 = 512 bytes<br>Sector size (logical/physical): 512 bytes / 512 bytes<br>I/O size (minimum/optimal): 512 bytes / 512 bytes<br>Disk label type: dos<br>Disk identifier: 0x1220ac70<br><br>   Device Boot      Start         End      Blocks   Id  System<br><br>Command (m for help): n<br>Partition type:<br>   p   primary (0 primary, 0 extended, 4 free)<br>   e   extended<br>Select (default p): p<br>Partition number (1-4, default 1): 1<br>First sector (2048-65011711, default 2048): <br>Using default value 2048<br>Last sector, +sectors or +size{K,M,G} (2048-65011711, default 65011711): <br>Using default value 65011711<br>Partition 1 of type Linux and of size 31 GiB is set<br><br>Command (m for help): wq<br>The partition table has been altered!<br><br>Calling ioctl() to re-read partition table.<br>Syncing disks.<br><br>[root@localhost ~]# partprobe <br><br>[root@localhost ~]# fdisk -l<br>~~ 생략<br>   Device Boot      Start         End      Blocks   Id  System<br>/dev/sda1   *        2048     1026047      512000   83  Linux<br>/dev/sda2         1026048    68282367    33628160   8e  Linux LVM<br><br>Disk /dev/sdb: 33.3 GB, 33285996544 bytes, 65011712 sectors<br>Units = sectors of 1 * 512 = 512 bytes<br>Sector size (logical/physical): 512 bytes / 512 bytes<br>I/O size (minimum/optimal): 512 bytes / 512 bytes<br>Disk label type: dos<br>Disk identifier: 0x1220ac70<br><br>   Device Boot      Start         End      Blocks   Id  System<br>/dev/sdb1            2048    65011711    32504832   83  Linux<br>~~ 생략<br><br><br>03) PV 생성<br><br>[root@localhost ~]# pvcreate /dev/sdb1<br>  Physical volume &quot;/dev/sdb1&quot; successfully created<br><br><br>04) VG 생성 및 확인<br>[root@localhost ~]# vgcreate vg00 /dev/sdb1<br>  Volume group &quot;vg00&quot; successfully created<br><br>[root@localhost ~]# vgs<br>  VG   #PV #LV #SN Attr   VSize  VFree <br>  rhel   1   2   0 wz--n- 32.07g 40.00m<br>  vg00   1   0   0 wz--n- 31.00g 31.00g<br><br><br>05) Base 디렉토리 생성<br><br>[root@localhost ~]# mkdir -p /jtest/sap<br><br><br>06) LV01 &amp; 02 생성<br><br>[root@localhost ~]# lvcreate -L 15G -n lv01 vg00<br>  Logical volume &quot;lv01&quot; created.<br>[root@localhost ~]# lvcreate -L 15G -n lv02 vg00<br>  Logical volume &quot;lv02&quot; created.<br><br><br>07) XFS 파일시스템 포맷 <br><br>[root@localhost ~]# mkfs.xfs /dev/vg00/lv01 <br>meta-data=/dev/vg00/lv01         isize=256    agcount=4, agsize=983040 blks<br>         =                       sectsz=512   attr=2, projid32bit=1<br>         =                       crc=0        finobt=0<br>data     =                       bsize=4096   blocks=3932160, imaxpct=25<br>         =                       sunit=0      swidth=0 blks<br>naming   =version 2              bsize=4096   ascii-ci=0 ftype=0<br>log      =internal log           bsize=4096   blocks=2560, version=2<br>         =                       sectsz=512   sunit=0 blks, lazy-count=1<br>realtime =none                   extsz=4096   blocks=0, rtextents=0<br><br>[root@localhost ~]# mkfs.xfs /dev/vg00/lv02<br>meta-data=/dev/vg00/lv02         isize=256    agcount=4, agsize=983040 blks<br>         =                       sectsz=512   attr=2, projid32bit=1<br>         =                       crc=0        finobt=0<br>data     =                       bsize=4096   blocks=3932160, imaxpct=25<br>         =                       sunit=0      swidth=0 blks<br>naming   =version 2              bsize=4096   ascii-ci=0 ftype=0<br>log      =internal log           bsize=4096   blocks=2560, version=2<br>         =                       sectsz=512   sunit=0 blks, lazy-count=1<br>realtime =none                   extsz=4096   blocks=0, rtextents=0<br><br><br>08) 디렉토리 마운트<br><br>[root@localhost ~]# mount /dev/vg00/lv01 /jtest/sap/<br>[root@localhost ~]# mkdir /jtest/sap/PEQ<br>[root@localhost ~]# mount /dev/vg00/lv02 /jtest/sap/PEQ/<br><br><br>09) VG 이름 바꾸기 와 LV 나누기<br><br>[root@localhost ~]# umount /jtest/sap/PEQ/<br><br>[root@localhost ~]# lvremove vg00/lv02<br>Do you really want to remove active logical volume lv02? [y/n]: y<br>  Logical volume &quot;lv02&quot; successfully removed<br><br>[root@localhost ~]# vgrename vg00 vg01<br>  Volume group &quot;vg00&quot; successfully renamed to &quot;vg01&quot;<br><br>[root@localhost ~]# lvcreate -L 7G -n lv02 vg01<br>WARNING: xfs signature detected on /dev/vg01/lv02 at offset 0. Wipe it? [y/n]: y<br>  Wiping xfs signature on /dev/vg01/lv02.<br>  Logical volume &quot;lv02&quot; created.<br><br>[root@localhost ~]# lvcreate -L 7G -n lv03 vg01<br>  Logical volume &quot;lv03&quot; created.<br><br>[root@localhost ~]# mkdir /jtest/sap/MUQ<br>[root@localhost ~]# mount /dev/vg01/lv02 /jtest/sap/PEQ/<br>mount: /dev/mapper/vg01-lv02 is write-protected, mounting read-only<br>mount: unknown filesystem type '(null)'<br><br>[root@localhost ~]# mount /dev/vg01/lv02 /jtest/sap/PEQ/<br>mount: /dev/mapper/vg01-lv02 is write-protected, mounting read-only<br>mount: unknown filesystem type '(null)'<br><br>[root@localhost ~]# mount /dev/vg01/lv02 /jtest/sap/MUQ/<br>mount: /dev/mapper/vg01-lv02 is write-protected, mounting read-only<br>mount: unknown filesystem type '(null)'<br><br><br>10) 마운트 확인<br><br>[root@localhost ~]# df -h<br>Filesystem             Size  Used Avail Use% Mounted on<br>/dev/mapper/rhel-root   29G  2.9G   26G  10% /<br>devtmpfs               3.1G     0  3.1G   0% /dev<br>tmpfs                  3.1G   84K  3.1G   1% /dev/shm<br>tmpfs                  3.1G  8.8M  3.1G   1% /run<br>tmpfs                  3.1G     0  3.1G   0% /sys/fs/cgroup<br>/dev/sda1              497M  157M  341M  32% /boot<br>tmpfs                  621M   16K  621M   1% /run/user/42<br>tmpfs                  621M     0  621M   0% /run/user/0<br>/dev/mapper/vg00-lv01   15G   33M   15G   1% /jtest/sap<br><br><br>감사합니다.<br><br><publishedDate>2016-04-11T06:29:18Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GpQfuIAF"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-04-08T04:11:03Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-04-08T04:11:02Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>심우택 차장님~ 먼저 죄송하다는 말씀드립니다. 여러 케이스들로 인해서 아직 내부에서 재현 테스트를 해보지 못했습니다.<br>금일까지는 조금 어려울거 같습니다. 늦더라도 다음주내에는 꼭 내부에서 재현 시도한 뒤에 문제분석을 하도록 하겠습니다.<br><br>케이스 응대에 대한 답변이 늦어진 점에 대해서 양해 부탁드립니다.<br><br>감사합니다.<br><br><publishedDate>2016-04-08T04:11:02Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000Gp7vRIAR"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-04-07T04:24:41Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-04-07T04:24:41Z</b><br><br>안녕하세요. <br><br>dropbox.redhat.com 에 파일명 sosreport-PQUOAL03SL-20160407125053.tar.xz 으로 업로드 하였습니다.<br><br>감사합니다.<br><br><publishedDate>2016-04-07T04:24:41Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GmpUXIAZ"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-04-01T06:22:05Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-04-01T06:22:04Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>올려주신 문의내용을 보면 현재의 상황은 XFS 파일시스템이 문제가 되었다가 리부팅시에 /etc/fstab 설정된<br>파일시스템 체크 옵션으로 자동 repair 가 된거 같습니다. 그래서, 현재는 파일시스템 corruption 의 원<br>인을 알아내기가 어려울거 같습니다.<br><br>혹시, 자동 unmount 되는 이슈를 재현한 다음 파일시스템 dump 와 LVM dump 를 생성해서 케이스에 업로<br>드가 가능하신가요?<br><br>만약, 재현이 어려우시다면 알려진 이슈가 있는지 확인해보기 위해서 케이스에 sosreport 를 업로드 해주시길<br>부탁드립니다.<br><br><br>감사합니다.<br><br><publishedDate>2016-04-01T06:22:04Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000Gmp8RIAR"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2016-04-01T05:28:18Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2016-04-01T05:28:18Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>현재 올려주신 문의내용을 자세히 살펴보고 있는중입니다. 확인이 되는대로 업데이트를 남기도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-04-01T05:28:18Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br><br>이미 사용하고 있는 200G LV xfs 볼륨을 remove 한 후 100G 2개 LV xfs 로 분리하는 작업을 하는 중, <br><br>특정 디렉토리의 Mount point 가 계속해서 mount 하자마자 즉시 unmount 되는 현상이 발견 되었습니다.<br><br>간략히 작업 내역을 요약하자면 아래와 같습니다.<br><br>이미 사용하고 있는 /usr/sap/PQU (200G) 볼륨을 /usr/sap/PUQ(100G) , /usr/sap/NQU(100G) 나누는 작업 임.<br><br>1. 기존 PQU umount 및 신규 생성 할 NQU 디렉토리 생성<br>mkdir -p /usr/sap/NQU<br>fuser -kcu /usr/sap/PQU<br>umount /usr/sap/PQU<br><br>2. 기존 PQU LV 볼륨 제거 및 100G 2개로 나눠 신규 생성. (mkfs.xfs 수행)<br>lvremove /dev/LLQUOSAPVG/usr_sap_PQU<br>lvcreate -n usr_sap_PQU -L 100G LLQUOSAPVG<br>lvcreate -n usr_sap_NQU -L 100G LLQUOSAPVG<br>mkfs.xfs /dev/LLQUOSAPVG/usr_sap_PQU<br>mkfs.xfs /dev/LLQUOSAPVG/usr_sap_NQU<br><br>3. 기존 VG Name 변경<br>vgrename LLQUOSAPVG LLPQUOSAPVG<br>vi /etc/fstab (VG Name 수정)<br>mount -a<br><br>디렉토리 구조는 아래와 같습니다.<br><br>/usr/sap -&gt; DEV : /dev/LLQUOSAPVG/usr_sap<br>/usr/sap/PQU -&gt; DEV : /dev/LLQUOSAPVG/usr_sap_PQU<br>/usr/sap/NQU -&gt; DEV : /dev/LLQUOSAPVG/usr_sap_NQU<br><br>VG Rename 을 하는 시점에 /usr/sap 은 기존 VG Name 으로 mount 되어 있었습니다.<br><br>문제는 신규로 다시 생성한 PQU/NQU 를 마운트를 시도해 보니,<br><br>PQU Monut 과정에서 아래와 같은 로그가 남으면서 Mount 가 계속해서 실패가 되었습니다.<br><br># tail /var/log/messages<br>...<br>Kernel: XFS (dm-1): Mounting V4 Filesystem<br>Kernel: XFS (dm-1): Ending clean mount<br>Kernel: XFS (dm-1): Umounting Filesystem<br><br>* 디렉토리 stat 정보<br>root@PQUOAL03SL / # stat /usr/sap/PQU<br>  File: '/usr/sap/PQU'<br>  Size: 6               Blocks: 0          IO Block: 4096   directory<br>Device: fd49h/64841d    Inode: 131         Links: 2<br>Access: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)<br>Access: 2016-02-27 17:33:32.236357399 +0900<br>Modify: 2016-01-20 11:24:52.396631682 +0900<br>Change: 2016-03-31 17:15:57.235454550 +0900<br> Birth: -<br><br>root@PQUOAL03SL / # stat /usr/sap/NQU<br>  File: '/usr/sap/NQU'<br>  Size: 6               Blocks: 0          IO Block: 4096   directory<br>Device: fd03h/64771d    Inode: 128         Links: 2<br>Access: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)<br>Access: 1970-01-01 09:00:00.000000000 +0900<br>Modify: 2016-03-31 17:11:34.436324000 +0900<br>Change: 2016-03-31 17:11:34.436324000 +0900<br> Birth: -</issue><environment>리부팅을 통해 정상적으로 Mount 는 되었으나, <br><br>운영 중 vgrename 을 할 때 위와 같은 문제가 발생할 수 있는지 궁금합니다.<br><br>작업 절차 상 모든 VG volume 을 umount 하고 vg rename 을 했어야 하는 걸로 판단이 되는데, <br><br>vgrename 을 총 6대를 작업하였으나, 2대는 정상적으로 Mount 가 되었습니다.<br><br>작업 절차의 문제인지, LVM 등의 오류인지 확인 부탁 드립니다.<br><br>sosreport 는 dropbox 에 별도로 업로드 하겠습니다.<br><br>감사합니다.</environment><cep>false</cep></case>