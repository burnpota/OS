======================<br><b>생성계정 : 타임 게이트</b><br><b>생성날짜 : 2017-04-10T05:07:07Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2017-05-05T10:04:09Z</b><br><b>id : 500A000000Wm980IAB</b><br>======================<br><br><b><font size=15>
제목  : Need to analyse two vmcore files why system got reboot when pulling on a one of storage cables forcibly [ OS리부팅에 대한 확인 요청 ]
</font></b><br><br>======================<br><b>사전문의<br></b><br>안녕하십니까 <br><br>서버 안정화의 일환으로 가용성 테스트를 진행하였습니다<br><br>스토리지 SAN 패스에 대해서 4개 패스중 2개 패스를 절체하여<br><br>운영상에 어떠한 문제가 있는지를 체크하던중..<br><br>서버가 리부팅 되는 증상을 보였습니다<br><br>대략 Apr  8 15:07:31  해당 시간에 SAN 볼륨을 4패스 중 2패스를 절체하였습니다<br><br>이후 &quot;2번 서버&quot; 장비가 리부팅되는 증상이 있었습니다<br><br>원인 확인 부탁드립니다<br><br>해당 볼륨은 베리타스 볼륨을 사용중으로 베리타스 담당자께서 확인 중에 있습니다만 OS단에 특별한 이슈가 있었는지 실제로 볼륨이 모두 제거된것인지<br><br>디테일한 분석 부탁드립니다<br><br>sosreport 파일 첨부드립니다<br><br>감사합니다<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>타입  : Other</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 3 (Normal)</b><br>======================<br><comment id="a0aA000000JJdJhIAL"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2017-04-20T04:26:06Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2017-04-20T04:26:06Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>먼저 피드백 감사드립니다. 말씀하신대로 Vertias 로부터 답변을 받으신 뒤에 저희 Red Hat 의 지원이 다시 필요하시다면<br>케이스에 필요한 요청사항을 남겨주시고, 그 동안에 본 케이스는 대기상태로 남겨두도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-20T04:26:06Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JJOL9IAP"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-19T06:21:56Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-19T06:21:56Z</b><br><br>답변감사합니다.<br>베리타스쪽에 문의도 하여 놓았으니 내용 업데이트 되면 말씀드리겠습니다.<br><br><publishedDate>2017-04-19T06:21:56Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJ63qIAD"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2017-04-18T02:47:10Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2017-04-18T02:47:09Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>올려주신 vmcore 를 저희 커널/스토리지 전문그룹에서 분석한 결과를 아래와 같이 안내드립니다.<br><br>- 아  래<br><br>1) 아래는 보내주신 첫번째 vmcore 를 저희가 분석한 내용입니다.<br><br>System information :<br><br><br>   DMI_BIOS_VENDOR: Dell Inc.<br>   DMI_BIOS_VERSION: 2.2.5<br>   DMI_BIOS_DATE: 09/06/2016<br>   DMI_SYS_VENDOR: Dell Inc.<br>   DMI_PRODUCT_NAME: PowerEdge R730<br><br>   CPUS: 28<br>   DATE: Fri Apr 14 03:31:38 2017<br>   UPTIME: 02:46:04<br>   LOAD AVERAGE: 0.00, 0.03, 0.05<br>   TASKS: 1185<br>   NODENAME: PNLSDL02SL<br>   RELEASE: 3.10.0-327.44.2.el7.x86_64<br>   MEMORY: 511.9 GB<br>   PANIC: &quot;BUG: unable to handle kernel NULL pointer dereference at 0000000000000035&quot;<br>   PID: 16455<br>   COMMAND: &quot;dmpdaemon&quot;<br>   TASK: ffff887f21716780  [THREAD_INFO: ffff887f2329c000]<br>   CPU: 8<br>   STATE: TASK_RUNNING (PANIC)<br><br>Third-Party 모듈<br><br>crash&gt; mod -t<br>NAME       TAINTS<br>veki       POE<br>fdd        POE<br>vxspec     POE<br>vxportal   POE<br>dmpaa      POE<br>dmpap      POE<br>vxcafs     POE<br>dmpjbod    POE<br>vxdmp      POE<br>vxfs       POE<br>RedCastle  POE<br>vxio       POE<br>gab        POE<br>llt        POE<br>crash&gt; <br><br>위에서 보신것과 같이 panic 이 된 태스크는 &quot;dmpdaemon&quot; 입니다.<br><br>panic 된 태스크의 Backtrace 는 아래와 같이 볼 수 있습니다.<br><br>crash&gt; bt<br>PID: 16455  TASK: ffff887f21716780  CPU: 8   COMMAND: &quot;dmpdaemon&quot;<br> #0 [ffff887f2329f928] machine_kexec at ffffffff81051e9b<br> #1 [ffff887f2329f988] crash_kexec at ffffffff810f2a42<br> #2 [ffff887f2329fa58] oops_end at ffffffff8163f9c8<br> #3 [ffff887f2329fa80] no_context at ffffffff8162fb01<br> #4 [ffff887f2329fad0] __bad_area_nosemaphore at ffffffff8162fb97<br> #5 [ffff887f2329fb18] bad_area_nosemaphore at ffffffff8162fd01<br> #6 [ffff887f2329fb28] __do_page_fault at ffffffff8164274e<br> #7 [ffff887f2329fb88] do_page_fault at ffffffff816428e3<br> #8 [ffff887f2329fbb0] page_fault at ffffffff8163ebc8<br>    [exception RIP: blk_rq_map_kern+31]<br>    RIP: ffffffff812d027f  RSP: ffff887f2329fc60  RFLAGS: 00010286<br>    RAX: ffffffffffffffed  RBX: ffff883f206a20a0  RCX: 00000000000000ff<br>    RDX: 00000000000000ff  RSI: ffff883f189c5300  RDI: ffff883f206a20a0<br>    RBP: ffff887f2329fc88   R8: 0000000000000010   R9: ffff883f189c5400<br>    R10: ffff883f7e007700  R11: ffffffffa078af44  R12: 0000000000000000<br>    R13: ffffffffffffffed  R14: ffffffffffffffed  R15: ffff887f20d76800<br>    ORIG_RAX: ffffffffffffffff  CS: 0010  SS: 0018<br> #9 [ffff887f2329fc90] dmp_kernel_scsi_ioctl at ffffffffa078c1bd [vxdmp]<br>#10 [ffff887f2329fcd0] dmp_scsi_ioctl at ffffffffa07cc739 [vxdmp]<br>#11 [ffff887f2329fd68] dmp_send_scsireq at ffffffffa07cd3a0 [vxdmp]<br>#12 [ffff887f2329fd88] dmp_check_path_alive at ffffffffa07c136b [vxdmp]<br>#13 [ffff887f2329fdc8] dmp_check_disabled_policy at ffffffffa07c190a [vxdmp]<br>#14 [ffff887f2329fe60] dmp_initiate_restore at ffffffffa07c1dd3 [vxdmp]<br>#15 [ffff887f2329fe90] dmp_daemons_loop at ffffffffa07cecea [vxdmp]<br>#16 [ffff887f2329fec8] kthread at ffffffff810a5b8f<br>#17 [ffff887f2329ff50] ret_from_fork at ffffffff81647018<br>crash&gt; <br><br><br>현재 수행중인 프로세스의 Disassembly 는 아래와 같이 보실 수 있습니다.<br><br>crash&gt; dis -rl blk_rq_map_kern+31<br>/usr/src/debug/kernel-3.10.0-327.44.2.el7/linux-3.10.0-327.44.2.el7.x86_64/block/blk-map.c: 293<br>0xffffffff812d0260 &lt;blk_rq_map_kern&gt;:   nopl   0x0(%rax,%rax,1) [FTRACE NOP]<br>0xffffffff812d0265 &lt;blk_rq_map_kern+5&gt;: push   %rbp<br>0xffffffff812d0266 &lt;blk_rq_map_kern+6&gt;: mov    %rsp,%rbp<br>0xffffffff812d0269 &lt;blk_rq_map_kern+9&gt;: push   %r14<br>0xffffffff812d026b &lt;blk_rq_map_kern+11&gt;:        push   %r13<br>0xffffffff812d026d &lt;blk_rq_map_kern+13&gt;:        mov    %rsi,%r13<br>0xffffffff812d0270 &lt;blk_rq_map_kern+16&gt;:        mov    %rdx,%rsi<br>0xffffffff812d0273 &lt;blk_rq_map_kern+19&gt;:        mov    %ecx,%edx<br>0xffffffff812d0275 &lt;blk_rq_map_kern+21&gt;:        push   %r12<br>0xffffffff812d0277 &lt;blk_rq_map_kern+23&gt;:        push   %rbx<br>0xffffffff812d0278 &lt;blk_rq_map_kern+24&gt;:        mov    %rdi,%rbx<br>0xffffffff812d027b &lt;blk_rq_map_kern+27&gt;:        sub    $0x8,%rsp<br>/usr/src/debug/kernel-3.10.0-327.44.2.el7/linux-3.10.0-327.44.2.el7.x86_64/block/blk-map.c: 294<br>0xffffffff812d027f &lt;blk_rq_map_kern+31&gt;:        mov    0x48(%r13),%r12   &lt;------- creashed here<br>crash&gt; <br><br><br>crash&gt; whatis blk_rq_map_kern<br>int blk_rq_map_kern(struct request_queue *, struct request *, void *, unsigned int, gfp_t);<br><br><br>* blk_rq_map_kern - map kernel data to a request, for REQ_TYPE_BLOCK_PC usage<br><br>여기서 보실 수 있듯이 vxdump 모듈에서 dump_kernel_scsi_ioctl 함수에 이ㅡ해서 제공된 요청이 여기에 있습니다.<br>또한, 여기서 보실수 있듯이 제공된 요청의 pointer (struct request *) 는 vxdmp 모듈에 의해서 제공된<br>유효하지 않은 메모리 주소입니다.<br><br>crash&gt; px 0xffffffffffffffed+0x48           &lt;---- instruction  -   mov    0x48(%r13),%r12 <br>$2 = 0x35<br><br><br>이는 정확히 crash 된 위치입니다.<br><br>[ 9875.093344] VxVM vxdmp V-5-0-112 [Info] disabled path 128/0x40 belonging to the dmpnode 201/0x2c0 due to admin CLI<br>[ 9875.093347] <br>[ 9875.113352] VxVM vxdmp V-5-0-112 [Info] disabled path 66/0x100 belonging to the dmpnode 201/0x2c0 due to admin CLI<br>[ 9875.113355] <br>[ 9875.131348] VxVM vxdmp V-5-0-112 [Info] disabled path 66/0x110 belonging to the dmpnode 201/0x1f0 due to admin CLI<br>[ 9875.131351] <br>[ 9875.146338] VxVM vxdmp V-5-0-112 [Info] disabled path 128/0x50 belonging to the dmpnode 201/0x1f0 due to admin CLI<br>[ 9875.146341] <br>[ 9968.479377] BUG: unable to handle kernel NULL pointer dereference at 0000000000000035  &lt;------------- [2]<br>[ 9968.479445] IP: [&lt;ffffffff812d027f&gt;] blk_rq_map_kern+0x1f/0x160<br>[ 9968.479498] PGD 0 <br>[ 9968.479518] Oops: 0000 [#1] SMP <br><br>vxdmp 모듈에서 제공된 r13 레지스터 값은 손상된것을 찾았고, 손상이 되었거나 올바르지 않은 값이 vxdmp 모듈에서 제공이 된것입니다.<br>이것이 시스템이 crash 가 된 원인입니다.<br><br>그래서, 왜 올바르지 않은 값이 blk_rq_map_kern 으로부터 제공이 되었는지에 대한 더 낳은 조사를 위해서 Verita 로 vmcore 를<br>전달하여 분석요청 하시길 바랍니다.<br><br><br>2) 두번째 vmcoer 분석은 첫번째에서 일어난거과 유사합니다.<br><br>      KERNEL: /cores/retrace/repos/kernel/x86_64/usr/lib/debug/lib/modules/3.10.0-327.44.2.el7.x86_64/vmlinux<br>    DUMPFILE: /cores/retrace/tasks/273827365/crash/vmcore  [PARTIAL DUMP]<br>        CPUS: 28<br>        DATE: Fri Apr 14 03:32:45 2017<br>      UPTIME: 16 days, 22:26:01<br>LOAD AVERAGE: 0.08, 0.15, 0.10<br>       TASKS: 5308<br>    NODENAME: PNLSDL01SL<br>     RELEASE: 3.10.0-327.44.2.el7.x86_64<br>     VERSION: #1 SMP Thu Nov 24 05:49:35 EST 2016<br>     MACHINE: x86_64  (2599 Mhz)<br>      MEMORY: 511.9 GB<br>       PANIC: &quot;BUG: unable to handle kernel NULL pointer dereference at 0000000000000035&quot;<br>         PID: 15817<br>     COMMAND: &quot;dmpdaemon&quot;<br>        TASK: ffff887ef46f3980  [THREAD_INFO: ffff883f0e5a4000]<br>         CPU: 0<br>       STATE: TASK_RUNNING (PANIC)<br><br>mod: nfsd: last symbol: legacy_recdir_name_error is not _MODULE_END_nfsd?<br>mod: cannot find or load object file for veki module<br>mod: cannot find or load object file for vxportal module<br>mod: cannot find or load object file for vxspec module<br>mod: cannot find or load object file for fdd module<br>mod: cannot find or load object file for dmpaa module<br>mod: cannot find or load object file for dmpap module<br>mod: cannot find or load object file for dmpjbod module<br>mod: cannot find or load object file for vxcafs module<br>mod: ib_mad: last symbol: ack_recv is not _MODULE_END_ib_mad?<br>mod: cannot find or load object file for vxdmp module<br>mod: cannot find or load object file for amf module<br>mod: cannot find or load object file for vxfs module<br>mod: cannot find or load object file for RedCastle module<br>mod: cannot find or load object file for vxio module<br>mod: cannot find or load object file for llt module<br>mod: cannot find or load object file for gab module<br>crash&gt; cd /cores/retrace/tasks/273827365/misc<br>Working directory /cores/retrace/tasks/273827365/misc.<br>crash&gt; <br><br>crash&gt; bt<br>PID: 15817  TASK: ffff887ef46f3980  CPU: 0   COMMAND: &quot;dmpdaemon&quot;<br> #0 [ffff883f0e5a7928] machine_kexec at ffffffff81051e9b<br> #1 [ffff883f0e5a7988] crash_kexec at ffffffff810f2a42<br> #2 [ffff883f0e5a7a58] oops_end at ffffffff8163f9c8<br> #3 [ffff883f0e5a7a80] no_context at ffffffff8162fb01<br> #4 [ffff883f0e5a7ad0] __bad_area_nosemaphore at ffffffff8162fb97<br> #5 [ffff883f0e5a7b18] bad_area_nosemaphore at ffffffff8162fd01<br> #6 [ffff883f0e5a7b28] __do_page_fault at ffffffff8164274e<br> #7 [ffff883f0e5a7b88] do_page_fault at ffffffff816428e3<br> #8 [ffff883f0e5a7bb0] page_fault at ffffffff8163ebc8<br>    [exception RIP: blk_rq_map_kern+31]<br>    RIP: ffffffff812d027f  RSP: ffff883f0e5a7c60  RFLAGS: 00010286<br>    RAX: ffffffffffffffed  RBX: ffff883edaf5a0a0  RCX: 00000000000000ff<br>    RDX: 00000000000000ff  RSI: ffff883f1cdafe00  RDI: ffff883edaf5a0a0<br>    RBP: ffff883f0e5a7c88   R8: 0000000000000010   R9: ffff883f1cdafb00<br>    R10: ffff883f7e007700  R11: ffffffffa068ef44  R12: 0000000000000000<br>    R13: ffffffffffffffed  R14: ffffffffffffffed  R15: ffff883f2377b0c0<br>    ORIG_RAX: ffffffffffffffff  CS: 0010  SS: 0018<br> #9 [ffff883f0e5a7c90] dmp_kernel_scsi_ioctl at ffffffffa06901bd [vxdmp]<br>#10 [ffff883f0e5a7cd0] dmp_scsi_ioctl at ffffffffa06d0739 [vxdmp]<br>#11 [ffff883f0e5a7d68] dmp_send_scsireq at ffffffffa06d13a0 [vxdmp]<br>#12 [ffff883f0e5a7d88] dmp_check_path_alive at ffffffffa06c536b [vxdmp]<br>#13 [ffff883f0e5a7dc8] dmp_check_disabled_policy at ffffffffa06c590a [vxdmp]<br>#14 [ffff883f0e5a7e60] dmp_initiate_restore at ffffffffa06c5dd3 [vxdmp]<br>#15 [ffff883f0e5a7e90] dmp_daemons_loop at ffffffffa06d2cea [vxdmp]<br>#16 [ffff883f0e5a7ec8] kthread at ffffffff810a5b8f<br>#17 [ffff883f0e5a7f50] ret_from_fork at ffffffff81647018<br>crash&gt; <br><br>마찬가지로 더 나은 조사를 위해서는 모든 third party 를 제거해서 이슈를 재현한 뒤에 생성된<br>vmcore 를 올려주시면 저희 Red Hat 측면에서의 분석을 제공해드릴 수 있습니다.<br><br>그러기가 어렵다만, 첫번째와 마찬가지로 Veritas/Symantec 으로 vmcore 를 전달해서 분석요청<br>을 하시길 바랍니다.<br><br>위의 분석에 대한 어떤 다른 문의사항이 있으시다면 저희에게 말씀주시길 바랍니다.<br><br><br>감사합니다.<br><br><publishedDate>2017-04-18T02:47:09Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JIu8qIAD"><br>======================<br><b>생성계정 : Yewale, Nitin</b><br><b>생성날짜 : 2017-04-17T05:10:50Z</b><br><b>마지막 답변자 : Yewale, Nitin</b><br><b>마지막 수정 일자 : 2017-04-17T05:11:06Z</b><br><br>Hello,<br><br>My name is Nitin and I am a member of storage support team collaborating on the issue mentioned with this service request. Please allow me some time to review the provided data. I shall update here with my findings.<br><br>Thank you<br>Nitin Yewale<br><br><publishedDate>2017-04-17T05:10:50Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JIrz8IAD"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-16T12:13:08Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-16T12:13:08Z</b><br><br>PNLSDL01SL.tar<br>PNLSDL02SL.tar<br>의 vmcore 파일을 드롭박스에 업로드 하였으며 베리타스에서는 어떠한 팬싱설정도 안되어 있다고 합니다.<br>분석 부탁드립니다. 감사합니다.<br><br><publishedDate>2017-04-16T12:13:08Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JIcDiIAL"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-14T05:44:26Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-14T05:44:26Z</b><br><br>저번과 같은 상태에서  kdump와 로그를 수집하였습니다.<br>담당자로부터 메일을 수신하면 바로 업데이트 하도록 하겠습니다. 감사합니다.<br><br><publishedDate>2017-04-14T05:44:26Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JHrnnIAD"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2017-04-12T07:02:31Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2017-04-12T07:28:40Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>Apr  8 15:07:31 PNLSDL02SL kernel: qla2xxx [0000:06:00.1]-500b:4: LOOP DOWN detected (2 7 0 0).<br>Apr  8 15:07:31 PNLSDL02SL kernel: qla2xxx [0000:05:00.1]-500b:2: LOOP DOWN detected (2 7 0 0).<br><br>- HBA 가 attach 된 loop 를 현재 Down 상태인것을 식별하고, 이를 다시 Up 할 수 없는상태입니다. 이는 SAN 의 케이블을<br>  제거 했을때 나타나는 메시지입니다.<br><br>Apr  8 15:08:01 PNLSDL02SL kernel: rport-2:0-0: blocked FC remote port time out: removing target and saving binding<br>Apr  8 15:08:01 PNLSDL02SL kernel: rport-4:0-0: blocked FC remote port time out: removing target and saving binding<br><br>- san remote port 가 host 로 login 할때 remote port 로의 연결을 초기화 할 수 없어서 host 가 local rport<br>  리소스들을 제거중이라는 로그를 남기는것입니다. 이는 케이블이 제거가 되어서 remote port 가 더 이상 존재하지 않기 때문<br>  입니다.<br><br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 4:0:0:0: [sdfc] Synchronizing SCSI cache<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 4:0:0:0: [sdfc] Synchronize Cache(10) failed: Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 2:0:0:0: [sdc] Synchronizing SCSI cache<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 2:0:0:0: [sdc] Synchronize Cache(10) failed: Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 4:0:0:1: [sdfd] Synchronizing SCSI cache<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 4:0:0:1: [sdfd] Synchronize Cache(10) failed: Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 2:0:0:1: [sdd] Synchronizing SCSI cache<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 2:0:0:1: [sdd] Synchronize Cache(10) failed: Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 4:0:0:2: [sdfe] Synchronizing SCSI cache<br><br>- 디바이스로 I/O 를 보냈는데 케이블 제거로 인해서 DID_NO_CONNECT 에러메시지가 나타난것이고, 이 에러의 의미는<br>  디바이스로 임시적으로 접근이 불가능하거나 ( a LOOP or LINK DOWN 발생 ) , 더 이상 디바이스가 사용가능하지<br>  않다는 의미입니다. <br><br><br>감사합니다.<br><br><publishedDate>2017-04-12T07:02:30Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JDOptIAH"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-11T08:17:07Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-11T08:17:06Z</b><br><br>답변 감사합니다<br><br>우선 kdump 생성된것은 없었습니다<br><br>베리타스 환경에서 확인 중에 있는데요<br><br>OS단에서 특이사항은 없는지요?<br><br>해당 시점에 아래와 같은 로그가 나왔는데요 해당 로그가 의미하는 것은 무엇인가요?<br><br>Apr  8 15:07:31 PNLSDL02SL kernel: qla2xxx [0000:06:00.1]-500b:4: LOOP DOWN detected (2 7 0 0).<br>Apr  8 15:07:31 PNLSDL02SL kernel: qla2xxx [0000:05:00.1]-500b:2: LOOP DOWN detected (2 7 0 0).<br><br>Apr  8 15:08:01 PNLSDL02SL kernel: rport-2:0-0: blocked FC remote port time out: removing target and saving binding<br>Apr  8 15:08:01 PNLSDL02SL kernel: rport-4:0-0: blocked FC remote port time out: removing target and saving binding<br><br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 4:0:0:0: [sdfc] Synchronizing SCSI cache<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 4:0:0:0: [sdfc] Synchronize Cache(10) failed: Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 2:0:0:0: [sdc] Synchronizing SCSI cache<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 2:0:0:0: [sdc] Synchronize Cache(10) failed: Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 4:0:0:1: [sdfd] Synchronizing SCSI cache<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 4:0:0:1: [sdfd] Synchronize Cache(10) failed: Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 2:0:0:1: [sdd] Synchronizing SCSI cache<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 2:0:0:1: [sdd] Synchronize Cache(10) failed: Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OK<br>Apr  8 15:08:01 PNLSDL02SL kernel: sd 4:0:0:2: [sdfe] Synchronizing SCSI cache<br>.<br>.<br>.<br><br><publishedDate>2017-04-11T08:17:06Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JD6LrIAL"><br>======================<br><b>생성계정 : Moon, Jack, Jong Young</b><br><b>생성날짜 : 2017-04-10T06:47:24Z</b><br><b>마지막 답변자 : Moon, Jack, Jong Young</b><br><b>마지막 수정 일자 : 2017-04-10T06:47:24Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service 를 이용해주셔서 감사합니다.<br><br>시스템이 kdump 설정이 정상적으로 되어 있는 상태에서 커널버그를 직면하였거나, 시스템이 hung 이 되어서 Panic 이 되었다면,<br>/var/crash 디렉토리내에 vmcore 가 생성이 되어져 있을것입니다. 저희 Red Hat 에서는 이를 분석해야 시스템이 리부팅이 된<br>원인을 알수가 있습니다.<br><br>또는, 클러스터 노드가 리부팅이 된 다른 원인으로는 현재의 시스템과 같이 Veritas 클러스터가 설정이 된 상태라면 스토리지 케이<br>블 절체가 Fence 의 원인이 되어서 1번 Veritas 클러스터 노드가 2번 서버를 Fence 시켜서 리부팅이 되었을수도 있으니, 이와<br>관련된 기술문의를 위하여 Veritas 로 연락해주시길 바랍니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-10T06:47:24Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br>