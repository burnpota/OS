======================<br><b>생성계정 : 우택 심</b><br><b>생성날짜 : 2016-07-13T07:32:08Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2016-08-05T10:06:48Z</b><br><b>id : 500A000000UqEtQIAV</b><br>======================<br><br><b><font size=15>
제목  : PEPSCL01SL (VMWare VM) Hang 장애의 건
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요.<br><br>오늘 (2016-07-13) 오후 15:00 경 PEPSCL01SL (Cluster node01) 에서 장애가 감지 되었습니다.<br><br>현재 상암센터 -&gt; 과천센터 VM Clone 작업을 진행중인데요, 비슷한 시간 Clone 작업이 있었다고 합니다.<br><br>SAR 및 messages 로그를 확인 한 결과 오후 14:14 경부터 O/S Hang 상태로 추측하고 있지만, <br><br>Ping 테스트를 했을 때, Cluster 의 H/B , Service VIP 모두 살아 있었으며, H/B 에 문제가 없어 실제 Cluster Token 에 문제가 없어 Failover 가 되지는 않았습니다.<br><br>(단지 SAP Process 등이 Hang 상태로 빠져서 인지 Application 자체 서비스에 문제가 있었습니다.)<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>확인 된 장애는 아래와 같습니다.<br><br>1. PEPSCL02SL (node02) 에서 pcs status 했을 때, PEPSCL01SL (node01) 노드의 pcsd 상태 감지 실패<br><br>2. PEPSCL01SL (node01) SSH 로그인 실패<br><br>3. VMWare Console 로 확인 했을 때 SAP 관련 Process hung_task_timeout 120sec 메세지 출력 중임을 확인.<br><br>장애조치는 아래와 같이 진행하였습니다.<br><br>1. VMWare 에서 NMI Signal 을 이용하여 O/S Crash (vmcore 수집)<br><br>2. PEPSCL02SL (node02) 에서 kdump_fence 성공하여 Resource Failover<br><br>언제 문제가 발생했습니까? 이러한 문제가 자주 발생합니까? 반복적으로 발생합니까? 특정 시간에 발생합니까?<br><br>클러스터의 PCSD 서비스 통신이 불가하여, resource move 도 불가능 상태였습니다.<br><br>보내드리는 vmcore 데이터를 통해 2016-07-13 14:14 Hang 원인에 대해 확인 부탁 드립니다.<br><br>문제 해결 기간 및  긴급도와 관련된 정보를 제공해 주시겠습니까?<br><br>dropbox.redhat.com 에 아래와 같은 파일을 업로드 하겠습니다.<br><br>1. sosreport-PEPSCL01SL-20160713154427.tar.xz (업로드 완료)<br><br>2. vmcore-PEPSCL01SL (별도 업로드 후 Comment 남기겠습니다.)<br><br>감사합니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 3 (Normal)</b><br>======================<br><comment id="a0aA000000HVFO2IAP"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-07-22T04:44:22Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-07-22T04:44:22Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>본 이슈와 관련되어 추가 요청사항이 있어서 요청드립니다.<br>해당 시스템의  /var/log/vmtoolsd.log 로그 파일을 제공해 주시기 바랍니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-07-22T04:44:22Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HV4XuIAL"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-07-21T08:30:18Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-07-21T08:30:18Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>유선으로 이야기 드렸던 부분에 대해서 정리하여 드립니다.<br><br>1. 우선 open-vmtools는 Red Hat에서 의해서 shipping 되고는 있으나, 실제로 upstream에서 패치가 있어야 해당 부분을 back-porting이 가능한 상태입니다.<br><br>해당 버그는 이미 알려진 버그임에 따라 VMware에서도 인지하고 있으리라 봅니다. 그래서 혹시 upstream patch가 있는지와 그에 대한 진행사황이 있는지 확인해주시면 향후 back-porting하는데 도움이 될 것 같습니다.<br><br><br>2. 저희 엔지니어링 팀을 통해서도 혹시 이와 관련되어 following하고 있는 부분이 잇는지를 검토하도록 하겠습니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-07-21T08:30:18Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HV2HBIA1"><br>======================<br><b>생성계정 : kim, jimin</b><br><b>생성날짜 : 2016-07-21T05:12:22Z</b><br><b>마지막 답변자 : kim, jimin</b><br><b>마지막 수정 일자 : 2016-07-21T05:12:22Z</b><br><br>문제가 발생한 시스템은 OS 버전이 RHEL 7.2 이고 VMware 권고로 Redhat에서 제공한 Open-vmtools를 사용하고있습니다.<br><br>Open-vmtools에 이슈가 있다면, VMware에서 제공하는 vmtools를 사용하는게 맞는지 문의 드립니다.<br><br><publishedDate>2016-07-21T05:12:22Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HUoWuIAL"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-07-20T11:40:17Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-07-20T11:40:16Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>본 케이스와 관련되어 저희 글로벌 엔지니어의 답변을 받은 내용을 다시 한 번 정리하여 드립니다.<br><br>시스템 hang원인을 찾기위하여 vmcore를 분석한 결과, 현재의 이슈는 VMware위에서 운영중인 guest machine을 snapshot을 할때 hang이 되는 사례인 것으로 분석 및 확인되고 있습니다.<br>즉, VMware는 운영중인 guest의 snapshot을 수행하기 위해서 실행중인 guest의 파일시스템을 freeze하게 되며, 이때 vmtoolsd라는 프로세스가 동작하게 됩니다. 그리고 이 경우 freeze된 시스템에 파일시스템의 변화를 시도하면서 시스템이 hang 상태에 빠지게 됩니다.<br><br>이와관련되어 ESXi 5.5 P03에서부터의 VMware Tools에서 해당 이슈가 해결된 버젼을 제공하고 있는 것으로 알고 있습니다.<br><br><br>이와 관련되어 좀 더 자세한 내용은 아래 링크를 참고하여 주시기 바랍니다.<br><br>  https://access.redhat.com/solutions/1127253<br>======================<br>감사합니다.<br><br><publishedDate>2016-07-20T11:40:16Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HUZmuIAH"><br>======================<br><b>생성계정 : Douwsma, Donald</b><br><b>생성날짜 : 2016-07-19T08:16:20Z</b><br><b>마지막 답변자 : Douwsma, Donald</b><br><b>마지막 수정 일자 : 2016-07-19T08:16:20Z</b><br><br>Hi, <br><br>I'm a software maintenance engineer assisting the team with your case. <br><br>We've seen this kind of problem before when VMware is taking a snapshot of a guest machine. VMware runs a process (vmtoolsd) to freeze the filesystems running in the guest prior to taking a snapshot. In some cases we've seen this process attempt to change a filesystem after it has frozen them, which leads to system hangs.<br><br>  https://access.redhat.com/solutions/1127253<br><br>In this case it looks like vmtoolsd was trying to write to a log file on one of the frozen filesystems<br>  /var/log/vmtoolsd.log<br><br>Do you have any local changes for vmware logging? Normally these would be in a config file under /etc/vmware-tools/<br><br><br>Regards, <br>Donald<br><br><br>Investigation for this follows. <br><br>Find the longest running UNinteruptable tasks tasks<br>  crash&gt; ps -m | grep UN | tail<br>  ...<br>  [ 0 00:49:10.045] [UN]  PID: 36974  TASK: ffff880e95af0b80  CPU: 3   COMMAND: &quot;ontuned&quot;<br>  [ 0 00:49:10.586] [UN]  PID: 10800  TASK: ffff880fd6235080  CPU: 3   COMMAND: &quot;MemHistoryThrea&quot;<br>  [ 0 00:49:12.350] [UN]  PID: 1014   TASK: ffff880fe147e780  CPU: 3   COMMAND: &quot;vmtoolsd&quot;<br>  [ 0 00:49:12.512] [UN]  PID: 10801  TASK: ffff880fd6235c00  CPU: 0   COMMAND: &quot;Java Main Threa&quot;<br><br>Examine what vmtoolsd was doing <br>  crash&gt; set 1014<br>  crash&gt; bt <br>  PID: 1014   TASK: ffff880fe147e780  CPU: 3   COMMAND: &quot;vmtoolsd&quot;<br>   #0 [ffff880fd6673e18] __schedule at ffffffff8163a26d<br>   #1 [ffff880fd6673e80] schedule at ffffffff8163a909<br>   #2 [ffff880fd6673e90] __sb_start_write at ffffffff811e108e<br>   #3 [ffff880fd6673ef8] vfs_write at ffffffff811de6bb<br>   #4 [ffff880fd6673f38] sys_write at ffffffff811df06f<br>   #5 [ffff880fd6673f80] system_call_fastpath at ffffffff81645909<br>    RIP: 00007f1c196731cd  RSP: 00007ffc4a0a4ff0  RFLAGS: 00000293<br>    RAX: 0000000000000001  RBX: ffffffff81645909  RCX: ffffffffffffffff<br>    RDX: 0000000000000051  RSI: 00007f1c1e89e7d0  RDI: 0000000000000003<br>    RBP: 00007ffc4a0a4d10   R8: 0000000000000000   R9: 0000000000000000<br>    R10: 00007f1c1dbe8dc0  R11: 0000000000000293  R12: 00007f1c1dba6550<br>    R13: 00007f1c1e89e7d0  R14: 0000000000000051  R15: 0000000000000000<br>    ORIG_RAX: 0000000000000001  CS: 0033  SS: 002b<br><br>Try to find the file being written to<br>   kernel/fs/read_write.c<br>   541 SYSCALL_DEFINE3(write, unsigned int, fd, const char __user *, buf,<br>   542                 size_t, count)<br>   543 {<br>   544         struct fd f = fdget_pos(fd);<br>   545         ssize_t ret = -EBADF;<br><br>Grap the struct file from the stack.<br><br>  crash&gt; bt -f<br>  ...<br>   #3 [ffff880fd6673ef8] vfs_write at ffffffff811de6bb<br>      ffff880fd6673f00: 0000000000000002 ffff880fc3761100<br>                                       ^^^^^ fd.file <br>      ffff880fd6673f10: 0000000000000003 00007f1c1e89e7d0<br>      ffff880fd6673f20: 0000000000000051 0000000000000000 <br>      ffff880fd6673f30: ffff880fd6673f78 ffffffff811df06f <br>   #4 [ffff880fd6673f38] sys_write at ffffffff811df06f<br>  crash&gt; struct file.f_path ffff880fc3761100<br>    f_path = {<br>      mnt = 0xffff880fe04d2520, <br>      dentry = 0xffff8808609dc240<br>    }<br>  crash&gt; struct file.f_path.dentry ffff880fc3761100<br>    f_path.dentry = 0xffff8808609dc240<br>  crash&gt; dentry.d_name.name 0xffff8808609dc240<br>    d_name.name = 0xffff8808609dc278 &quot;vmtoolsd.log&quot;<br>  crash&gt; dentry.d_name.name,d_sb 0xffff8808609dc240<br>    d_name.name = 0xffff8808609dc278 &quot;vmtoolsd.log&quot;<br>    d_sb = 0xffff880fe34cb000<br><br>crosscheck against what files vmtoolsd had open<br>  crash&gt; files<br>  PID: 1014   TASK: ffff880fe147e780  CPU: 3   COMMAND: &quot;vmtoolsd&quot;<br>  ROOT: /    CWD: /<br>   FD       FILE            DENTRY           INODE       TYPE PATH<br>  ...<br>  3 ffff880fc3761100 ffff8808609dc240 ffff88086708ac38 REG  /var/log/vmtoolsd.log<br><br>  crash&gt; dentry.d_sb ffff8808609dc240<br>    d_sb = 0xffff880fe34cb000<br>  crash&gt; mount | grep ffff880fe34cb000<br>  ffff880fe1625700 ffff880fe34cb000 xfs    /dev/sda3 /var<br><br>Check if its frozen https://access.redhat.com/articles/1225503<br>  crash&gt; p ((struct super_block *)0xffff880fe34cb000)-&gt;s_writers.frozen<br>  $1 = 4<br><br>  $ grep open-vm-tools installed-rpms<br>  open-vm-tools-9.10.2-4.el7.x86_64<br><br>So this is in a vmtoolsd that we ship. VMware are the upstream maintainers of this package,<br><br><publishedDate>2016-07-19T08:16:20Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HTb8bIAD"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-07-14T07:40:38Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-07-14T07:40:37Z</b><br><br>안녕하세요.<br><br>dropbox.redhat.com 에 sosreport-PEPSCL02SL-20160714111558.tar.xz 파일명으로 두번 째 노드의 sosreport 를 업로드 하였습니다.<br><br>확인 부탁 드립니다.<br><br>감사합니다.<br><br><publishedDate>2016-07-14T07:40:37Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HTb8RIAT"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-07-14T07:40:10Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-07-14T07:40:10Z</b><br><br>안녕하세요.<br><br>dropbox.redhat.com 에 sosreport-PEPSCL02SL-20160714111558.tar.xz 파일명으로 두번 째 노드의 sosreport 를 업로드 하였습니다.<br><br>확인 부탁 드립니다.<br><br>감사합니다.<br><br><publishedDate>2016-07-14T07:40:10Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HTTfOIAX"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-07-14T01:24:57Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-07-14T01:28:43Z</b><br><br>안녕하세요,<br>Red Hat Technical Account Manager 한진구 입니다.<br><br>올려주신 vmcore를 분석하여 답변 드리도록 하겠습니다.<br><br>vmcore분석은 일반적으로 영업일 기준 2-3일 정도 소요가 됩니다. 물론 그보다 빨리 분석이 되면 바로 안내드리도록 하겠습니다.<br><br><br>그리고.. 2번 노드의 sosreport도 함께 첨부 바랍니다.<br>======================<br><br><br><br>감사합니다.<br><br><publishedDate>2016-07-14T01:24:57Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HTMSWIA5"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-07-13T14:04:35Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-07-13T14:04:35Z</b><br><br>안녕하세요.<br><br>dropbox.redhat.com 에 vmcore-PEPSCL01SL 파일 명으로 덤프파일을 업로드 하였습니다.<br><br>감사합니다.<br><br><publishedDate>2016-07-13T14:04:35Z</publishedDate><createdByType>Customer</createdByType><br>======================<br></comments><br><br>오늘 (2016-07-13) 오후 15:00 경 PEPSCL01SL (Cluster node01) 에서 장애가 감지 되었습니다.<br><br>현재 상암센터 -&gt; 과천센터 VM Clone 작업을 진행중인데요, 비슷한 시간 Clone 작업이 있었다고 합니다.<br><br>SAR 및 messages 로그를 확인 한 결과 오후 14:14 경부터 O/S Hang 상태로 추측하고 있지만, <br><br>Ping 테스트를 했을 때, Cluster 의 H/B , Service VIP 모두 살아 있었으며, H/B 에 문제가 없어 실제 Cluster Token 에 문제가 없어 Failover 가 되지는 않았습니다.<br><br>(단지 SAP Process 등이 Hang 상태로 빠져서 인지 Application 자체 서비스에 문제가 있었습니다.)</issue><environment>확인 된 장애는 아래와 같습니다.<br><br>1. PEPSCL02SL (node02) 에서 pcs status 했을 때, PEPSCL01SL (node01) 노드의 pcsd 상태 감지 실패<br><br>2. PEPSCL01SL (node01) SSH 로그인 실패<br><br>3. VMWare Console 로 확인 했을 때 SAP 관련 Process hung_task_timeout 120sec 메세지 출력 중임을 확인.<br><br>장애조치는 아래와 같이 진행하였습니다.<br><br>1. VMWare 에서 NMI Signal 을 이용하여 O/S Crash (vmcore 수집)<br><br>2. PEPSCL02SL (node02) 에서 kdump_fence 성공하여 Resource Failover</environment><periodicityOfIssue>클러스터의 PCSD 서비스 통신이 불가하여, resource move 도 불가능 상태였습니다.<br><br>보내드리는 vmcore 데이터를 통해 2016-07-13 14:14 Hang 원인에 대해 확인 부탁 드립니다.</periodicityOfIssue><timeFramesAndUrgency>dropbox.redhat.com 에 아래와 같은 파일을 업로드 하겠습니다.<br><br>1. sosreport-PEPSCL01SL-20160713154427.tar.xz (업로드 완료)<br><br>2. vmcore-PEPSCL01SL (별도 업로드 후 Comment 남기겠습니다.)<br><br>감사합니다.</timeFramesAndUrgency><cep>false</cep></case>