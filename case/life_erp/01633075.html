======================<br><b>생성계정 : 우택 심</b><br><b>생성날짜 : 2016-05-12T07:25:04Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2016-06-03T10:05:05Z</b><br><b>id : 500A000000UBucsIAD</b><br>======================<br><br><b><font size=15>
제목  : PPOSCL01SL Pacemaker 클러스터 Failover 실패 문의
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요. <br><br>2016-05-12 10:57:00 경 VMware Hypervisor 의 문제로 인해 PPOSCL01SL (VM) 문제가 발생하였습니다.<br><br>이로인해 클러스터 간 H/B Totem Checking 에 문제가 생겨 아래와 같이 클러스터 Failover 가 진행되다가 실패하였습니다.<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>1. May 12 10:57:00 PPOSCL01SL 클러스터 offline 감지<br>2. May 12 10:57:01 PPOSCL02SL -&gt; PPOSCL01SL kdump stonith 시작<br>3. May 12 10:58:01 kdump stonith timeout<br>4. May 12 10:58:01 PPOSCL02SL -&gt; PPOSCL01SL vmware stonith 시작<br>5. May 12 10:59:01 vmware stonith time expire<br><br>언제 문제가 발생했습니까? 이러한 문제가 자주 발생합니까? 반복적으로 발생합니까? 특정 시간에 발생합니까?<br><br>PPOSCL01SL VM 이 작동하고 있는 VMWare Host 에 문제가 있어 VCenter 에 PPOSCL01SL VM Reboot Action 을 보내도 응답이 없어 계속적으로 time expire 되는 문제로 판단 하고 있으나, 정확한 원인을 CEE 에서 확인 부탁 드립니다.<br><br>그리고 아래 /var/log/cluster/corosync.log 로그에서 발췌 한 기록을 보면, 위 2 ~ 5 과정이 kdump stonith 12회, vmware stonith 12회, 총 24회 retry 가 진행되었으며, 그 이후에는 더 이상 stonith retry 가 없었는데요, 이 retry 값이 어떻게 계산되어 적용 된 것인지 궁금합니다.<br><br> (각 Stonith 의 timeout 시간은 60초 입니다.)<br><br>아래는 /var/log/cluster/corosync.log 에서 발췌 한 로그 일부 입니다.<br><br>root@PPOSCL02SL /var/log/cluster # cat corosync.log | grep &quot;Call to kdump_stonith for PPOSCL01SL-HB&quot;<br>May 12 10:58:01 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:00:01 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:02:01 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:04:01 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:06:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:08:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:10:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:12:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:14:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:16:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:17:50 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br><br><br>root@PPOSCL02SL /var/log/cluster # cat corosync.log | grep https://urllib3.readthedocs.org/en/latest/security.html<br>May 12 10:59:01 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:103979 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:01:01 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:105656 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:03:01 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:107198 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:05:01 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:108660 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:07:02 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:110165 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:09:02 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:111674 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:11:02 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:113192 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:13:02 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:114697 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:15:02 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:116406 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:16:50 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:118570 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:18:38 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:119935 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br><br> <br>May 12 11:18:38 [30971] PPOSCL02SL       crmd:   notice: tengine_stonith_callback:      Stonith operation 12 for PPOSCL01SL-HB failed (Generic Pacemaker error): aborting transition.<br>May 12 11:18:38 [30971] PPOSCL02SL       crmd:   notice: abort_transition_graph:        Transition aborted: Stonith failed (source=tengine_stonith_callback:733, 0)<br>May 12 11:18:38 [30971] PPOSCL02SL       crmd:   notice: too_many_st_failures:          Too many failures to fence PPOSCL01SL-HB (11), giving up<br><br>문제 해결 기간 및  긴급도와 관련된 정보를 제공해 주시겠습니까?<br><br>문제가 발생했던 Host 가 정상화 되고,  PPOSCL01SL (VM) 에서 pcs cluster start 한 이후 Resource 가 PPOSCL02SL 로 정상적으로 Failover 되었습니다.<br><br>발생했던 클러스터 노드 2대의 sosreport 를 dropbox.redhat.com  에 업로드 하겠습니다.<br><br>감사합니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 4 (Low)</b><br><br><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-05-19T01:26:59Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-05-19T01:26:59Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>그 retry한 값들에 대해서는 아래와 같은 설정 파일들로 retry횟수를 조절하실 수 있습니다.<br><br>&gt; pcmk_reboot_retries, pcmk_off_retries, pcmk_list_retries, pcmk_monitor_retries<br><br><br>관련되어 참고할 만한 문서를 아래 첨부하여 드립니다.<br><br>https://access.redhat.com/solutions/1285983<br>======================<br>그리고 추가적으로, 저희 전문엔지니어는 아래와 같은 부분의 설정을 언급하고 있으며, 좋은 구성을위해서 아래의 설정을 검토하기를 권장하고 있습니다. 이부분에 대한 기존의 history가 있으면 공유 바랍니다.<br><br>- https://access.redhat.com/solutions/667443<br>======================<br>감사합니다.<br><br><publishedDate>2016-05-19T01:26:59Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000H82q4IAB"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-05-17T04:31:10Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-05-17T04:31:10Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>&gt; retry 된 회수는 어떻게 계산되어 반복된 것인지 궁금합니다.<br><br>retry 횟수 계산법을 문의하시는 특별한 이유가 있으신지요?<br>======================<br>감사합니다.<br><br><publishedDate>2016-05-17T04:31:10Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000H821fIAB"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-05-17T02:01:23Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-05-17T02:01:23Z</b><br><br>안녕하세요.<br><br>분석 답변 감사합니다.<br><br>그렇다면 kdump_stonith 와 vmware_stonith 가 번갈아가며, 11회 총 24분 동안 retry 되었는데,<br><br>retry 된 회수는 어떻게 계산되어 반복된 것인지 궁금합니다.<br><br>이 회수에 대해 설정이 가능한지 여부 확인 부탁드립니다.<br><br>감사합니다.<br><br><publishedDate>2016-05-17T02:01:23Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000H80ouIAB"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-05-17T00:35:27Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-05-17T01:18:37Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>본 케이스와 관련되어 저희 Cluster 전문 엔지니어의 분석 결과가 일전에 전달이 되었습니다.<br><br>분석에서도 클러스터 노드에 이슈가 생기게되었고, 클러스터는 펜싱을 위한 작업을 진행하였으나 VMware의 문제로 인하여 펜싱에 성공하지 못함에 따라 서비스가 fail-over되지 못하였습니다.<br><br>기본적으로 저희 클러스터는 정상적으로 펜싱을 성공하지 못한 경우, 리소스의 충돌 등의 이유로 펜싱이 되지 못합니다.<br><br><br>아래의 내용은 저힁 엔지니어 분석 내용입니다.<br><br>There was nothing in the logs that state why cluster node was fenced:<br>May 12 10:47:59 PPOSCL01SL crmd[31466]:  notice: State transition S_TRANSITION_ENGINE -&gt; S_IDLE [ input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd ]<br>May 12 11:22:15 PPOSCL01SL rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;7.4.7&quot; x-pid=&quot;967&quot; x-info=&quot;http://www.rsyslog.com&quot;] start<br><br>The surviving node noticed that token missed:<br>May 12 10:56:54 PPOSCL02SL corosync[30941]: [TOTEM ] A processor failed, forming new configuration.<br>May 12 10:57:00 PPOSCL02SL attrd[30969]:  notice: crm_update_peer_proc: Node PPOSCL01SL-HB[1] - state is now lost (was member)<br>May 12 10:57:00 PPOSCL02SL attrd[30969]:  notice: Removing all PPOSCL01SL-HB attributes for attrd_peer_change_cb<br>May 12 10:57:00 PPOSCL02SL attrd[30969]:  notice: Lost attribute writer PPOSCL01SL-HB<br>May 12 10:57:00 PPOSCL02SL attrd[30969]:  notice: Removing PPOSCL01SL-HB/1 from the membership list<br>May 12 10:57:00 PPOSCL02SL attrd[30969]:  notice: Purged 1 peers with id=1 and/or uname=PPOSCL01SL-HB from the membership cache<br>May 12 10:57:00 PPOSCL02SL pacemakerd[30965]:  notice: crm_reap_unseen_nodes: Node PPOSCL01SL-HB[1] - state is now lost (was member)<br>May 12 10:57:00 PPOSCL02SL corosync[30941]: [TOTEM ] A new membership (172.18.21.142:116) was formed. Members left: 1<br>May 12 10:57:00 PPOSCL02SL corosync[30941]: [TOTEM ] Failed to receive the leave message. failed: 1<br>May 12 10:57:00 PPOSCL02SL corosync[30941]: [QUORUM] Members[1]: 2<br><br>- corosync: [TOTEM ] A processor failed, forming new configuration. - Red Hat Customer Portal<br>  https://access.redhat.com/solutions/59425<br><br>The node will be fenced off:<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Node PPOSCL01SL-HB will be fenced because the node is no longer part of the cluster<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Node PPOSCL01SL-HB is unclean<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action PPOSSCS_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action PPOSSCS_script_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action ping:0_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action ping:0_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action kdump_stonith_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action vmware_stonith2_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action vmware_stonith2_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Scheduling Node PPOSCL01SL-HB for STONITH<br>May 12 10:57:01 PPOSCL02SL pengine[30970]:  notice: Move    PPOSSCS#011(Started PPOSCL01SL-HB -&gt; PPOSCL02SL-HB)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]:  notice: Move    PPOSSCS_script#011(Started PPOSCL01SL-HB -&gt; PPOSCL02SL-HB)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]:  notice: Stop    ping:0#011(PPOSCL01SL-HB)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]:  notice: Move    kdump_stonith#011(Started PPOSCL01SL-HB -&gt; PPOSCL02SL-HB)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]:  notice: Stop    vmware_stonith2#011(PPOSCL01SL-HB)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Calculated Transition 0: /var/lib/pacemaker/pengine/pe-warn-4.bz2<br><br><br>May 12 10:57:01 PPOSCL02SL crmd[30971]:  notice: Executing reboot fencing operation (36) on PPOSCL01SL-HB (timeout=60000)<br>May 12 10:57:01 PPOSCL02SL stonith-ng[30967]:  notice: Client crmd.30971.2df2ebc2 wants to fence (reboot) 'PPOSCL01SL-HB' with device '(any)'<br>May 12 10:57:01 PPOSCL02SL stonith-ng[30967]:  notice: Initiating remote operation reboot for PPOSCL01SL-HB: 682c832e-3613-4a02-ae35-f41c5b4d6d92 (0)<br>May 12 10:57:01 PPOSCL02SL stonith-ng[30967]:  notice: kdump_stonith can fence (reboot) PPOSCL01SL-HB: static-list<br>May 12 10:57:01 PPOSCL02SL stonith-ng[30967]:  notice: vmware_stonith1 can fence (reboot) PPOSCL01SL-HB: static-list<br><br>We see that first kdump was first agent that will fence the node, but timer eventually expired indicating that either kdump is not properly setup on node that was fenced or no kernel panic occurred cause kdump kernel to respond to the fence_kdump.<br>May 12 10:57:01 PPOSCL02SL crmd[30971]:  notice: Initiating action 30: start kdump_stonith_start_0 on PPOSCL02SL-HB (local)<br>May 12 10:57:01 PPOSCL02SL stonith-ng[30967]: warning: Agent 'fence_kdump' does not advertise support for 'reboot', performing 'off' action instead<br>May 12 10:57:01 PPOSCL02SL fence_kdump[102667]: waiting for message from '172.18.21.141'<br>May 12 10:58:01 PPOSCL02SL stonith-ng[30967]:  notice: Child process 102667 performing action 'off' timed out with signal 15<br>May 12 10:58:01 PPOSCL02SL stonith-ng[30967]:   error: Operation 'reboot' [102667] (call 2 from crmd.30971) for host 'PPOSCL01SL-HB' with device 'kdump_stonith' returned: -62 (Timer expired)<br>May 12 10:58:01 PPOSCL02SL stonith-ng[30967]:  notice: Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br><br>After fence_kdump attempted then fence_vmware was attempted on the cluster node. <br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]:  notice: Child process 103979 performing action 'reboot' timed out with signal 15<br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]:   error: Operation 'reboot' [103979] (call 2 from crmd.30971) for host 'PPOSCL01SL-HB' with device 'vmware_stonith1' returned: -62 (Timer expired)<br><br><br>Then we see that fence_vmware fails with a timeout as well. <br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:103979 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:103979 [   InsecureRequestWarning) ]<br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]:  notice: Call to vmware_stonith1 for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]:  notice: All fencing options to fence PPOSCL01SL-HB for crmd.30971@PPOSCL02SL-HB.682c832e failed<br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]:   error: Operation reboot of PPOSCL01SL-HB by PPOSCL02SL-HB for crmd.30971@PPOSCL02SL-HB.682c832e: Timer expired<br>May 12 10:59:01 PPOSCL02SL crmd[30971]:  notice: Stonith operation 2/36:0:0:3c12e83d-8eb8-437d-9b8d-44c22100a730: Timer expired (-62)<br>May 12 10:59:01 PPOSCL02SL crmd[30971]:  notice: Stonith operation 2 for PPOSCL01SL-HB failed (Timer expired): aborting transition.<br>May 12 10:59:01 PPOSCL02SL crmd[30971]:  notice: Transition aborted: Stonith failed (source=tengine_stonith_callback:733, 0)<br>May 12 10:59:01 PPOSCL02SL crmd[30971]:  notice: Peer PPOSCL01SL-HB was not terminated (reboot) by PPOSCL02SL-HB for PPOSCL02SL-HB: Timer expired (ref=682c832e-3613-4a02-ae35-f41c5b4d6d92) by client crmd.30971<br>[.....]<br>May 12 11:16:25 PPOSCL02SL fence_vmware_soap: Failed: Unable to obtain correct plug status or plug is not available<br>May 12 11:16:49 PPOSCL02SL fence_vmware_soap: Failed: Unable to obtain correct plug status or plug is not available<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]:   error: Operation 'reboot' [118570] (call 11 from crmd.30971) for host 'PPOSCL01SL-HB' with device 'vmware_stonith1' returned: -201 (Generic Pacemaker error)<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:118570 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:118570 [   InsecureRequestWarning) ]<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:118570 [ Failed: Unable to obtain correct plug status or plug is not available ]<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:118570 [  ]<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:118570 [  ]<br>[....]<br>May 12 11:18:38 PPOSCL02SL crmd[30971]:  notice: Too many failures to fence PPOSCL01SL-HB (11), giving up<br>May 12 11:18:38 PPOSCL02SL crmd[30971]:  notice: State transition S_TRANSITION_ENGINE -&gt; S_IDLE [ input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd ]<br>May 12 11:26:23 PPOSCL02SL corosync[30941]: [TOTEM ] A new membership (172.18.21.141:120) was formed. Members joined: 1<br>May 12 11:26:23 PPOSCL02SL corosync[30941]: [CPG   ] downlist left_list: 0 received in state 0<br>May 12 11:26:23 PPOSCL02SL crmd[30971]:  notice: pcmk_quorum_notification: Node PPOSCL01SL-HB[1] - state is now member (was lost)<br>May 12 11:26:23 PPOSCL02SL pacemakerd[30965]:  notice: pcmk_quorum_notification: Node PPOSCL01SL-HB[1] - state is now member (was lost)<br>May 12 11:26:23 PPOSCL02SL corosync[30941]: [QUORUM] Members[2]: 1 2<br><br>The fencing eventually gave up after so many unsuccessful attempts. Eventually the cluster node rejoined the cluster. <br><br><br>또한 추가적으로 저희 엔지니어가 가이드하는 내용중 일부를 아래 첨부하여 드립니다.<br><br>There is two stonith devices configured for fence_vmware_soap. Since they are talking to the same host, only 1 stonith device needs to be defined. Your fencing configuration is improperly configured:<br>$ grep vmware_stonith sos_commands/cluster/crm_report/PPOSCL02SL/cib.xml | grep -ie ipaddr -ie  pcmk_host_list -ie pcmk_host_map<br>          &lt;nvpair id=&quot;vmware_stonith1-instance_attributes-ipaddr&quot; name=&quot;ipaddr&quot; value=&quot;100.254.19.11&quot;/&gt;<br>          &lt;nvpair id=&quot;vmware_stonith1-instance_attributes-pcmk_host_list&quot; name=&quot;pcmk_host_list&quot; value=&quot;PPOSCL01SL-HB&quot;/&gt;<br>          &lt;nvpair id=&quot;vmware_stonith2-instance_attributes-ipaddr&quot; name=&quot;ipaddr&quot; value=&quot;100.254.19.11&quot;/&gt;<br>          &lt;nvpair id=&quot;vmware_stonith2-instance_attributes-pcmk_host_list&quot; name=&quot;pcmk_host_list&quot; value=&quot;PPOSCL02SL-HB&quot;/&gt;<br><br>Review this article on how to properly configured a fence_vmware_soap agent communicating to the same host (Vcenter/ESX). The cluster nodes use `pcmk_host_map` to create a map of &lt;cluster node name&gt; ---&gt; &lt;VMware VM name (case sensitive and name from doing a listing with fence_vmware_soap). This creates a 1 to many defined stonith device that multiple cluster nodes will use. <br>- How do I configure a stonith device using agent fence_vmware_soap in a RHEL 6 or 7 High Availability<br>  cluster with pacemaker? - Red Hat Customer Portal<br>  https://access.redhat.com/solutions/917813<br><br><br>감사합니다.<br><br><publishedDate>2016-05-17T00:35:27Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GEkG5IAL"><br>======================<br><b>생성계정 : Bradley, Shane</b><br><b>생성날짜 : 2016-05-12T17:11:51Z</b><br><b>마지막 답변자 : Bradley, Shane</b><br><b>마지막 수정 일자 : 2016-05-12T17:11:51Z</b><br><br>There was nothing in the logs that state why cluster node was fenced:<br>May 12 10:47:59 PPOSCL01SL crmd[31466]:  notice: State transition S_TRANSITION_ENGINE -&gt; S_IDLE [ input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd ]<br>May 12 11:22:15 PPOSCL01SL rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;7.4.7&quot; x-pid=&quot;967&quot; x-info=&quot;http://www.rsyslog.com&quot;] start<br><br>The surviving node noticed that token missed:<br>May 12 10:56:54 PPOSCL02SL corosync[30941]: [TOTEM ] A processor failed, forming new configuration.<br>May 12 10:57:00 PPOSCL02SL attrd[30969]:  notice: crm_update_peer_proc: Node PPOSCL01SL-HB[1] - state is now lost (was member)<br>May 12 10:57:00 PPOSCL02SL attrd[30969]:  notice: Removing all PPOSCL01SL-HB attributes for attrd_peer_change_cb<br>May 12 10:57:00 PPOSCL02SL attrd[30969]:  notice: Lost attribute writer PPOSCL01SL-HB<br>May 12 10:57:00 PPOSCL02SL attrd[30969]:  notice: Removing PPOSCL01SL-HB/1 from the membership list<br>May 12 10:57:00 PPOSCL02SL attrd[30969]:  notice: Purged 1 peers with id=1 and/or uname=PPOSCL01SL-HB from the membership cache<br>May 12 10:57:00 PPOSCL02SL pacemakerd[30965]:  notice: crm_reap_unseen_nodes: Node PPOSCL01SL-HB[1] - state is now lost (was member)<br>May 12 10:57:00 PPOSCL02SL corosync[30941]: [TOTEM ] A new membership (172.18.21.142:116) was formed. Members left: 1<br>May 12 10:57:00 PPOSCL02SL corosync[30941]: [TOTEM ] Failed to receive the leave message. failed: 1<br>May 12 10:57:00 PPOSCL02SL corosync[30941]: [QUORUM] Members[1]: 2<br><br>- corosync: [TOTEM ] A processor failed, forming new configuration. - Red Hat Customer Portal<br>  https://access.redhat.com/solutions/59425<br><br>The node will be fenced off:<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Node PPOSCL01SL-HB will be fenced because the node is no longer part of the cluster<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Node PPOSCL01SL-HB is unclean<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action PPOSSCS_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action PPOSSCS_script_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action ping:0_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action ping:0_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action kdump_stonith_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action vmware_stonith2_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Action vmware_stonith2_stop_0 on PPOSCL01SL-HB is unrunnable (offline)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Scheduling Node PPOSCL01SL-HB for STONITH<br>May 12 10:57:01 PPOSCL02SL pengine[30970]:  notice: Move    PPOSSCS#011(Started PPOSCL01SL-HB -&gt; PPOSCL02SL-HB)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]:  notice: Move    PPOSSCS_script#011(Started PPOSCL01SL-HB -&gt; PPOSCL02SL-HB)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]:  notice: Stop    ping:0#011(PPOSCL01SL-HB)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]:  notice: Move    kdump_stonith#011(Started PPOSCL01SL-HB -&gt; PPOSCL02SL-HB)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]:  notice: Stop    vmware_stonith2#011(PPOSCL01SL-HB)<br>May 12 10:57:01 PPOSCL02SL pengine[30970]: warning: Calculated Transition 0: /var/lib/pacemaker/pengine/pe-warn-4.bz2<br><br><br>May 12 10:57:01 PPOSCL02SL crmd[30971]:  notice: Executing reboot fencing operation (36) on PPOSCL01SL-HB (timeout=60000)<br>May 12 10:57:01 PPOSCL02SL stonith-ng[30967]:  notice: Client crmd.30971.2df2ebc2 wants to fence (reboot) 'PPOSCL01SL-HB' with device '(any)'<br>May 12 10:57:01 PPOSCL02SL stonith-ng[30967]:  notice: Initiating remote operation reboot for PPOSCL01SL-HB: 682c832e-3613-4a02-ae35-f41c5b4d6d92 (0)<br>May 12 10:57:01 PPOSCL02SL stonith-ng[30967]:  notice: kdump_stonith can fence (reboot) PPOSCL01SL-HB: static-list<br>May 12 10:57:01 PPOSCL02SL stonith-ng[30967]:  notice: vmware_stonith1 can fence (reboot) PPOSCL01SL-HB: static-list<br><br>We see that first kdump was first agent that will fence the node, but timer eventually expired indicating that either kdump is not properly setup on node that was fenced or no kernel panic occurred cause kdump kernel to respond to the fence_kdump.<br>May 12 10:57:01 PPOSCL02SL crmd[30971]:  notice: Initiating action 30: start kdump_stonith_start_0 on PPOSCL02SL-HB (local)<br>May 12 10:57:01 PPOSCL02SL stonith-ng[30967]: warning: Agent 'fence_kdump' does not advertise support for 'reboot', performing 'off' action instead<br>May 12 10:57:01 PPOSCL02SL fence_kdump[102667]: waiting for message from '172.18.21.141'<br>May 12 10:58:01 PPOSCL02SL stonith-ng[30967]:  notice: Child process 102667 performing action 'off' timed out with signal 15<br>May 12 10:58:01 PPOSCL02SL stonith-ng[30967]:   error: Operation 'reboot' [102667] (call 2 from crmd.30971) for host 'PPOSCL01SL-HB' with device 'kdump_stonith' returned: -62 (Timer expired)<br>May 12 10:58:01 PPOSCL02SL stonith-ng[30967]:  notice: Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br><br>After fence_kdump attempted then fence_vmware was attempted on the cluster node. <br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]:  notice: Child process 103979 performing action 'reboot' timed out with signal 15<br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]:   error: Operation 'reboot' [103979] (call 2 from crmd.30971) for host 'PPOSCL01SL-HB' with device 'vmware_stonith1' returned: -62 (Timer expired)<br><br><br>Then we see that fence_vmware fails with a timeout as well. <br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:103979 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:103979 [   InsecureRequestWarning) ]<br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]:  notice: Call to vmware_stonith1 for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]:  notice: All fencing options to fence PPOSCL01SL-HB for crmd.30971@PPOSCL02SL-HB.682c832e failed<br>May 12 10:59:01 PPOSCL02SL stonith-ng[30967]:   error: Operation reboot of PPOSCL01SL-HB by PPOSCL02SL-HB for crmd.30971@PPOSCL02SL-HB.682c832e: Timer expired<br>May 12 10:59:01 PPOSCL02SL crmd[30971]:  notice: Stonith operation 2/36:0:0:3c12e83d-8eb8-437d-9b8d-44c22100a730: Timer expired (-62)<br>May 12 10:59:01 PPOSCL02SL crmd[30971]:  notice: Stonith operation 2 for PPOSCL01SL-HB failed (Timer expired): aborting transition.<br>May 12 10:59:01 PPOSCL02SL crmd[30971]:  notice: Transition aborted: Stonith failed (source=tengine_stonith_callback:733, 0)<br>May 12 10:59:01 PPOSCL02SL crmd[30971]:  notice: Peer PPOSCL01SL-HB was not terminated (reboot) by PPOSCL02SL-HB for PPOSCL02SL-HB: Timer expired (ref=682c832e-3613-4a02-ae35-f41c5b4d6d92) by client crmd.30971<br>[.....]<br>May 12 11:16:25 PPOSCL02SL fence_vmware_soap: Failed: Unable to obtain correct plug status or plug is not available<br>May 12 11:16:49 PPOSCL02SL fence_vmware_soap: Failed: Unable to obtain correct plug status or plug is not available<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]:   error: Operation 'reboot' [118570] (call 11 from crmd.30971) for host 'PPOSCL01SL-HB' with device 'vmware_stonith1' returned: -201 (Generic Pacemaker error)<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:118570 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:118570 [   InsecureRequestWarning) ]<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:118570 [ Failed: Unable to obtain correct plug status or plug is not available ]<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:118570 [  ]<br>May 12 11:16:50 PPOSCL02SL stonith-ng[30967]: warning: vmware_stonith1:118570 [  ]<br>[....]<br>May 12 11:18:38 PPOSCL02SL crmd[30971]:  notice: Too many failures to fence PPOSCL01SL-HB (11), giving up<br>May 12 11:18:38 PPOSCL02SL crmd[30971]:  notice: State transition S_TRANSITION_ENGINE -&gt; S_IDLE [ input=I_TE_SUCCESS cause=C_FSA_INTERNAL origin=notify_crmd ]<br>May 12 11:26:23 PPOSCL02SL corosync[30941]: [TOTEM ] A new membership (172.18.21.141:120) was formed. Members joined: 1<br>May 12 11:26:23 PPOSCL02SL corosync[30941]: [CPG   ] downlist left_list: 0 received in state 0<br>May 12 11:26:23 PPOSCL02SL crmd[30971]:  notice: pcmk_quorum_notification: Node PPOSCL01SL-HB[1] - state is now member (was lost)<br>May 12 11:26:23 PPOSCL02SL pacemakerd[30965]:  notice: pcmk_quorum_notification: Node PPOSCL01SL-HB[1] - state is now member (was lost)<br>May 12 11:26:23 PPOSCL02SL corosync[30941]: [QUORUM] Members[2]: 1 2<br><br>The fencing eventually gave up after so many unsuccessful attempts. Eventually the cluster node rejoined the cluster. <br><br>-------------------------------------------------------------------------------------------------<br>Summary<br>-------------------------------------------------------------------------------------------------<br><br>Finding out why token was lost can be very difficult and assumptions have to be made because we usually do not have a &quot;smoking gun&quot; as to the reason a token was lost. It is very difficult to find the key that explains the token lost in some situations. What we can do is analyze the data that we have and make a couple assumptions to help us point in the right direction as to what caused the token lost. <br><br>- What can I do to determine what caused &quot;A processor failed, forming new configuration&quot; and/or a node to be<br>  fenced in a RHEL 6 or 7 High Availability cluster?<br>  https://access.redhat.com/solutions/122293<br><br>The totem's token can be thought of as the cluster's heartbeat, and the token setting is the amount of time the cluster will wait for that message to be received from another node declaring it as lost. If the cluster node is unable to receive totem token from other node in cluster within totem token timeout period then the failed node will be fenced out of the cluster. fence operation will reboot the failed node so that it can rejoin the cluster with a clean state. <br><br>A token loss is a fairly generic event that indicates connectivity between two or more nodes was disrupted or a node stopped responding. The services openais(RHEL 5) or corosync(RHEL 6, RHEL 7) and cman or pacemaker use a unicast token that is passed between nodes to determine which are alive and participating in the cluster. <br><br>There are 3 general causes for token lost:<br>• A panic or hard stop could cause a token to be lost. <br>  Setup `kdump` to capture a vmcore to see if a kernel panic is the reason of the token lost, if it does occur<br>  then we focus on that and if not we can eliminate that as possible cause of token lost.<br>  - How do I configured kdump for use with the RHEL 6 High-Availability addon?<br>    https://access.redhat.com/articles/67570<br>• Resource utilization can cause token lost such as a high load on I/O, cpu, memory, or network prevent<br>   token from being processed. In some situation a log event will be recorded stated that the process was not <br>   scheduled.  See links on token lost above for more information on troubleshooting.<br>• A network issue in the network stack like the network card, network switch, etc cause a token to be lost.<br>  See links on token lost above for more information on troubleshooting.<br><br>If kdump is properly configured and has been tested then we can say that a kernel panic was not the reason for the token lost.<br><br>----<br><br>Then the fence agent fence_vmware failed to fence the cluster node off because it kept timing out. This continue to fail over and over. For whatever reason the fence_vmware device was erroring out with the following message: &quot; Failed: Unable to obtain correct plug status or plug is not available &quot;<br><br>Verify that your options used with pacemaker and from the command line are correct and that requirements are met. It very well could mean that it is incorrect uuid/name of vm.<br><br>- What are the requirements for using the fence agent fence_vmware_soap? - Red Hat Customer Portal<br>  https://access.redhat.com/solutions/306233<br><br>This issue is known to occur when the filesystem<br>- &quot;Unable to obtain correct plug status or plug is not available&quot; in RHEL 7 - Red Hat Customer Portal<br>  https://access.redhat.com/solutions/2018033<br><br><br>There is two stonith devices configured for fence_vmware_soap. Since they are talking to the same host, only 1 stonith device needs to be defined. Your fencing configuration is improperly configured:<br>$ grep vmware_stonith sos_commands/cluster/crm_report/PPOSCL02SL/cib.xml | grep -ie ipaddr -ie  pcmk_host_list -ie pcmk_host_map<br>          &lt;nvpair id=&quot;vmware_stonith1-instance_attributes-ipaddr&quot; name=&quot;ipaddr&quot; value=&quot;100.254.19.11&quot;/&gt;<br>          &lt;nvpair id=&quot;vmware_stonith1-instance_attributes-pcmk_host_list&quot; name=&quot;pcmk_host_list&quot; value=&quot;PPOSCL01SL-HB&quot;/&gt;<br>          &lt;nvpair id=&quot;vmware_stonith2-instance_attributes-ipaddr&quot; name=&quot;ipaddr&quot; value=&quot;100.254.19.11&quot;/&gt;<br>          &lt;nvpair id=&quot;vmware_stonith2-instance_attributes-pcmk_host_list&quot; name=&quot;pcmk_host_list&quot; value=&quot;PPOSCL02SL-HB&quot;/&gt;<br><br>Review this article on how to properly configured a fence_vmware_soap agent communicating to the same host (Vcenter/ESX). The cluster nodes use `pcmk_host_map` to create a map of &lt;cluster node name&gt; ---&gt; &lt;VMware VM name (case sensitive and name from doing a listing with fence_vmware_soap). This creates a 1 to many defined stonith device that multiple cluster nodes will use. <br>- How do I configure a stonith device using agent fence_vmware_soap in a RHEL 6 or 7 High Availability<br>  cluster with pacemaker? - Red Hat Customer Portal<br>  https://access.redhat.com/solutions/917813<br><br>I would remove the currently configured stonith devices and then create new stonith devices based on the article above. Then after the stonith devices are created then you should test to verify that fencing occurs when a cluster node is evicted.<br>- What is the proper way to simulate a network failure on a RHEL Cluster?<br>  https://access.redhat.com/solutions/79523<br><br>When there are multiple stonith agents configured for the same fence_vmware_soap host then the following documented in this article below can fail.<br>- pcs shows several &quot;Failed actions&quot; for my fence_vmware_soap devices with &quot;'unknown error' (1)&quot; and <br>  status=Timed Out&quot; in RHEL 6 with pacemaker  <br>  https://access.redhat.com/solutions/667443)<br><br><publishedDate>2016-05-12T17:11:51Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GEcqqIAD"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-05-12T07:36:21Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-05-12T07:36:21Z</b><br><br>안녕하세요.<br><br>dropbox.redhat.com/incoming 에 아래와 같은 파일명으로 업로드 완료 하였습니다.<br><br>sosreport-PPOSCL01SL-20160512142226.tar.xz<br>sosreport-PPOSCL02SL-20160512142129.tar.xz<br><br>감사합니다.<br><br><publishedDate>2016-05-12T07:36:21Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GEcjkIAD"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-05-12T07:26:57Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-05-12T07:27:25Z</b><br><br>안녕하세요,<br>Red Hat Technical Account Manager 한진구 입니다.<br><br>관련 시스템 두대의 sosreport도 수집하여 케이스에 업데이트 바라며, dropbox에 업로드시 완료 후, 안내 바랍니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-05-12T07:26:57Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br><br>2016-05-12 10:57:00 경 VMware Hypervisor 의 문제로 인해 PPOSCL01SL (VM) 문제가 발생하였습니다.<br><br>이로인해 클러스터 간 H/B Totem Checking 에 문제가 생겨 아래와 같이 클러스터 Failover 가 진행되다가 실패하였습니다.</issue><environment>1. May 12 10:57:00 PPOSCL01SL 클러스터 offline 감지<br>2. May 12 10:57:01 PPOSCL02SL -&gt; PPOSCL01SL kdump stonith 시작<br>3. May 12 10:58:01 kdump stonith timeout<br>4. May 12 10:58:01 PPOSCL02SL -&gt; PPOSCL01SL vmware stonith 시작<br>5. May 12 10:59:01 vmware stonith time expire</environment><periodicityOfIssue>PPOSCL01SL VM 이 작동하고 있는 VMWare Host 에 문제가 있어 VCenter 에 PPOSCL01SL VM Reboot Action 을 보내도 응답이 없어 계속적으로 time expire 되는 문제로 판단 하고 있으나, 정확한 원인을 CEE 에서 확인 부탁 드립니다.<br><br>그리고 아래 /var/log/cluster/corosync.log 로그에서 발췌 한 기록을 보면, 위 2 ~ 5 과정이 kdump stonith 12회, vmware stonith 12회, 총 24회 retry 가 진행되었으며, 그 이후에는 더 이상 stonith retry 가 없었는데요, 이 retry 값이 어떻게 계산되어 적용 된 것인지 궁금합니다.<br><br> (각 Stonith 의 timeout 시간은 60초 입니다.)<br><br>아래는 /var/log/cluster/corosync.log 에서 발췌 한 로그 일부 입니다.<br><br>root@PPOSCL02SL /var/log/cluster # cat corosync.log | grep &quot;Call to kdump_stonith for PPOSCL01SL-HB&quot;<br>May 12 10:58:01 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:00:01 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:02:01 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:04:01 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:06:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:08:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:10:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:12:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:14:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:16:02 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br>May 12 11:17:50 [30967] PPOSCL02SL stonith-ng:   notice: process_remote_stonith_exec:   Call to kdump_stonith for PPOSCL01SL-HB on behalf of crmd.30971@PPOSCL02SL-HB: Timer expired (-62)<br><br><br>root@PPOSCL02SL /var/log/cluster # cat corosync.log | grep https://urllib3.readthedocs.org/en/latest/security.html<br>May 12 10:59:01 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:103979 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:01:01 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:105656 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:03:01 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:107198 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:05:01 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:108660 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:07:02 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:110165 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:09:02 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:111674 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:11:02 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:113192 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:13:02 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:114697 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:15:02 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:116406 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:16:50 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:118570 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br>May 12 11:18:38 [30967] PPOSCL02SL stonith-ng:  warning: log_operation: vmware_stonith1:119935 [ /usr/lib/python2.7/site-packages/urllib3/connectionpool.py:769: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html ]<br><br> <br>May 12 11:18:38 [30971] PPOSCL02SL       crmd:   notice: tengine_stonith_callback:      Stonith operation 12 for PPOSCL01SL-HB failed (Generic Pacemaker error): aborting transition.<br>May 12 11:18:38 [30971] PPOSCL02SL       crmd:   notice: abort_transition_graph:        Transition aborted: Stonith failed (source=tengine_stonith_callback:733, 0)<br>May 12 11:18:38 [30971] PPOSCL02SL       crmd:   notice: too_many_st_failures:          Too many failures to fence PPOSCL01SL-HB (11), giving up</periodicityOfIssue><timeFramesAndUrgency>문제가 발생했던 Host 가 정상화 되고,  PPOSCL01SL (VM) 에서 pcs cluster start 한 이후 Resource 가 PPOSCL02SL 로 정상적으로 Failover 되었습니다.<br><br>발생했던 클러스터 노드 2대의 sosreport 를 dropbox.redhat.com  에 업로드 하겠습니다.<br><br>감사합니다.</timeFramesAndUrgency><cep>false</cep></case>