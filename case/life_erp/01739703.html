======================<br><b>생성계정 : 우택 심</b><br><b>생성날짜 : 2016-11-14T15:26:17Z</b><br><b>마지막 답변자 : Jay Shin</b><br><b>마지막 수정 일자 : 2016-11-21T01:59:31Z</b><br><b>id : 500A000000VmWU2IAN</b><br>======================<br><br><b><font size=15>
제목  : 시스템 Shutdown 시 NMI Panic 관련 문의
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요.<br><br>어제 오픈했던 케이스 https://access.redhat.com/support/cases/#/case/01739163 와 별도로 Shutdown 시 18대 시스템 중 7대 시스템에서 NMI Panic (vmcore 생성) 되는 문제가 발견 되었습니다.<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>가용성 테스트 중 SAN SCSI 절체 테스트를 진행하였고, <br><br>정상적인 umount 아닌 I/O Error 가 발생 된 상태로 systemctl reboot 을 하였습니다.<br><br>오랜 시간 시스템 연결이 안되어 살펴보니 7대 시스템에서 kdump -&gt; vmcore -&gt; reboot 이 되었음을 확인하였고, 아래와 같은 로그가 공통적으로 기록 되었습니다.<br><br>Nov 14 14:47:43 ISLTAL06SL hpasmlited[2600]: hpDeferSPDThread: Starting thread to collect DIMM SPD Data.<br>Nov 14 14:47:43 ISLTAL06SL hpasmlited[2600]: Initialize data structures successful<br>Nov 14 14:47:44 ISLTAL06SL hp-ams[2040]: CRITICAL: An Unrecoverable System Error (NMI) has occurred (Service Information: 0x00CC47F0, 0x00CC4AF0)<br><br>문제 해결 기간 및  긴급도와 관련된 정보를 제공해 주시겠습니까?<br><br>7대 중 ISLTAL06SL 시스템의 vmcore / sosreport / log 데이터를 dropbox.redhat.com 에 아래와 같은 파일명으로 업로드 하였습니다.<br><br>ISLTAL06SL_LOG.tar.gz<br>ISLTAL06SL_sosreport.tar.xz<br>ISLTAL06SL_vmcore.tar.gz<br><br>확인 부탁 드립니다.<br>감사합니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 4 (Low)</b><br><enhancedSLA>false</enhancedSLA><contactIsPartner>false</contactIsPartner><tags/><br><br><comment id="a0aA000000II2cGIAT"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2016-11-21T01:59:31Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2016-11-21T01:59:30Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>먼저, 본 기술 문의가 해결되어 다행입니다.<br><br>만약 본 기술 문의와 관련하여 추가 질문이 있으시다면 언제든지 본 기술 문의를 재개하실 수 있습니다.<br><br>기술 문의가 처리 완료되면 *고객 설문조사* 메일이 발송됩니다. 고객님께서 남기신 의견은 보다 나은 서비스를 위해 지속적으로 반영될 것입니다.<br>향후 기술 지원 서비스의 품질 향상을 위해, 소중한 시간을 내어 주시면 대단히 감사드리겠습니다.<br><br>감사합니다.<br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>GSS, Asia Pacific, Red Hat Inc<br><br><publishedDate>2016-11-21T01:59:30Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000II2aeIAD"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-11-21T01:54:15Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-11-21T01:54:15Z</b><br><br>지원 감사합니다.<br><br>본 케이스는 Closed 하도록 하겠습니다.<br><br><publishedDate>2016-11-21T01:54:15Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000II2VtIAL"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2016-11-21T01:41:39Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2016-11-21T01:41:38Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>아래 문서에 따르면, 600초로 기본 설정되어있습니다.<br><br>ShutdownWatchdogSec is set to 10 minutes i.e. 600 seconds.<br><br>* A few HP Gen8 and Gen9 systems are crashing due to NMI. <br>  https://access.redhat.com/solutions/1309033<br><br>감사합니다.<br><br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>Email: jaeshin@redhat.com <br><br>Red Hat, Asia-Pacific Pty Ltd <br>Website: www.redhat.com<br><br><publishedDate>2016-11-21T01:41:38Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000II2T9IAL"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-11-21T01:34:36Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-11-21T01:34:36Z</b><br><br>안녕하세요.<br><br>이번 케이스와 관련하여 한 가지 더 문의 드립니다.<br><br>OS 에서 reboot Signal 이 Hardware 로 이미 전달 된 상태에서 umount hang 상태가 지속 된다면, <br><br>Hardware watchdog 에서 얼마 만에 이번 케이스처럼 NMI 를 유발하는지 궁금 합니다.<br><br>실제로 iLO 로그를 살펴보니 해당 시간에 NMI 발생 로그가 있습니다.<br><br>확인 부탁 드립니다.<br><br>감사합니다.<br><br><publishedDate>2016-11-21T01:34:36Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000II2MrIAL"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2016-11-21T01:16:50Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2016-11-21T01:16:50Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>본 기술 문의의 상태를 처리완료 상태로 변경하고자 합니다.<br><br>만약 본 기술 문의와 관련하여 추가 질문이 있으시다면 언제든지 본 기술 문의를 *재개*하실 수 있습니다.<br><br>기술 문의가 처리 완료되면 *고객 설문조사* 메일이 발송됩니다. 고객님께서 남기신 의견은 보다 나은 서비스를 위해 지속적으로 반영될 것입니다.<br>향후 기술 지원 서비스의 품질 향상을 위해, 소중한 시간을 내어 주시면 대단히 감사드리겠습니다.<br><br>만약 본 이슈와 관련하여 추가적인 문의 사항이 있으실 경우 연락 주시기 바랍니다.<br><br>감사합니다.<br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>GSS, Asia Pacific, Red Hat Inc<br><br><publishedDate>2016-11-21T01:16:50Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IHkEAIA1"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2016-11-17T23:57:56Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2016-11-17T23:57:56Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 입니다.<br><br>본 케이스와 연관되어 더 궁금한 사항이 있거나 추가적인 지원이 필요하신가요?<br><br>본 안내 후 일주일 이내에 별다른 답변이 없다면 자동으로 종료 상태가 된다는 것을 알려 드립니다.<br><br>만약 추가적인 지원이 필요하다면, 연락 부탁드립니다.<br><br>감사합니다.<br><br>Jay Shin<br>Technical Support Engineer<br>GSS, Asia Pacific, Red Hat Inc<br><br><publishedDate>2016-11-17T23:57:56Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IH4NjIAL"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2016-11-15T04:51:35Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2016-11-15T04:51:35Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>시스템 패닉은 아래 DIE_DEBUG 값을 가지고 있으며, hp watchdog 에 의하여 패닉이 발생한 것으로 확인됩니다.<br><br>---------------------------------------------------------<br>crash&gt; bt -f<br>...<br> #2 [ffff885effa05de8] panic at ffffffff8162ea73<br>    ffff885effa05df0: 0000000000000008 ffff885effa05e70 <br>    ffff885effa05e00: ffff885effa05e10 d9aa44629659377d <br>    ffff885effa05e10: 00000000791b4028 ffffc90070e1c072 <br>    ffff885effa05e20: 0000000000000001 0000000000000001 <br>    ffff885effa05e30: 0000000000000000 0000000000000001 <br>    ffff885effa05e40: ffffffffa0495000 0000000000000000 <br>    ffff885effa05e50: ffffffff819556f0 0000000000000003 &lt;&lt;&lt; 0x03 : die value<br>    ffff885effa05e60: ffff885effa05e78 ffffffffa04938ed <br> #3 [ffff885effa05e68] hpwdt_pretimeout at ffffffffa04938ed [hpwdt]<br>...<br><br>/* Grossly misnamed. */<br>enum die_val {<br>  DIE_OOPS = 1,<br>  DIE_INT3,<br>  DIE_DEBUG,     &lt;-- 03 (0x03)<br>  DIE_PANIC,<br>  DIE_NMI,<br>  DIE_DIE,<br>  DIE_NMIWATCHDOG,<br>  DIE_KERNELDEBUG,<br>  DIE_TRAP,<br>  DIE_GPF,<br>  DIE_CALL,<br>  DIE_NMI_IPI,<br>  DIE_PAGE_FAULT,<br>  DIE_NMIUNKNOWN, <br>  DIE_NMIMEMPARITY,<br>  DIE_NMIIOCHECK,<br>};<br>---------------------------------------------------------<br><br>crash&gt; ps -m | grep UN<br>[ 0 00:09:50.381] [UN]  PID: 1      TASK: ffff88be6ef90000  CPU: 2   COMMAND: &quot;systemd-shutdow&quot;<br>[ 0 00:10:56.765] [UN]  PID: 10371  TASK: ffff88be669cd080  CPU: 44  COMMAND: &quot;umount&quot;<br><br>crash&gt; set 10371<br>    PID: 10371<br>COMMAND: &quot;umount&quot;<br>   TASK: ffff88be669cd080  [THREAD_INFO: ffff88be66af4000]<br>    CPU: 44<br>  STATE: TASK_UNINTERRUPTIBLE <br><br>crash&gt; bt<br>PID: 10371  TASK: ffff88be669cd080  CPU: 44  COMMAND: &quot;umount&quot;<br> #0 [ffff88be66af7d30] __schedule at ffffffff8163a26d<br> #1 [ffff88be66af7d98] schedule at ffffffff8163a909<br> #2 [ffff88be66af7da8] xfs_ail_push_all_sync at ffffffffa0211c41 [xfs]<br> #3 [ffff88be66af7e10] xfs_unmountfs at ffffffffa01fcb08 [xfs]<br> #4 [ffff88be66af7e48] xfs_fs_put_super at ffffffffa01ff9c2 [xfs]<br> #5 [ffff88be66af7e60] generic_shutdown_super at ffffffff811e0ab6<br> #6 [ffff88be66af7e88] kill_block_super at ffffffff811e0f07<br> #7 [ffff88be66af7ea8] deactivate_locked_super at ffffffff811e1249<br> #8 [ffff88be66af7ec8] deactivate_super at ffffffff811e1846<br> #9 [ffff88be66af7ee0] mntput_no_expire at ffffffff811fe785<br>#10 [ffff88be66af7f08] sys_umount at ffffffff811ff8bf<br>#11 [ffff88be66af7f80] system_call_fastpath at ffffffff81645909<br>    RIP: 00007f227edad327  RSP: 00007ffe5751bdd8  RFLAGS: 00010206<br>    RAX: 00000000000000a6  RBX: ffffffff81645909  RCX: 0000000000000000<br>    RDX: 0000000000000001  RSI: 0000000000000000  RDI: 00007f2281105b30<br>    RBP: 00007f2281105b30   R8: 00007f2281106d00   R9: 0000000000000000<br>    R10: 00007ffe5751bac0  R11: 0000000000000246  R12: 00007f2281103040<br>    R13: 00007f228110b0a0  R14: 0000000000000000  R15: 00007f227f91dd38<br>    ORIG_RAX: 00000000000000a6  CS: 0033  SS: 002b<br><br><br>crash&gt; dis -rl ffffffffa01fcb08 | tail<br>0xffffffffa01fcaec &lt;xfs_unmountfs+76&gt;:<br>callq  0xffffffff811fa7e0 &lt;iput&gt;<br>/usr/src/debug/kernel-3.10.0-327.el7/linux-3.10.0-327.el7.x86_64/fs/xfs/xfs_mount.c: 987<br>0xffffffffa01fcaf1 &lt;xfs_unmountfs+81&gt;:<br>mov    $0x1,%esi<br>0xffffffffa01fcaf6 &lt;xfs_unmountfs+86&gt;:<br>mov    %r12,%rdi<br>0xffffffffa01fcaf9 &lt;xfs_unmountfs+89&gt;:<br>callq  0xffffffffa0206940 &lt;xfs_log_force&gt;<br>/usr/src/debug/kernel-3.10.0-327.el7/linux-3.10.0-327.el7.x86_64/fs/xfs/xfs_mount.c: 992 &lt;--------<br>0xffffffffa01fcafe &lt;xfs_unmountfs+94&gt;:<br>mov    0x10(%r12),%rdi<br>0xffffffffa01fcb03 &lt;xfs_unmountfs+99&gt;:<br>callq  0xffffffffa0211b80 &lt;xfs_ail_push_all_sync&gt;<br><br>https://access.redhat.com/labs/psb/versions/kernel-3.10.0-327.el7/fs/xfs/xfs_mount.c<br><br>  987     xfs_log_force(mp, XFS_LOG_SYNC);<br>  988<br>  989     /*<br>  990      * Flush all pending changes from the AIL.<br>  991      */<br>  992     xfs_ail_push_all_sync(mp-&gt;m_ail);  &lt;&lt;---------<br><br>crash&gt; dis -rl ffffffffa0211c41 | head -15<br>/usr/src/debug/kernel-3.10.0-327.el7/linux-3.10.0-327.el7.x86_64/fs/xfs/xfs_trans_ail.c: 597<br>0xffffffffa0211b80 &lt;xfs_ail_push_all_sync&gt;:<br>nopl   0x0(%rax,%rax,1) [FTRACE NOP]<br>0xffffffffa0211b85 &lt;xfs_ail_push_all_sync+5&gt;:<br>push   %rbp<br>0xffffffffa0211b86 &lt;xfs_ail_push_all_sync+6&gt;:<br>mov    %rsp,%rbp<br>0xffffffffa0211b89 &lt;xfs_ail_push_all_sync+9&gt;:<br>push   %r15<br>0xffffffffa0211b8b &lt;xfs_ail_push_all_sync+11&gt;:<br>push   %r14<br>0xffffffffa0211b8d &lt;xfs_ail_push_all_sync+13&gt;:<br>push   %r13<br>/usr/src/debug/kernel-3.10.0-327.el7/linux-3.10.0-327.el7.x86_64/include/linux/spinlock.h: 293<br>0xffffffffa0211b8f &lt;xfs_ail_push_all_sync+15&gt;:<br>lea    0x40(%rdi),%r13<br>/usr/src/debug/kernel-3.10.0-327.el7/linux-3.10.0-327.el7.x86_64/fs/xfs/xfs_trans_ail.c: 597<br>0xffffffffa0211b93 &lt;xfs_ail_push_all_sync+19&gt;:<br>push   %r12<br>0xffffffffa0211b95 &lt;xfs_ail_push_all_sync+21&gt;:<br>push   %rbx<br>0xffffffffa0211b96 &lt;xfs_ail_push_all_sync+22&gt;:<br>mov    %rdi,%rbx<br>/usr/src/debug/kernel-3.10.0-327.el7/linux-3.10.0-327.el7.x86_64/include/linux/spinlock.h: 293<br>0xffffffffa0211b99 &lt;xfs_ail_push_all_sync+25&gt;:<br>mov    %r13,%rdi<br><br>https://access.redhat.com/labs/psb/versions/kernel-3.10.0-327.el7/fs/xfs/xfs_trans_ail.c#line595<br><br>  591 /*<br>  592  * Push out all items in the AIL immediately and wait until the AIL is empty.<br>  593  */<br>  594 void<br>  595 xfs_ail_push_all_sync(<br>  596         struct xfs_ail  *ailp)<br>  597 {<br>  598         struct xfs_log_item     *lip;<br>  599         DEFINE_WAIT(wait);<br>  600 <br>  601         spin_lock(&amp;ailp-&gt;xa_lock);<br>  602         while ((lip = xfs_ail_max(ailp)) != NULL) {<br>  603                 prepare_to_wait(&amp;ailp-&gt;xa_empty, &amp;wait, TASK_UNINTERRUPTIBLE);<br>  604                 ailp-&gt;xa_target = lip-&gt;li_lsn;<br>  605                 wake_up_process(ailp-&gt;xa_task);<br>  606                 spin_unlock(&amp;ailp-&gt;xa_lock);<br>  607                 schedule();<br>  608                 spin_lock(&amp;ailp-&gt;xa_lock);<br>  609         }<br><br><br>static xfs_log_item_t *<br>xfs_ail_max(<br>        struct xfs_ail  *ailp)<br>{<br>        if (list_empty(&amp;ailp-&gt;xa_ail))<br>                return NULL;<br><br>        return list_entry(ailp-&gt;xa_ail.prev, xfs_log_item_t, li_ail);<br>}<br><br> #2 [ffff88be66af7da8] xfs_ail_push_all_sync at ffffffffa0211c41 [xfs]<br>    ffff88be66af7db0: 0000000000000000 ffff88be669cd080 <br>    ffff88be66af7dc0: ffffffff810a6ae0 ffff885e6c588170 <br>    ffff88be66af7dd0: ffff885e6c588170 000000007fe38633 <br>    ffff88be66af7de0: ffff88be6bedc000 ffff88be6bedc000 <br>    ffff88be66af7df0: ffff885e6c120cc0 ffff885e6cea4740 <br>    ffff88be66af7e00: ffff885e6cea4720 ffff88be66af7e40 <br>    ffff88be66af7e10: ffffffffa01fcb08 <br> #3 [ffff88be66af7e10] xfs_unmountfs at ffffffffa01fcb08 [xfs]<br><br>crash&gt; px (0xffff88be6bedc000 + 0x10)<br>$6 = 0xffff88be6bedc010<br>crash&gt; rd 0xffff88be6bedc010<br>ffff88be6bedc010:  ffff885e6c588100                    ..Xl^...<br>crash&gt; <br><br>crash&gt; struct xfs_ail ffff885e6c588100<br>struct xfs_ail {<br>  xa_mount = 0xffff88be6bedc000, <br>  xa_task = 0xffff88be56d48b80, <br>  xa_ail = {<br>    next = 0xffff885def438ab0, <br>    prev = 0xffff885b8bf74980<br>  }, <br>  xa_target = 365072250639, <br>  xa_target_prev = 365072250639, <br>  xa_cursors = {<br>    next = 0xffff885e6c588130, <br>    prev = 0xffff885e6c588130<br>  }, <br>  xa_lock = {<br>    {<br>      rlock = {<br>        raw_lock = {<br>          {<br>            head_tail = 2436272438, <br>            tickets = {<br>              head = 37174, <br>              tail = 37174<br>            }<br>          }<br>        }<br>      }<br>    }<br>  }, <br>  xa_last_pushed_lsn = 0, <br>  xa_log_flush = 0, <br>  xa_buf_list = {<br>    next = 0xffff885e6c588158, <br>    prev = 0xffff885e6c588158<br>  }, <br>  xa_empty = {<br>    lock = {<br>      {<br>        rlock = {<br>          raw_lock = {<br>            {<br>              head_tail = 3554726880, <br>              tickets = {<br>                head = 54240, <br>                tail = 54240<br>              }<br>            }<br>          }<br>        }<br>      }<br>    }, <br>    task_list = {<br>      next = 0xffff88be66af7dc8, <br>      prev = 0xffff88be66af7dc8<br>    }<br>  }<br>}<br><br>본 문제는 아래 버그질라에 언급된 umount 시에 EIO 에러를 출력하며 행에 빠지는 문제에 해당하는 것으로 보입니다.<br><br>https://bugzilla.redhat.com/show_bug.cgi?id=1267042<br><br>해당 버그질라는 얼마전에 출시된 Red Hat Enterprise Linux 7.3 을 통해 수정되었으며,<br>커널 버전을 kernel-3.10.0-514.el7 로 업그레이드하여 문제를 수정할 수 있을 것으로 보입니다.<br><br>감사합니다.<br><br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>Email: jaeshin@redhat.com <br><br>Red Hat, Asia-Pacific Pty Ltd <br>Website: www.redhat.com<br><br><publishedDate>2016-11-15T04:51:35Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IH2ZqIAL"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2016-11-15T00:13:57Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2016-11-15T00:13:57Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>해당 케이스는 담당자 TAM 이 처리하고 있으며 Collaboration 상태로 확인됩니다.<br>담당자에 의해 안내받으실 수 있을 것으로 생각됩니다.<br><br>감사합니다.<br><br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>Email: jaeshin@redhat.com <br><br>Red Hat, Asia-Pacific Pty Ltd <br>Website: www.redhat.com<br><br><publishedDate>2016-11-15T00:13:57Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000IH2XfIAL"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-11-15T00:07:38Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-11-15T00:07:38Z</b><br><br>안녕하세요.<br><br>그렇다면 kernel crash 가 발생한 NMI 이전에 이미 시스템 Hang 이 있었는데요, Hang 원인에 대해서 vmcore 분석결과를 알고 싶습니다.<br><br>동시에 7대에서 발생한 이유에 대해 정확히 파악이 필요한 상황입니다.<br><br>감사합니다.<br><br><publishedDate>2016-11-15T00:07:38Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000IH2NBIA1"><br>======================<br><b>생성계정 : Shin, Jay</b><br><b>생성날짜 : 2016-11-14T23:44:23Z</b><br><b>마지막 답변자 : Shin, Jay</b><br><b>마지막 수정 일자 : 2016-11-14T23:44:23Z</b><br><br>안녕하세요<br><br>Red Hat Global Support Services 를 이용해 주셔서 감사합니다.<br><br>HP Gen9 계열 시스템에서 빈번하게 발생하는 NMI Panic 에 대하여 아래 문서[1]에 관련 내용이 기술되어있습니다.<br>문서를 확인하여 NMI Panic 이 발생하지 않도록 설정을 완료하시기 바랍니다.<br><br>---------------------------------------------------------------<br>$ cat etc/systemd/system.conf|grep -v &quot;#&quot;<br><br>[Manager]<br>LogLevel=notice<br>---------------------------------------------------------------<br><br>[관련 문서]<br>[1] A few HP Gen8 and Gen9 systems are crashing due to NMI. <br>    https://access.redhat.com/solutions/1309033<br> <br>만약 본 이슈와 관련하여 추가적인 문의 사항이 있으실 경우 연락 주시기 바랍니다.<br><br>감사합니다.<br><br><br>Jay Shin, Technical Support Engineer<br><br>Office: +82 2 3490 5200 - ext 3 (기술문의)<br>Email: jaeshin@redhat.com <br><br>Red Hat, Asia-Pacific Pty Ltd <br>Website: www.redhat.com<br><br><publishedDate>2016-11-14T23:44:23Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br><br>어제 오픈했던 케이스 https://access.redhat.com/support/cases/#/case/01739163 와 별도로 Shutdown 시 18대 시스템 중 7대 시스템에서 NMI Panic (vmcore 생성) 되는 문제가 발견 되었습니다.</issue><environment>가용성 테스트 중 SAN SCSI 절체 테스트를 진행하였고, <br><br>정상적인 umount 아닌 I/O Error 가 발생 된 상태로 systemctl reboot 을 하였습니다.<br><br>오랜 시간 시스템 연결이 안되어 살펴보니 7대 시스템에서 kdump -&gt; vmcore -&gt; reboot 이 되었음을 확인하였고, 아래와 같은 로그가 공통적으로 기록 되었습니다.<br><br>Nov 14 14:47:43 ISLTAL06SL hpasmlited[2600]: hpDeferSPDThread: Starting thread to collect DIMM SPD Data.<br>Nov 14 14:47:43 ISLTAL06SL hpasmlited[2600]: Initialize data structures successful<br>Nov 14 14:47:44 ISLTAL06SL hp-ams[2040]: CRITICAL: An Unrecoverable System Error (NMI) has occurred (Service Information: 0x00CC47F0, 0x00CC4AF0)</environment><timeFramesAndUrgency>7대 중 ISLTAL06SL 시스템의 vmcore / sosreport / log 데이터를 dropbox.redhat.com 에 아래와 같은 파일명으로 업로드 하였습니다.<br><br>ISLTAL06SL_LOG.tar.gz<br>ISLTAL06SL_sosreport.tar.xz<br>ISLTAL06SL_vmcore.tar.gz<br><br>확인 부탁 드립니다.<br>감사합니다.</timeFramesAndUrgency><cep>false</cep></case>