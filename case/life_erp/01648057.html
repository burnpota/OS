======================<br><b>생성계정 : jimin kim</b><br><b>생성날짜 : 2016-06-08T01:51:53Z</b><br><b>마지막 답변자 : 우택 심</b><br><b>마지막 수정 일자 : 2016-07-05T07:09:16Z</b><br><b>id : 500A000000UZjPUIA1</b><br>======================<br><br><b><font size=15>
제목  : oracle db DISK I/O 지연
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>oracle db DISK I/O 지연이 발생하였고 I/O 성능을 향상시킬수 있는 방법을 문의드리려고 합니다.<br><br>문제 해결 기간 및  긴급도와 관련된 정보를 제공해 주시겠습니까?<br><br>안녕하세요 <br><br>SDS 상암센터 김지민 선임입니다.<br><br>아래의 내용으로 서버에서 이슈로 인하여 문의를 드리려고 합니다.<br>시스템 용도는 oracle DB가 설치 되어 있는 DB 서버이고 마이그레이션의 용도입니다.<br><br>sosreport는 담당 컨설턴트 분인 심우택 차장님 통해서 전달하겠습니다.<br><br>========================================<br>BO-DS (HP DL980 Gen7) Migration 시스템 성능 이슈<br><br> - 운영계와 개발/품질계 Migration 을 위해 구성된 BO-DS 시스템이 있습니다.<br><br> - Hitachi Storage 에서 5TB Disk 20ea LUN 을 할당 받아, (Multipath 사용)<br><br> - 이를 다시 LVM VG 20ea 로 구성하고, 여기에서 1TB LV 를 100ea 로 나눠 총 Mount 볼륨 100ea 로 사용하는 시스템 입니다.<br><br> - HBA (Qlogic) Port 2개만을 연결하여 현재 사용하고 있는데요, 성능 이슈가 제기 된 상태입니다.<br><br> - 몇 가지 대안이 나왔는데, 아래와 같습니다.<br><br> (a). Disk Block Size 8192 조정<br> - 이미 케이스가 오픈되어 불가하다는 답변을 받았습니다. (https://access.redhat.com/support/cases/#/case/01610765)<br><br> (b). HBA 추가 증설 후 14 Channel 을 이용하여 LUN 분산<br> - 과거 RockPlace 에서 테스트를 진행하였으나, 10~15% 가량의 성능향상이 있었다고 합니다.<br> - 하지만, 이렇게 변경하기 위해 100개의 파일시스템 구성을 다시 해야 합니다.<br><br> (c). XFS 등 다른 파일 시스템 구성<br> - 현재 EXT4 파일시스템을 변경하는 방안입니다.<br><br> (d). Multipath RoundRobin 방식 변경<br> - 여러개의 Channel 을 묶어 BandWidth 를 늘려 사용하는 방안입니다.<br> - 지원여부 확인 필요<br>========================================<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 6.5</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 4 (Low)</b><br><enhancedSLA>false</enhancedSLA><contactIsPartner>false</contactIsPartner><tags/><br><br><comment id="a0aA000000HN7jpIAD"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-07-05T07:09:01Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-07-05T07:09:01Z</b><br><br>안녕하세요.<br><br>현재 시스템 SAN 을 분리하여 LUN 및 dbf 파일 분산을 통해 재 구성하여 운영 중에 있습니다.<br><br>추가 이슈가 나올 시 다시 케이스를 열도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-07-05T07:09:01Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HLMcGIAX"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-06-27T05:06:16Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-06-27T05:06:16Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>업데이트 감사합니다.<br><br>tablespace 분리 후 테스트한 후에 업데이트 바랍니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-06-27T05:06:16Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HLMRAIA5"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-06-27T04:36:10Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-06-27T04:36:10Z</b><br><br>안녕하세요. <br><br>오늘 Storage LUN 을 다중 path 로 분산하는 물지적 작업과 Oracle dbf 파일을 여러 디렉토리에 분산해서 저장하는 작업을 진행하였습니다.<br><br>Migration AP 가동 후 문제점 또는 요구사항이 있을 시 추가로 코멘트 업데이트 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-06-27T04:36:10Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HJDAhIAP"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-06-15T07:20:46Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-06-15T07:20:46Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>성능향상이 있을지를 확인하기 위해서는 좀 더 데이터 수집이 필요할 것 같습니다.<br><br>가장 I/O가 많은 시점 그리고.. %util이 100%를 넘어가는 시점에서 아래의 명령어를 통해서 정보를 수집해주시기 바랍니다.<br><br><br># iostat -xk 1 &gt; iostat_-xk.txt<br><br>그리고 해당 시점에서 아래의 데이터도 같이 수집해주시기 바랍니다.<br><br># mpstat -P ALL 1<br>======================<br>감사합니다.<br><br><publishedDate>2016-06-15T07:20:46Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HJBszIAH"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-06-15T04:16:23Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-06-15T04:16:23Z</b><br><br>안녕하세요.<br><br>우선 확인된 sar 데이터 결과를 기준으로,<br><br>현 시스템에 HBA 채널을 2port 에서 4port 로 확장한다면, 로드밸런싱에 따른 성능향상이 있을지 궁금합니다.<br><br><publishedDate>2016-06-15T04:16:23Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HHvhXIAT"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-06-09T01:22:37Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-06-09T01:22:37Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>&gt; 8G HBA 가 read/write 합쳐서 최대 8G Bandwidth 인지 확인 부탁 드립니다<br><br>하드웨어의 모델에 따라 각각 다르기는 하지만 최근 하드웨어의 경우, 일반적으로 8G HBA의 경우, Read/write 별개로 각각 8Gbit의 Bandwidth를 가지는 것으로 알고 있습니다.<br><br>이와 관련되어서는 하드웨어 벤더쪽으로 해당 아답터의 성능에 대해서 별도의 문의하여 확인받으시기 바랍니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-06-09T01:22:37Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HHlyLIAT"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-06-08T10:11:44Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-06-08T10:11:44Z</b><br><br>Direct I/O 아닌 상태로 봐서는 전반적으로 8G HBA 의 최대 성능을 내고 있는 것으로 판단 됩니다.<br><br>단 운영 환경에서 LV 100ea 를 동시에 사용한다고 하면, 실제 read, write 가 각각 Bandwidth 를 사용하여 전체적으로 I/O 성능이 저하되는 것으로 예상됩니다.<br><br>그리고 8G HBA 가 read/write 합쳐서 최대 8G Bandwidth 인지 확인 부탁 드립니다.<br><br><publishedDate>2016-06-08T10:11:44Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HHlwFIAT"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-06-08T10:08:31Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-06-08T10:08:31Z</b><br><br>안녕하세요.<br><br>오늘 대상 장비에서 가장 사용 빈도가 높은 LVM 볼륨에 dd 로 테스트를 진행하였습니다.<br><br>첫 번째로 oflag=direct 와 두 번째로는 일반적인 방식으로 두 가지로 테스트 하였습니다.<br><br>[root@PIDSEL01SL:/oracle/MZ0/sapdata1/test] time dd if=/dev/zero of=test.img bs=1M count=10240 oflag=direct<br>10240+0 records in<br>10240+0 records out<br>10737418240 bytes (11 GB) copied, 23.0316 s, 466 MB/s<br><br>real    0m23.034s<br>user    0m0.011s<br>sys     0m5.822s<br><br>==============================================================================<br><br># iostat -xm 1 /dev/dm-165<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  100.00     0.00    50.00  1024.00     0.16    1.57   0.88   8.80<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.66    0.00    1.81    1.19    0.00   69.34<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  968.32     0.00   484.16  1024.00     1.52    1.57   0.87  84.26<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.77    0.00    1.98    1.10    0.00   69.15<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    5.00  966.00     0.07   481.03  1014.71     1.49    1.53   0.85  82.60<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.45    0.00    0.80    1.14    0.00   70.61<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  976.00     0.00   488.00  1024.00     1.52    1.56   0.86  83.80<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.46    0.00    0.75    1.13    0.00   70.66<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00 1002.00     0.00   487.13   995.66     1.57    1.57   0.89  88.70<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.64    0.00    1.35    0.95    0.00   70.06<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    4.00  892.00     0.06   444.03  1015.07     1.33    1.48   0.82  73.90<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.56    0.00    1.19    1.01    0.00   70.24<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    1.00  872.00     0.00   436.00  1022.84     1.35    1.54   0.86  75.10<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.39    0.00    0.99    1.01    0.00   70.60<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  874.00     0.00   437.00  1024.00     1.35    1.55   0.86  75.20<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.66    0.00    1.11    0.94    0.00   70.29<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    8.00  872.00     0.12   434.03  1010.40     1.36    1.55   0.86  75.40<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.34    0.00    0.96    0.90    0.00   70.79<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  875.00     0.00   425.10   994.97     1.32    1.52   0.83  72.60<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.11    0.00    0.95    1.20    0.00   70.74<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    1.00  868.00     0.00   434.00  1022.83     1.50    1.73   0.95  82.60<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.23    0.00    1.94    1.23    0.00   69.60<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    4.00  792.00     0.06   394.03  1013.95     1.59    2.00   1.06  84.70<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.64    0.00    2.43    1.08    0.00   68.85<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  944.00     0.00   472.00  1024.00     1.46    1.54   0.86  81.50<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.54    0.00    0.99    1.03    0.00   70.44<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  916.00     0.00   458.00  1024.00     1.42    1.55   0.85  78.10<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.58    0.00    1.14    0.94    0.00   70.34<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    5.00  875.00     0.07   423.13   984.89     1.33    1.51   0.83  73.20<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.38    0.00    0.89    0.93    0.00   70.81<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  850.00     0.00   425.00  1024.00     1.31    1.54   0.85  72.50<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.36    0.00    1.29    1.00    0.00   70.34<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  854.00     0.00   427.00  1024.00     1.34    1.57   0.86  73.60<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.62    0.00    1.43    0.95    0.00   70.00<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    8.00  926.00     0.12   434.24   952.45     1.39    1.49   0.80  74.60<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.55    0.00    0.95    0.98    0.00   70.52<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  864.00     0.00   432.00  1024.00     1.34    1.55   0.86  74.70<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.47    0.00    0.93    0.98    0.00   70.63<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    1.00  887.00     0.00   431.10   994.25     1.36    1.54   0.84  75.00<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.48    0.00    1.13    1.03    0.00   70.36<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00   13.00  882.00     0.20   431.16   987.07     1.36    1.52   0.85  75.70<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          26.88    0.00    1.01    1.18    0.00   70.92<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00  822.00     0.00   411.00  1024.00     1.38    1.68   0.93  76.10<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.75    0.00    1.55    1.09    0.00   69.61<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00 1014.00     0.00   449.16   907.19     1.41    1.39   0.75  76.10<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.91    0.00    3.51    1.03    0.00   67.56<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    5.00  904.00     0.07   450.03  1014.08     1.39    1.53   0.84  76.60<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.55    0.00    0.66    0.11    0.00   71.67<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00   25.00     0.00     0.10     8.00     0.00    0.04   0.04   0.10<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.62    0.00    0.61    0.20    0.00   71.57<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          27.66    0.00    0.75    0.11    0.00   71.48<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    8.00    4.00     0.12     0.03    26.67     0.00    0.00   0.00   0.00<br><br> ==============================================================================<br><br># sar -d 1 | grep dev253-165<br>16:58:24    DEV              tps             rd_sec/s  wr_sec/s    avgrq-sz  avgqu-sz     await     svctm     %util<br>16:55:32    dev253-165     26.26      0.00  26892.93   1024.00      0.04      1.38      0.85      2.22<br>16:55:33    dev253-165    951.46      0.00 974291.26   1024.00      1.50      1.58      0.88     83.30<br>16:55:34    dev253-165    978.79    137.37 993034.34   1014.70      1.50      1.53      0.85     83.03<br>16:55:35    dev253-165    976.00      0.00 999424.00   1024.00      1.52      1.55      0.85     83.40<br>16:55:36    dev253-165   1002.00      0.00 997648.00    995.66      1.56      1.56      0.88     88.30<br>16:55:37    dev253-165    900.00    128.00 913472.00   1015.11      1.36      1.51      0.84     75.80<br>16:55:38    dev253-165    896.94      8.16 917420.41   1022.84      1.36      1.51      0.84     75.41<br>16:55:39    dev253-165    861.39      0.00 882059.41   1024.00      1.35      1.57      0.87     75.35<br>16:55:40    dev253-165    890.91    258.59 899943.43   1010.43      1.37      1.54      0.85     75.96<br>16:55:41    dev253-165    875.00      0.00 870600.00    994.97      1.33      1.52      0.83     72.70<br>16:55:42    dev253-165    859.00      8.00 878592.00   1022.82      1.49      1.73      0.95     81.90<br>16:55:43    dev253-165    804.04    129.29 815127.27   1013.95      1.60      1.99      1.06     85.35<br>16:55:44    dev253-165    950.00      0.00 972800.00   1024.00      1.47      1.55      0.86     81.80<br>16:55:45    dev253-165    918.00      0.00 940032.00   1024.00      1.44      1.57      0.86     79.10<br>16:55:46    dev253-165    872.28    126.73 860015.84    986.09      1.31      1.50      0.83     71.98<br>16:55:47    dev253-165    859.60      8.08 879191.92   1022.81      1.32      1.54      0.85     73.23<br>16:55:48    dev253-165    862.63      0.00 883329.29   1024.00      1.36      1.57      0.87     74.65<br>16:55:49    dev253-165    941.41    258.59 896242.42    952.29      1.39      1.48      0.79     74.55<br>16:55:50    dev253-165    864.00      0.00 884736.00   1024.00      1.33      1.54      0.86     74.40<br>16:55:51    dev253-165    906.12      8.16 900906.12    994.25      1.41      1.55      0.85     77.24<br>16:55:52    dev253-165    888.12    411.88 876293.07    987.15      1.35      1.52      0.85     75.05<br>16:55:53    dev253-165    828.28      0.00 848161.62   1024.00      1.39      1.67      0.93     76.67<br>16:55:54    dev253-165   1006.00      0.00 911696.00    906.26      1.39      1.38      0.75     75.70<br>16:55:55    dev253-165    994.95    137.37 1009583.84   1014.85      1.52      1.53      0.84     83.74<br> <br>==============================================================================<br><br>[root@PIDSEL01SL:/oracle/MZ0/sapdata1/test] time dd if=/dev/zero of=test.img bs=1M count=10240<br>10240+0 records in<br>10240+0 records out<br>10737418240 bytes (11 GB) copied, 9.14787 s, 1.2 GB/s<br><br>real    0m9.150s<br>user    0m0.007s<br>sys     0m9.143s<br><br>==============================================================================<br><br># iostat -xm 1 /dev/dm-165<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00 185527.00     0.00   724.73     8.00 16652.60   86.45   0.01 100.00<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          23.68    0.00    3.46    1.88    0.00   70.99<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00 186672.00     0.00   729.23     8.00 11228.83   62.03   0.01 100.00<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          24.51    0.00    3.95    2.16    0.00   69.39<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    5.00 190128.00     0.07   742.69     8.00 11817.98   60.26   0.01 100.00<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          24.45    0.00    1.61    2.78    0.00   71.16<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    4.00 186324.00     0.02   727.79     8.00 17421.57   92.34   0.01 100.30<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          23.88    0.00    1.71    3.00    0.00   71.41<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    6.00 187773.00     0.02   733.49     8.00 17532.69   92.93   0.01  99.90<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          23.88    0.00    1.30    3.11    0.00   71.71<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00   12.00 184998.00     0.13   722.70     8.00 17618.09   95.44   0.01 100.10<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          23.75    0.00    1.39    2.98    0.00   71.87<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    9.00 187199.00     0.08   731.24     8.00 17520.72   93.24   0.01 100.10<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          24.22    0.00    2.29    2.60    0.00   70.89<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00   76.00 162690.00     0.38   635.51     8.00 15989.08  103.19   0.01  99.90<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          23.92    0.00    2.77    2.66    0.00   70.66<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00 202806.00     0.00   792.21     8.00 15602.33   72.64   0.00  99.90<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          24.02    0.00    1.33    3.43    0.00   71.22<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    6.00 186498.00     0.08   728.50     8.00 17894.99   95.32   0.01 100.10<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          24.73    0.00    1.54    3.51    0.00   70.22<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00 186969.00     0.00   730.32     8.00 18048.29   95.44   0.01 100.80<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          23.48    0.00    1.27    2.91    0.00   72.34<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00 186408.00     0.00   728.19     8.00 17770.61   95.04   0.01 100.00<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          23.41    0.00    1.14    2.72    0.00   72.74<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00 185392.00     0.00   724.16     8.00 17661.51   95.29   0.01  99.90<br><br>avg-cpu:  %user   %nice %system %iowait  %steal   %idle<br>          23.75    0.00    3.18    2.97    0.00   70.10<br><br>Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util<br>dm-165            0.00     0.00    0.00 186064.00     0.00   726.84     8.00 17767.23   94.71   0.01 100.10<br><br>==============================================================================<br><br># sar -d 1 | grep dev253-165<br>16:58:24    DEV              tps             rd_sec/s  wr_sec/s    avgrq-sz  avgqu-sz     await     svctm     %util<br>16:58:24    dev253-165 168457.14      0.00 1347640.82      8.00  14207.87     80.03      0.01     85.61<br>16:58:25    dev253-165 187513.27      0.00 1500138.78      8.00  12338.61     68.11      0.01    102.04<br>16:58:26    dev253-165 192954.55    137.37 1543587.88      8.00  10852.04     54.05      0.01    100.81<br>16:58:27    dev253-165 201156.67     26.67 1609253.33      8.00  19312.15     95.70      0.01    111.67<br>16:58:28    dev253-165 191691.00     48.00 1533464.00      8.00  17461.33     89.73      0.01     99.90<br>16:58:29    dev253-165 186310.00    264.00 1490424.00      8.00  17593.19     94.48      0.01    100.00<br>16:58:30    dev253-165 190334.34    169.70 1522610.10      8.00  17664.66     92.78      0.01    101.21<br>16:58:31    dev253-165 187267.00     32.00 1498104.00      8.00  17641.65     93.91      0.01    100.60<br>16:58:32    dev253-165 179934.69    775.51 1438889.80      8.00  14276.75     79.51      0.01    101.43<br>16:58:33    dev253-165 184778.43    156.86 1478172.55      8.00  17495.71     93.87      0.01     98.04<br>16:58:34    dev253-165 184320.00      0.00 1474560.00      8.00  18019.76     96.69      0.01    100.70<br>16:58:35    dev253-165 192915.31      0.00 1543330.61      8.00  18228.67     93.68      0.01    102.14<br>16:58:36    dev253-165 184448.00      0.00 1475584.00      8.00  17664.99     95.92      0.01     99.90<br>16:58:37    dev253-165 186112.00      0.00 1488896.00      8.00  17738.12     94.92      0.01    100.10<br><br><publishedDate>2016-06-08T10:08:31Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HHkgFIAT"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-06-08T07:52:45Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-06-08T07:52:45Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>우선 보내주신 sosreport와 문의주신 내용들을 검토하고 답변 드립니다.<br><br>아래 문의 주셨던 것중에, HBA를 추가 증설하는 것에 대해서는 분명 성능향상에 영향이 주어질 것으로 보입니다. 다만, (a)의 경우 설정이 불가능 하고, (c)의 경우에는 저장하는 파일의 크기, 빈도수 등에 영향을 주기 때문에 이부분은 테스트를 하셔야 합니다. 또한 xfs는 기본적으로 RHEL6의 기본 파일시스템은 아니기 때문에 제한적인 기술지원에 이슈가 존재할 수는 있습니다.<br><br>그리고 (d)의 경우에는 현재도 기본 multipath가 round-robin방식으로 구성되어 있기 때문에 향후 channel을 늘리게 될경우 구성은 가능하나, 스토리지 벤더에서 이러한 I/O에 대해서 어떠한 concern이 있는지는 확인해 볼 필요가 있을 것 같습니다.<br><br>~~~<br> (a). Disk Block Size 8192 조정<br> - 이미 케이스가 오픈되어 불가하다는 답변을 받았습니다. (https://access.redhat.com/support/cases/#/case/01610765)<br><br> (b). HBA 추가 증설 후 14 Channel 을 이용하여 LUN 분산<br> - 과거 RockPlace 에서 테스트를 진행하였으나, 10~15% 가량의 성능향상이 있었다고 합니다.<br> - 하지만, 이렇게 변경하기 위해 100개의 파일시스템 구성을 다시 해야 합니다.<br><br> (c). XFS 등 다른 파일 시스템 구성<br> - 현재 EXT4 파일시스템을 변경하는 방안입니다.<br><br> (d). Multipath RoundRobin 방식 변경<br> - 여러개의 Channel 을 묶어 BandWidth 를 늘려 사용하는 방안입니다.<br> - 지원여부 확인 필요<br>~~~<br><br><br>1. Migration I/O 성능 저하 시간 대<br><br>I/O 성능 떨어진다는 시간대를 알려주시면 비슷한 전 후 구간을 분석해 보도록 하겠습니다.<br><br>날짜와 시간대 확인 부탁드립니다.<br><br>-&gt; I/O 성능 관련 시간대 입니다. 2016/5/30 09:00 ~ 23:00 해당 시간에 DB에서 인덱스 재구성 작업이 진행된 시간 입니다.<br><br>-&gt; 해당 시간대 I/O 성능을 검토해 볼 수 있는 도움이 될 만한 sar 옵션이나 sosreport 내 도움이 될 만한 데이터가 있으면 답변 부탁드립니다.<br>======================<br>===&gt; 특이사항은 없었으나, 일부 시간대에 I/O가 많이 발생하는 것이 확인되며, iowait가 존재하는 것으로 보아 스토리지에서 I/O 처리에 있어서 모니터링이 같이 필요할 것으로 보입니다.<br>======================<br><br><br><br>3. I/O 성능 저하 기준<br><br>AP 입장 에서의 I/O 성능 저하 기준(초당성능, 타 시스템과의 비교 등) 에 대해 확인 부탁 드립니다.<br><br>-&gt; DB쪽에서 성능 지연 관련 log 등이 있는지를 요청하였습니다.<br><br><br>====&gt; 일반적으로 Oracle DB의 경우, oracle에서 제공하는 성능 모니터링을 통해서 어느 부분에 병목현상이 잇는지를 확인하시는 것이 좋습니다. <br>======================<br><br><br>다만, 현재 sosreport를 일부만 살펴보았는데.. 현재 Oracle 시스템을 설정하는 가이드의 설정들이 적용되어 있지 않은 것으로 보입니다.<br><br>관련 문서(Best Practice)를 보내드리오니, 우선 문서를 참고하여 설정한 후에 application을 배제한 I/O 성능 테스트를 통해서 IO의 병목이 있는지? 성능이 최대한 나올 수 있는지 환경을 확인후에, Oralce 벤더를 통해서 튜닝 가이드를 받는 것이 필요해 보입니다.<br><br>https://www.redhat.com/en/resources/deploying-oracle-database-11g-r2-red-hat-enterprise-linux-6<br>======================<br>업무에 참고하여 주시기 바랍니다.<br><br>감사합니다.<br><br><publishedDate>2016-06-08T07:52:45Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HHjbrIAD"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-06-08T05:50:02Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-06-08T05:50:02Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>보내주신 sosreport를 다운로드 받아서 시스템 구성과 관련되어 확인중이며, 향후 업데이트 드리도록 하겠습니다.<br><br>그리고 현재 severity를 2로 설정하셧으나, Red Hat Severity 정책에 따라서 해당 케이스는 4으로 조절하도록 하겠습니다. severity가 조절되더라도 현재 케이스를 제가 관리하고 있습니다.<br>======================<br>확인 후, 업데이트 드리도록 하겠습니다.<br><br><br>감사합니다.<br><br><publishedDate>2016-06-08T05:50:02Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000HHjWDIA1"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-06-08T05:38:33Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-06-08T05:38:33Z</b><br><br>안녕하세요. 추가로 고객사측에 질문했던 내용 업데이트 드립니다.<br><br>1. Migration I/O 성능 저하 시간 대<br><br>I/O 성능 떨어진다는 시간대를 알려주시면 비슷한 전 후 구간을 분석해 보도록 하겠습니다.<br><br>날짜와 시간대 확인 부탁드립니다.<br><br>-&gt; I/O 성능 관련 시간대 입니다. 2016/5/30 09:00 ~ 23:00 해당 시간에 DB에서 인덱스 재구성 작업이 진행된 시간 입니다.<br><br>-&gt; 해당 시간대 I/O 성능을 검토해 볼 수 있는 도움이 될 만한 sar 옵션이나 sosreport 내 도움이 될 만한 데이터가 있으면 답변 부탁드립니다.<br><br>2. 스토리지 벤더의 예상 I/O 성능 값<br><br>스토리지 벤더의 예상 값과 OS 입장에서도 정상적인 볼륨에 R/W 값을 비교하고자 합니다.<br><br>-&gt; 현재 스토리지 엔지니어 통한 성능값 확인 중입니다.<br><br><br>3. I/O 성능 저하 기준<br><br>AP 입장 에서의 I/O 성능 저하 기준(초당성능, 타 시스템과의 비교 등) 에 대해 확인 부탁 드립니다.<br><br>-&gt; DB쪽에서 성능 지연 관련 log 등이 있는지를 요청하였습니다.<br><br><publishedDate>2016-06-08T05:38:33Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HHiNyIAL"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-06-08T02:05:01Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-06-08T02:05:01Z</b><br><br>안녕하세요. <br><br>dropbox.redhat.com 에 sosreport-PIDSEL01SL-20160602152934-b788.tar.xz 파일 업로드 하였습니다.<br><br>추가로 정보 수집을 하여 업데이트 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2016-06-08T02:05:01Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000HHiN5IAL"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-06-08T02:02:31Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-06-08T02:02:31Z</b><br><br>안녕하세요,<br>Red Hat Technical Account Manager 한진구 입니다.<br><br>문의주신 내용에 대해서 검토 후, 업데이트 드리겠습니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-06-08T02:02:31Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br><br>SDS 상암센터 김지민 선임입니다.<br><br>아래의 내용으로 서버에서 이슈로 인하여 문의를 드리려고 합니다.<br>시스템 용도는 oracle DB가 설치 되어 있는 DB 서버이고 마이그레이션의 용도입니다.<br><br>sosreport는 담당 컨설턴트 분인 심우택 차장님 통해서 전달하겠습니다.<br><br>========================================<br>BO-DS (HP DL980 Gen7) Migration 시스템 성능 이슈<br><br> - 운영계와 개발/품질계 Migration 을 위해 구성된 BO-DS 시스템이 있습니다.<br><br> - Hitachi Storage 에서 5TB Disk 20ea LUN 을 할당 받아, (Multipath 사용)<br><br> - 이를 다시 LVM VG 20ea 로 구성하고, 여기에서 1TB LV 를 100ea 로 나눠 총 Mount 볼륨 100ea 로 사용하는 시스템 입니다.<br><br> - HBA (Qlogic) Port 2개만을 연결하여 현재 사용하고 있는데요, 성능 이슈가 제기 된 상태입니다.<br><br> - 몇 가지 대안이 나왔는데, 아래와 같습니다.<br><br> (a). Disk Block Size 8192 조정<br> - 이미 케이스가 오픈되어 불가하다는 답변을 받았습니다. (https://access.redhat.com/support/cases/#/case/01610765)<br><br> (b). HBA 추가 증설 후 14 Channel 을 이용하여 LUN 분산<br> - 과거 RockPlace 에서 테스트를 진행하였으나, 10~15% 가량의 성능향상이 있었다고 합니다.<br> - 하지만, 이렇게 변경하기 위해 100개의 파일시스템 구성을 다시 해야 합니다.<br><br> (c). XFS 등 다른 파일 시스템 구성<br> - 현재 EXT4 파일시스템을 변경하는 방안입니다.<br><br> (d). Multipath RoundRobin 방식 변경<br> - 여러개의 Channel 을 묶어 BandWidth 를 늘려 사용하는 방안입니다.<br> - 지원여부 확인 필요<br>========================================</timeFramesAndUrgency><cep>false</cep></case>