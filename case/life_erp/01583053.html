======================<br><b>생성계정 : 우택 심</b><br><b>생성날짜 : 2016-02-13T14:48:54Z</b><br><b>마지막 답변자 : JINKOO HAN</b><br><b>마지막 수정 일자 : 2016-03-14T00:45:43Z</b><br><b>id : 500A000000TcFOUIA3</b><br>======================<br><br><b><font size=15>
제목  : vmware 환경 xfs I/O error 발생의 건
</font></b><br><br>======================<br><b>사전문의<br></b><br>어떤 문제/오류/결함이 발생했습니까? 기대하시는 결과는 무엇입니까?<br><br>안녕하세요.<br><br>이미 지난 주 xfs 관련 케이스를 https://access.redhat.com/support/cases/#/case/01578254 오픈 했었는데요,<br><br>문제가 발생했던 당일 Hitachi Storage GAD 테스트 후 vmware 환경의 VM 에서도 xfs I/O error 가 발생하면서 vm 이 Hang 상태로 되어 <br><br>vmcore 도 생성할 수 없고, 단지 O/S 만 작동되는 상태가 된 것을 확인하였습니다.<br><br>어디서 문제가 발생했습니까? 어떤 환경에서 발생했습니까?<br><br>Hitachi Storage GAD 테스트 당일 VMWare Hypervisor 의 multipath 정책을 Roundrobin 으로 변경하였으나, <br><br>이번 문제는 정책을 변경하기 전 발생했던 error 입니다.<br><br>vm console 상태를 캡춰한 이미지를 함께 첨부해서 올립니다.<br><br>vm 은 모두 Hitachi Storage GAD Active/Active Path 를 사용하는데, 화면의 에러 메세지로 보았을 때 path 가 Detach 된 것으로 추정하고 있으나,<br><br>정확한 에러 원인을 확인하고 싶습니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 3 (Normal)</b><br><enhancedSLA>false</enhancedSLA><contactIsPartner>false</contactIsPartner><tags/><br><br><comment id="a0aA000000Giw6RIAR"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-03-14T00:45:41Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-03-14T00:45:41Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>약 4주간 별다른 업데이트가 없어서 본 케이스는 Close하도록 하겠습니다.<br><br>본 케이스와 관련되어 추가 문의사항이 있으시면 케이스를 &quot;Re-Open&quot;하시거나 또는 새로운 문의사항에 대해서 새로운 케이스를 오픈하시면 해당 케이스를 통해서 지원하도록 하겠습니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-03-14T00:45:41Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GazBRIAZ"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-02-29T02:04:34Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-02-29T02:04:34Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>보내주신 메시지에 대해서 확인한 결과, 해당 케이스는 Stroage와의 연결부분에서 모든 패스가 끊어졌던 것으로 유추됩니다.<br><br>Storage switch나 Stroage Controller 또는 link에 대해서 하드웨어 벤더와 당시에 패스가 살아있었는지를 확인하여 주시기 바랍니다.<br><br><br>아래 관련된 문서를 참고하여 주시기 바랍니다.<br><br>https://access.redhat.com/solutions/62032<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-02-29T02:04:34Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GasanIAB"><br>======================<br><b>생성계정 : 심, 우택</b><br><b>생성날짜 : 2016-02-27T14:35:53Z</b><br><b>마지막 답변자 : 심, 우택</b><br><b>마지막 수정 일자 : 2016-02-27T14:35:53Z</b><br><br>안녕하세요.<br><br>오늘 Hitachi Storage GAD 가용성 테스트 후 VMWare 환경에서 아래와 같은 비슷한 장애가 다시 발생 하였습니다.<br><br>Feb 27 15:25:28 PCRMAL04SL kernel: sd 0:0:3:0: [sdd] FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>Feb 27 15:25:28 PCRMAL04SL kernel: sd 0:0:3:0: [sdd] Sense Key : Illegal Request [current]<br>Feb 27 15:25:28 PCRMAL04SL kernel: sd 0:0:3:0: [sdd] Add. Sense: Logical unit not supported<br>Feb 27 15:25:28 PCRMAL04SL kernel: sd 0:0:3:0: [sdd] CDB: Write(10) 2a 00 00 a1 a8 70 00 00 08 00<br>Feb 27 15:25:28 PCRMAL04SL kernel: blk_update_request: I/O error, dev sdd, sector 10594416<br>Feb 27 15:25:28 PCRMAL04SL kernel: Buffer I/O error on device dm-2, logical block 1323790<br>Feb 27 15:25:28 PCRMAL04SL kernel: lost page write due to I/O error on dm-2<br>Feb 27 15:25:28 PCRMAL04SL kernel: sd 0:0:3:0: [sdd] FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>Feb 27 15:25:28 PCRMAL04SL kernel: sd 0:0:3:0: [sdd] Sense Key : Illegal Request [current]<br>Feb 27 15:25:28 PCRMAL04SL kernel: sd 0:0:3:0: [sdd] Add. Sense: Logical unit not supported<br>Feb 27 15:25:28 PCRMAL04SL kernel: sd 0:0:3:0: [sdd] CDB: Write(10) 2a 00 10 5b 46 d0 00 00 08 00<br>Feb 27 15:25:28 PCRMAL04SL kernel: blk_update_request: I/O error, dev sdd, sector 274417360<br>Feb 27 15:25:28 PCRMAL04SL kernel: Buffer I/O error on device dm-5, logical block 31680218<br>Feb 27 15:25:28 PCRMAL04SL kernel: lost page write due to I/O error on dm-5<br><br>Feb 27 15:25:28 PCRMAL02SL kernel: sd 0:0:0:0: [sda] FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>Feb 27 15:25:28 PCRMAL02SL kernel: sd 0:0:0:0: [sda] Sense Key : Illegal Request [current]<br>Feb 27 15:25:28 PCRMAL02SL kernel: sd 0:0:0:0: [sda] Add. Sense: Logical unit not supported<br>Feb 27 15:25:28 PCRMAL02SL kernel: sd 0:0:0:0: [sda] CDB: Write(10) 2a 00 03 15 d1 a0 00 00 08 00<br>Feb 27 15:25:28 PCRMAL02SL kernel: blk_update_request: I/O error, dev sda, sector 51761568<br>Feb 27 15:25:28 PCRMAL02SL kernel: Buffer I/O error on device sda2, logical block 6207796<br>Feb 27 15:25:28 PCRMAL02SL kernel: lost page write due to I/O error on sda2<br>Feb 27 15:25:28 PCRMAL02SL kernel: sd 0:0:0:0: [sda] FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>Feb 27 15:25:28 PCRMAL02SL kernel: sd 0:0:0:0: [sda] Sense Key : Illegal Request [current]<br>Feb 27 15:25:28 PCRMAL02SL kernel: sd 0:0:0:0: [sda] Add. Sense: Logical unit not supported<br>Feb 27 15:25:28 PCRMAL02SL kernel: sd 0:0:0:0: [sda] CDB: Write(10) 2a 00 03 15 d1 80 00 00 18 00<br>Feb 27 15:25:28 PCRMAL02SL kernel: blk_update_request: I/O error, dev sda, sector 51761536<br>Feb 27 15:25:28 PCRMAL02SL kernel: Buffer I/O error on device sda2, logical block 6207792<br>Feb 27 15:25:28 PCRMAL02SL kernel: lost page write due to I/O error on sda2<br>Feb 27 15:25:28 PCRMAL02SL kernel: Buffer I/O error on device sda2, logical block 6207793<br>Feb 27 15:25:28 PCRMAL02SL kernel: lost page write due to I/O error on sda2<br>Feb 27 15:25:28 PCRMAL02SL kernel: Buffer I/O error on device sda2, logical block 6207794<br>Feb 27 15:25:28 PCRMAL02SL kernel: lost page write due to I/O error on sda2<br><br>추측하기로는 GAD 원장/이중화 스토리지 중 하나에 장애가 발생하여, Path 가 단절 될 때 가상 머신에서는 SCSI 통신에 문제가 생겨 <br><br>Lun 이 offline 되었다가 다시 붙는 과정에서 이미 mount 되었던 filesystem 에 문제가 생기는 것으로 보고 있습니다.<br><br>그렇다면 vmware 환경에서도 기존 multipath 와 같이 Fail/Faulty 된 path 에 대해 일정시간 대기 하여 I/O 가 offline 이 되는 것을 막는 방법이 있는지 궁금합니다.<br><br>이번 이슈는 VMWare 쪽에서도 동시에 Case 를 진행하고 있습니다.<br><br>저희 내부적으로도 비슷한 유형의 장애 보고가 있었는지 확인 부탁 드립니다.<br><br>감사합니다.<br><br><publishedDate>2016-02-27T14:35:53Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000GXbFSIA1"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-02-15T01:55:18Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-02-15T01:55:18Z</b><br><br>안녕하세요,<br>Red Hat 한진구 입니다.<br><br>보내주신 로그 데이터를 확인해 보면,<br><br>&quot;2.png&quot; 파일에 내용에<br><br>blk_update_request: I/O error, dev sda, sector ...<br>XFS (sda2): metadata IO error, ....<br>XFS (sda2): Log I/O Error Detected. Shutting down filesystem<br>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^<br><br>테스트를 진행하는 과정에서 sda block device에 장애가 발생하여 filesystem이 내려갔던 것으로 확인됩니다.<br>그리고 그로 인하여 xfs I/O error 가 발생하였고 VM이 hang이 되는 상태가 된 것으로 추정됩니다.<br>======================<br>감사합니다.<br><br><publishedDate>2016-02-15T01:55:18Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000GXbCnIAL"><br>======================<br><b>생성계정 : HAN, JINKOO</b><br><b>생성날짜 : 2016-02-15T01:47:58Z</b><br><b>마지막 답변자 : HAN, JINKOO</b><br><b>마지막 수정 일자 : 2016-02-15T01:47:58Z</b><br><br>안녕하세요,<br>Red Hat Technical Account Manager 한진구 입니다.<br><br>문의주신 내용과 보내주신 데이터를 우선 확인 후, 업데이트 드리겠습니다.<br>======================<br><br>감사합니다.<br><br><publishedDate>2016-02-15T01:47:58Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br><br>이미 지난 주 xfs 관련 케이스를 https://access.redhat.com/support/cases/#/case/01578254 오픈 했었는데요,<br><br>문제가 발생했던 당일 Hitachi Storage GAD 테스트 후 vmware 환경의 VM 에서도 xfs I/O error 가 발생하면서 vm 이 Hang 상태로 되어 <br><br>vmcore 도 생성할 수 없고, 단지 O/S 만 작동되는 상태가 된 것을 확인하였습니다.</issue><environment>Hitachi Storage GAD 테스트 당일 VMWare Hypervisor 의 multipath 정책을 Roundrobin 으로 변경하였으나, <br><br>이번 문제는 정책을 변경하기 전 발생했던 error 입니다.<br><br>vm console 상태를 캡춰한 이미지를 함께 첨부해서 올립니다.<br><br>vm 은 모두 Hitachi Storage GAD Active/Active Path 를 사용하는데, 화면의 에러 메세지로 보았을 때 path 가 Detach 된 것으로 추정하고 있으나,<br><br>정확한 에러 원인을 확인하고 싶습니다.</environment><cep>false</cep></case>