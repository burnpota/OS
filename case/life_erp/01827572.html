======================<br><b>생성계정 : 타임 게이트</b><br><b>생성날짜 : 2017-04-10T04:33:25Z</b><br><b>마지막 답변자 : GSS Tools</b><br><b>마지막 수정 일자 : 2017-05-10T10:02:25Z</b><br><b>id : 500A000000Wm94UIAR</b><br>======================<br><br><b><font size=15>
제목  : 패스 4개중 2개 끊겼을시  lv 리소스를 인식하지 못하고 fail over 되는 증상
</font></b><br><br>======================<br><b>사전문의<br></b><br>안녕하세요?<br>삼성생명 가용성 테스트 하는 중입니다.<br>이중화 되어 있는 SAN 한쪽으로 끊어서 정상적인지 테스트 하던 중 lv 리소스가 넘어갔습니다.<br>이에 어떤 이유에 의해서 이런 증상이 발생되는지....<br>지금 현 구성에 문제점은 없는지 궁금합니다.<br><br>현재 구성은 halvm 으로 구성되어 있읍니다.<br><br>기존 구성에서 LV_APP_con_ctmag901 LV_APP_con_ctmag902 <br>이 두 리소스를 얼마전에 추가 했었으며<br>메뉴얼하게 리소스 넘기는 것에는 문제가 없었습니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>타입  : Other</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 3 (Normal)</b><br>======================<br><comment id="a0aA000000JKSIhIAP"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-25T07:34:35Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-25T07:34:35Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해주셔서 감사합니다.<br><br>케이스 진행 전 타임게이트 계정의 현재 케이스에대한<br>담당자 성함 및 연락처를 남겨주시기 바랍니다.<br>원할한 진행을 위해 컨텍 확인이 필요합니다.<br><br>또한, <br><br>&gt; 이렇게 보면  모니터링이 실패하게 되면 자동으로 fencing 되는게 맞는건지 아니면   stop 되는게 맞는건지 모르겠습니다.<br>&gt; 유추해 보면 <br>&gt; fencie device 가 모니터링에 실패하게 되면 stop/start 를 migration-thread-hold 값(3) 횟수만큼 진행합니다.<br>&gt; 만약 1회라도 실패하고 2회째 성공하게 되면 ipmilan_fence stionith 상태는 stopped 상태로 변경된다.<br>&gt; 2 회째 3회째 도 recover 가 되지 않으면 결국  상대노드에서 fecing 를 한다 <br><br>&quot;만약 1회라도에서 실패&quot;한다는건, 모니터링인가요, 리소스 restart 인가요?<br>정확한 파악을 위해 확인 부탁드립니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-25T07:34:35Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JKQqxIAH"><br>======================<br><b>생성계정 : 타임게이트, 삼성생명</b><br><b>생성날짜 : 2017-04-25T05:47:07Z</b><br><b>마지막 답변자 : 타임게이트, 삼성생명</b><br><b>마지막 수정 일자 : 2017-04-25T05:47:07Z</b><br><br>답변 감사합니다.<br>저희가 가상화 뿐 아니라 물리 장비에서도 동일한 구성으로 클러스터를 구축되어 있습니다.<br>ipmi_fence 로 feceing device 를 구성했는데 가끔 상대노드로  ipmi_fence  통신이 간헐적으로  연결이 가끔 안될때가 있습니다.<br>이럴때 ipmi_fecne 상태가 stopped  로 변경되는데 <br><br>예전에 레드햇으로 아래와 같은 답변을 받은적이 있습니다.<br>======================<br>https://access.redhat.com/support/cases/#/case/01774911<br>=================================================================================<br><br>Red Hat Global Support Services를 이용해주셔서 감사합니다.<br><br>stonith ipmilan 설정이 된 아이피 모니터링이 실패가 되면 자동으로 stonith 상태가 stop 으로 변경하게 되나요?<br><br>==&gt; 네, 모니터링이 실패되면 관련 리소스를 스톱 하였다가 다시 기동하게 되며 만일<br>기동시 실패되면 해당 리소스를 stopped로 변경하게 됩니다.<br><br>stop 이 되면 ip 통신이 가능하게 되면 started 상태로 변경이 되는지요?<br><br>==&gt; 스톱된 리소스는 자동으로 start 되지 않으며 수동으로 기동해 주셔야 됩니다.<br><br>실제 ipmilan  명령어로  로그인 테스트를 하게 되면 간혹 불규칙적으로 실패가 나올때가 있어서 문의 드립니다.<br><br>==&gt; fence_ipmilan 명령어가 불규칙적으로 실패되는 원인을 분석해볼 필요가 있을것으로 보입니다.<br><br>감사합니다.<br><br>===================================================================================<br><br>이렇게 보면  모니터링이 실패하게 되면 자동으로 fencing 되는게 맞는건지 아니면   stop 되는게 맞는건지 모르겠습니다.<br>유추해 보면 <br>fencie device 가 모니터링에 실패하게 되면 stop/start 를 migration-thread-hold 값(3) 횟수만큼 진행합니다.<br>만약 1회라도 실패하고 2회째 성공하게 되면 ipmilan_fence stionith 상태는 stopped 상태로 변경된다.<br>2 회째 3회째 도 recover 가 되지 않으면 결국  상대노드에서 fecing 를 한다 <br><br>이렇게 생각해야 되는지요?<br><br><publishedDate>2017-04-25T05:47:07Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JKAcdIAH"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-24T05:21:20Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-24T05:21:19Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해주셔서 감사합니다.<br><br>해당 예는 테스트를 위한 예제입니다.<br><br>Ondrej 의 설명을 덧붙이면,<br>~~~<br>주어진 예제는 더미 리소스 에이전트가 start 나 stop 오퍼레이션이 아닌 '모니터링' 액션이 되어질 때,<br>타임아웃되도록 수정되어져 있습니다.<br>여기서 모니터링 오퍼레이션은 타임아웃 동작을 의도적으로 보여줄 것입니다.<br><br>또한, start 나 stop 액션들이 내부 모니터링 체크를 수행할 때 실패하지 않도록 수정되었습니다.<br><br>타임아웃은 어떤 오퍼레이션 중에도 발생할 수 있습니다.<br>~~~<br><br>결과적으로 테스트를 위해 start 나 stop 오퍼레이션시에 실패하기보다는 모니터링 오퍼레이션 중 실패되도록 작성된<br>더미 리소스 에이전트가 작성되었다는 답변을 연계 받았습니다.<br><br>감사합니다.<br><br>Jae Wook Shin &amp; Ondrej Famera<br><br><publishedDate>2017-04-24T05:21:19Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JK4CgIAL"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-22T09:11:05Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-22T09:11:04Z</b><br><br>본의 아니게 신과장님께 overtime을 선사드린것에 대하여 죄송하고 감사할 따름이네요...<br>답변 잘 보았습니다. 그런데 궁금한게 있어서 살짝 다시 문의 드릴게요...<br><br>- 저희 테스트 환경에서 테스트 한 결과 다음과 같은 시간이 걸릴 것으로 예상됩니다.(리소스 재시작 값이 짧다고 봤을 때)<br>  1*(monitor interval)+3*(monitor timeout)= 95s<br><br>&gt;&gt;&gt; <br>이렇게 말씀 주셨는데요 제가 좀 시간만 계산하다보니 놓친게 있어서 문의 드립니다.<br>         질문) <br>             모니터링이란것이 모니터링하는것에 대한 체크인지 리소스를 체크하는것인지? 궁금하네요...<br>             아래 로그에서 보듯이 모니터링은 timeout되었으나 리소스는 정상적으로 리스타트 되었고 <br>             하지만 다시 모니터링이 실패(어떤이유인지?)되어 리소스를 재시작합니다.  리소스는 정상적으로 리턴을 받았는데 말이죠<br>             모니터링 fail이 나오는 이유는 무엇인가요?   <br><br>답변 부탁드릴게요... 감사합니다.<br><br><publishedDate>2017-04-22T09:11:04Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJyYIIA1"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-21T11:59:56Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-21T11:59:56Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용해주셔서 감사합니다.<br><br>현재 말씀드리는 것은 가장 최악의 경우의 시나리오를 상정해서 말씀드리는 것입니다.<br><br>&gt; resource on-fail 시 fence(failover) 되는 시간 3A+B=45<br>&gt; 총 failover(resource stop)되는데 걸리는 시간은 45초가 되는지 궁금하고 어떤 메시지를 출력하는지 문의드립니다.<br><br>저희 테스트 환경에서 테스트 한 결과 다음과 같은 시간이 걸릴 것으로 예상됩니다.(리소스 재시작 값이 짧다고 봤을 때)<br><br>  1*(monitor interval)+3*(monitor timeout)= 95s<br><br>리소스 네임이 'test' 의 /var/log/messages 상의 출력 예를 들면 다음과 같습니다.('monitor interval=5s timeout=30s')<br><br># 리소스 시작<br>  Apr 21 07:43:18 fastvm-c7-3-53 crmd[2090]:  notice: Result of start operation for test on fastvm-c7-3-53: 0 (ok)<br><br># 첫번째 모니터 타임아웃 : 이때 클러스터는 즉시 30초 후에 타임아웃 할수 있는 모니터링 오퍼레이션을 실행합니다.<br># 1st monitor timeout: Cluster immediately executes monitoring operation which times out after 30 s<br>  Apr 21 07:43:48 fastvm-c7-3-53 lrmd[2087]: warning: test_monitor_5000 process (PID 2329) timed out<br>  Apr 21 07:43:48 fastvm-c7-3-53 lrmd[2087]: warning: test_monitor_5000:2329 - timed out after 30000ms<br>  Apr 21 07:43:48 fastvm-c7-3-53 crmd[2090]:   error: Result of monitor operation for test on fastvm-c7-3-53: Timed Out<br><br># 리소스 재시작<br>  Apr 21 07:43:48 fastvm-c7-3-53 crmd[2090]:  notice: Result of stop operation for test on fastvm-c7-3-53: 0 (ok)<br>  Apr 21 07:43:48 fastvm-c7-3-53 crmd[2090]:  notice: Result of start operation for test on fastvm-c7-3-53: 0 (ok)<br><br># 두번째 모니터 타임아웃 : 이때 클러스터는 즉시 30초 후에 타임아웃 할수 있는 모니터링 오퍼레이션을 실행합니다.<br>  Apr 21 07:44:18 fastvm-c7-3-53 lrmd[2087]: warning: test_monitor_5000 process (PID 2350) timed out<br>  Apr 21 07:44:18 fastvm-c7-3-53 lrmd[2087]: warning: test_monitor_5000:2350 - timed out after 30000ms<br>  Apr 21 07:44:18 fastvm-c7-3-53 crmd[2090]:   error: Result of monitor operation for test on fastvm-c7-3-53: Timed Out<br><br># 리소스 재시작<br>  Apr 21 07:44:19 fastvm-c7-3-53 crmd[2090]:  notice: Result of stop operation for test on fastvm-c7-3-53: 0 (ok)<br>  Apr 21 07:44:19 fastvm-c7-3-53 crmd[2090]:  notice: Result of start operation for test on fastvm-c7-3-53: 0 (ok)<br><br># 세번째 모니터 타임아웃<br>  Apr 21 07:44:49 fastvm-c7-3-53 lrmd[2087]: warning: test_monitor_5000 process (PID 2385) timed out<br>  Apr 21 07:44:49 fastvm-c7-3-53 lrmd[2087]: warning: test_monitor_5000:2385 - timed out after 30000ms<br>  Apr 21 07:44:49 fastvm-c7-3-53 crmd[2090]:   error: Result of monitor operation for test on fastvm-c7-3-53: Timed Out<br><br># 3 타임아웃(migration-threshold=3) 후에 클러스터는 리소스를 다른 노드로 재배치 할 것을 결정합니다. 그래서 해당 노드에서는 오로지 스탑이 발생합니다.<br>  Apr 21 07:44:49 fastvm-c7-3-53 crmd[2090]:  notice: Result of stop operation for test on fastvm-c7-3-53: 0 (ok)<br><br>## 지금 리소스는 다른 노드로 재배치되었습니다.<br><br>만약 또다른 노드에서 또한 리스타트가 3번 실패하면 리소스는 정지한 상태가 될 것입니다.<br><br>&gt; 이후, 리소스 타임아웃 60초 진행되고 kdump 진입 타임아웃(120초) 이후 fence_ipmilan 진입되는 것이 맞는지요?<br><br>리소스가 'failed to stop' (not just timed out)가 된다면 클러스터는 펜싱 프로시져를 실행할 것입니다.:<br>'up to 120s waiting for fence_kdump'+'delay of fence_ipmilan for the fenced node'+'fence_ipmilan time to fence the other node (up to 60s - stonith timeout)'<br><br>&gt; ---&gt; 그림에서 설명 다시 주시겠지만 다른 노드로 재배치 하기전에 현재 노드에서 2번의 RESTART 3번째 타임아웃시<br>&gt;        다른노드로 마이그래이션으로 알면되겠지요? <br><br>예, 맞습니다. 앞서 안내드린 내용이 참고가 되실 것입니다.<br><br>&gt; ---&gt;  ipmilan_stonith1도 리소스로 봐야 하는지요?<br>&gt;      그리고 이것이 hang이나 ILO장애가 생긴다면 STOP AND START를 시켜야 하는데 각 타임아웃값은 디폴트로 얼마인지 궁금합니다.<br>&gt;      OP 내용에 STOP 과 START 내용이 없어서 문의 드려요..<br>&gt; Resource: ipmilan_stonith1 (class=stonith type=fence_ipmilan)<br>&gt;  Attributes: pcmk_host_list=PCTAAL01SL-HB ipaddr=172.18.24.103 login=Redhat passwd=nl!con00 lanplus=on auth=password delay=15 action=reboot   <br>&gt;  Operations: monitor interval=60s (ipmilan_stonith1-monitor-interval-60s)<br><br><br>STONITH 디바이스 또한 리소스입니다만 디폴트는 다른 일반적인 리소스와는 약간의 차이가 있습니다.<br>다음 링크의 테이블에는 옵션과 디폴트 들이 설명되어 있습니다.<br><br> ⁠ 5.9. Additional Fencing Configuration Options - Table 5.2. Advanced Properties of Fencing Devices<br>  https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/High_Availability_Add-On_Reference/s1-fencedevicesadditional-HAAR.html<br><br>STONITH 디바이스의 'monitor', 'reboot', 'status'  의 경우 디폴트는 60초입니다.<br>STONITH 디바이스들을 정지하기 전에 실패했을 때 2번 리트라이하게 됩니다.<br><br>이상 업무에 도움이 되시기 바랍니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-21T11:59:56Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JJumiIAD"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-21T05:24:27Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-21T05:24:27Z</b><br><br>&gt; 그러면 migration-threshod 값은 on-fail=restart일때 적용되는 옵션인지요?<br><br>예, 클러스터는 리소스를 또 다른 노드로 재배치 할려고 하기전에 정의된 migration-threshold 만큼의 사간동안 클러스터<br>리소스를 재시작할것입니다.<br><br>---&gt; 그림에서 설명 다시 주시겠지만 다른 노드로 재배치 하기전에 현재 노드에서 2번의 RESTART 3번째 타임아웃시<br>        다른노드로 마이그래이션으로 알면되겠지요? <br><br><br>펜싱은 오직 리소스가 &quot;failed to stop&quot; 한 경우에만 일어납니다.<br>'Redstart' action 은 'resource stop' 과 'resource start' 로 구성됩니다.<br>즉, 'resource stop' 이 실패했을 때만 펜싱이 일어날 것입니다.<br><br>---&gt;  ipmilan_stonith1도 리소스로 봐야 하는지요?<br>      그리고 이것이 hang이나 ILO장애가 생긴다면 STOP AND START를 시켜야 하는데 각 타임아웃값은 디폴트로 얼마인지 궁금합니다.<br>      OP 내용에 STOP 과 START 내용이 없어서 문의 드려요..<br> Resource: ipmilan_stonith1 (class=stonith type=fence_ipmilan)<br>  Attributes: pcmk_host_list=PCTAAL01SL-HB ipaddr=172.18.24.103 login=Redhat passwd=nl!con00 lanplus=on auth=password delay=15 action=reboot   <br>  Operations: monitor interval=60s (ipmilan_stonith1-monitor-interval-60s)<br><br><publishedDate>2017-04-21T05:24:27Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJtGWIA1"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-21T01:24:09Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-21T01:24:41Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>일단 처음 문의하신 내용에 대해서 먼저 답변을 드리면 다음과 같습니다.<br><br>&gt; 그러면 migration-threshod 값은 on-fail=restart일때 적용되는 옵션인지요?<br><br>예, 클러스터는 리소스를 또 다른 노드로 재배치 할려고 하기전에 정의된 migration-threshold 만큼의 사간동안 클러스터<br>리소스를 재시작할것입니다.<br><br>&gt; 그리고 resource-stickness: 100이 의미하는 무엇인지 궁금해서 문의 드려봅니다.<br><br>클러스터는 리소스에 대해 리소스를 어떤 노드로 배치해야할 지 결정하기 위해 스코어를 사용하고 있습니다.<br>Resource-stickiness: 100 는 리소스가 지금 돌고 있는 노드상에서 +100 얻을 것을 정의합니다.<br>이는 노드가 온라인으로 회복된 후에 또다른 노드로부터 페일오버된 노드상에서 클러스터를 유지시킬려고 할 때 유용할 수 있습니다.<br><br>펜싱은 오직 리소스가 &quot;failed to stop&quot; 한 경우에만 일어납니다.<br>'Redstart' action 은 'resource stop' 과 'resource start' 로 구성됩니다.<br>즉, 'resource stop' 이 실패했을 때만 펜싱이 일어날 것입니다.<br><br>그림부분은 추가로 업데이트 드리도록 하겠습니다.<br><br>감사합니다.<br><br>Jae Wook Shin &amp; Ondrej Famera<br><br><publishedDate>2017-04-21T01:24:09Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JJeAcIAL"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-20T05:38:20Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-20T05:38:20Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>음, 죄송한데 보다 확실하게 하기 위해서 간단하게 그림으로 그리셔서<br>사진으로 올려주시겠어요?<br><br>확인 바랍니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-20T05:38:20Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JJe11IAD"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-20T05:19:51Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-20T05:19:51Z</b><br><br>그림이 깨졌네요.... ^ 는 윈라인 |(pipe)를 가리킵니다.<br><br>그리고 fence 되기까지의 총 시간은 45초로 보이는데 이 메커니즘이 맞는지 궁금합니다.<br><br><publishedDate>2017-04-20T05:19:51Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJdxMIAT"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-20T05:15:11Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-20T05:15:11Z</b><br><br>안녕하십니까?<br>migration treshold 3에 관련 한 메카니즘에 대한 질문을 드리겠습니다.<br>만약에 리소스에 문제가 생겼을시<br><br>모니터인터벌                   타임아웃                                                                                  migration treshold<br>|--------------|-------------------------------------|                                                                   1번<br>           5 s       ^(fail)              30s                              ^(restart)<br>                       |--------------|----------------------------------|                                                 2번<br>                                  5s         ^(fail)           30s                            ^(restart)<br>                                               |------------|----------------------------------|                            3번<br>                                                        5s       ^(fail)             30s                         ^(fence)<br>  <br>이런 상태로 작동하는지 궁금합니다. 감사합니다.<br><br><publishedDate>2017-04-20T05:15:11Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJdcOIAT"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-20T05:00:59Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-20T05:00:59Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>유선상으로 말씀드린바와같이 클러스터 인타이틀먼트가 확인되었으므로<br>해당 케이스에서 이어서 기술지원을 진행하도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-20T05:00:59Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JJOzlIAH"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-19T07:23:10Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-19T07:23:09Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>조치 감사드립니다.<br>제가 새로 올려주신 케이스를 가져왔으니<br>새롭게 올려주신 케이스에서 이어서 안내드리도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-19T07:23:09Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JJOTaIAP"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-19T06:34:08Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-19T06:34:08Z</b><br><br>제가 1648604계정으로 재 질문 드리겠습니다. 감사합니다.<br><br><publishedDate>2017-04-19T06:34:08Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJODlIAP"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-19T06:10:35Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-19T06:10:35Z</b><br><br>계정 맵핑하여 진행 부탁드립니다.<br><br>삼성생명 High-Availability 에 대한 계약/계정번호 보내드립니다.<br>(프로젝트 : S-ERP)<br>제품            수량      서비스 시작일    서비스 종료일   계정번호    계약번호   <br>RH00025F3       4       2016-01-01    2018-12-31  1648604   10833664<br> 감사합니다.<br><br><publishedDate>2017-04-19T06:10:35Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJOBkIAP"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-19T06:07:44Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-19T06:07:44Z</b><br><br>확인 부탁드립니다.<br><br>삼성생명 High-Availability 에 대한 계약/계정번호 보내드립니다.<br>(프로젝트 : S-ERP)<br>제품            수량      서비스 시작일    서비스 종료일   계정번호    계약번호   <br>RH00025F3       4       2016-01-01    2018-12-31  1648604   10833664<br> 감사합니다.<br><br><publishedDate>2017-04-19T06:07:44Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJNhqIAH"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-19T05:15:43Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-19T05:15:43Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>제가 내부적으로 확인해본 결과, 일단 현재 서브스크립션 관계가 정리중이신 것으로 확인됩니다.<br>다만, 저희 내부 절차상 해당 정리가 완료된 후부터 지원 가능할 것 같습니다.<br>죄송하지만 정리가 완료된 후부터 바로 이어서 신속하게 기술지원을 진행하도록 하겠습니다.<br>아무쪼록 양해부탁드립니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-19T05:15:43Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JJ8WEIA1"><br>======================<br><b>생성계정 : 타임게이트, 삼성생명</b><br><b>생성날짜 : 2017-04-18T08:19:24Z</b><br><b>마지막 답변자 : 타임게이트, 삼성생명</b><br><b>마지막 수정 일자 : 2017-04-18T08:19:24Z</b><br><br>답변 감사합니다.<br>그러면 migration-threshod 값은 on-fail=restart일때 적용되는 옵션인지요?<br>그리고 resource-stickness: 100이 의미하는 무엇인지 궁금해서 문의 드려봅니다.<br><br><publishedDate>2017-04-18T08:19:24Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JJ81KIAT"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-18T07:29:35Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-18T07:29:35Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>문의하신 건에 대하여 저희 클러스터 전문 그룹으로 연계 받은 내용에 대하여 남겨드립니다. <br><br>각 operation (start,stop,monitor) 은 각자 자신의 on-fail response 을 갖습니다. <br>만약 저희가 다음 설정 예와 같은 monitor openration 만 고려한다면<br>각 단계에서 failure 가 발생한 것으로 간주하여 말씀드리겠습니다.(모든 현상이 failure timeout 내에 발생했다는 것을 가정):<br><br>First Failure: LV_APP_con_ctmag902 가 원래 노드에서 재시작될 것입니다. (on-fail action restart)<br><br>Second Failure: LV_APP_con_ctmag902 가 원래 노드에서 재시작될 것입니다. (on-fail action restart)<br><br>Third Failure: LV_APP_con_ctmag902 가 Migration Threshold 때문에 또 다른 클러스터 노드로 페일오버가 시도될 것입니다.<br><br>에러가 클린 업 될 때까지 실패한 노드 상에서 실행될 수 없을 것입니다.(pcs resource cleanup 을 수동으로 실행하거나 설정된 failure timeout 을 초과한 후까지)<br><br>노드가 원래 위치에서 다시 시작할 때나 마이그레이션을 중지 할 때만 펜스할 것입니다.<br>&quot;STOP&quot; operation 은 디폴트로 &quot;Fence&quot; on-fail action 을 가지고 있습니다.<br><br>이상 업무에 도움이 되시기 바랍니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-18T07:29:35Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JIwoyIAD"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-17T11:57:16Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-17T11:57:16Z</b><br><br>답변 감사합니다.<br>현재 생명쪽 리소스는 migration-thredhold 값이 3입니다.<br>그러면 on-fail=restart로 설정시 리소스를 넘기지 않고 재시작을 3번 시도 후 fence를 진행하는것인지요?<br><br> 결과적으로 <br><br> monitor interval=5s timeout=30 on-fail=restart OCF_CHECK_LEVEL=10 (LV_APP_con_ctmag902-monitor-interval-5s)<br><br>위와 같은 상황에서 30초 타임아웃후 리소스 재시작을 3번 시도 하고(총 90초)  리소스가 넘어가지 않았을때  fence를 시키는것인지 문의 드립니다.<br><br>아니라면 시간별로 설명 부탁드리겠습니다. <br><br>감사합니다.<br><br><publishedDate>2017-04-17T11:57:16Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JIuEtIAL"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-17T05:24:57Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-17T05:24:57Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>문의하신 내용에 대하여 답변을 드리면 다음과 같습니다.<br><br>테스트1에서 멀티패스 장애가 클러스터 자원 모니터링에 영향을 미치지 않는 것으로 보이며,<br>클러스터에서 조치를 취할 필요가 없으므로 정상적인 상태로 생각됩니다.<br><br>테스트2 또한 예상대로 동작하는 것으로 보입니다. 문제가 발생했다면 이전과 같이 노드 펜싱 그리고, unclean 한 노드를 보았을 것입니다.<br>클러스터가 timeout=30s 그리고 on-fail=restart 인 경우에 정상적으로 동작하기 때문에 우리는 어떤 것이 여기에서 도움이 되었는지<br>알수가 없을 수도 있습니다. 예측할 수 있는 것은 더 많은 시간을 할당한 것이 모니터링이 정상적으로 끝나도록 하거나 &quot;on-fail=restart&quot; 가 리소스를<br>재시작하고 그것이 성공할 수 있는 시간을 허용했다는 것입니다.<br>이에 대해서는 로그로부터 확인할 수 있습니다.<br><br>== 'on-fail=restart mechanism' 에 대해서:<br><br>다음 링크의 Table 6.4 는 리소스가 실패했을 때 일어날 수 있는 처리를 설명하고 있습니다.<br>'restart' 는 'monitor' 오퍼레이션의 디폴트입니다.<br><br>  6.6. Resource Operations - Table 6.4. Properties of an Operation<br>  https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/High_Availability_Add-On_Reference/s1-resourceoperate-HAAR.html#tb-resource-operation-HAAR<br><br>  ...<br>  on-fail - The action to take if this action ever fails.<br>  ...<br>  restart - Stop the resource and start it again (possibly on a different node)<br>  fence - STONITH the node on which the resource failed <br>  ...<br>  The default for the 'stop' operation is 'fence' when STONITH is enabled and 'block' otherwise. All other operations default to 'restart'<br>  ...<br><br>오퍼레이션이 실패했을 때 일어날 수 있는 몇가지 것들에 대해서 다음 문서에서 자세히 설명하고 있습니다.<br><br>  8.2. Moving Resources Due to Failure<br>  https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/High_Availability_Add-On_Reference/s1-failure_migration-HAAR.html<br><br>디폴트 설정에서 만약 리소스가 한 노드에서 실패하면 다른 노드에서 재시작됩니다.<br>(때문에 디폴트 migration-threshold 가 INFINITY 입니다)<br><br>  6.4. Resource Meta Options - Table 6.3. Resource Meta Options<br>  https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/High_Availability_Add-On_Reference/s1-resourceopts-HAAR.html#tb-resource-options-HAAR<br><br>  ...<br>  migration-threshold - INFINITY (disabled)<br>  ...<br>  How many failures may occur for this resource on a node, before this node <br>  is marked ineligible to host this resource. <br>  ...<br><br>'migration-threshold' 메타 옵션은 다음 아티클에서 설명된 것과 같이 보다 나은 동작을 구성하는데 도움이 될 수 있습니다.<br>(예로부터 'Resolution' 부분을 확인하여 주십시요.)<br>다음 링크는 또한 리소스를 다른 노드로 마이그레이트 하기 전에 한 노드에서 몇번 리소스를 재시작하게 할지에 대한 방법을<br>서술하고 있습니다.<br><br>  After detecting a resource failure, pacemaker restarts the resource on same node instead of relocating it to another node <br>  https://access.redhat.com/solutions/1584703<br><br>위의 동작에는 '시작 실패' 또는 '멈추지 못함' 같은 예외가 있다는 점에 유의하십시오.<br>그러한 상황에서 클러스터는 '8.2. Moving Resources Due to Failure' 아티클에 묘사된 바와 같이 다르게 동작할 수 있습니다.<br><br>  ...<br>  There are two exceptions to the migration threshold concept; they occur when a resource either <br>  fails to start or fails to stop. If the cluster property start-failure-is-fatal is set to true <br>  (which is the default), start failures cause the failcount to be set to INFINITY and thus <br>  always cause the resource to move immediately. <br>  ...<br><br>상기 답변과 관련해서 추가 문의가 있으시면 저희에게 알려주시기 바랍니다.<br><br>감사합니다.<br><br>Jae Wook Shin &amp; Ondrej Famera<br><br><publishedDate>2017-04-17T05:24:57Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JIryyIAD"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-16T12:10:15Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-16T12:10:15Z</b><br><br>안녕하세요?<br>문제되었던 2가지의 케이스에대해서 이야기 하도록 하겠습니다.<br><br>1. 총 4path중에 2path 끊어졌을시 발생되었던 문제.<br> - 정상적으로 2path보이며 fail over되지 않았습니다. (timeout=10 on-fail=fence and timeout=30 on-fail=restart)<br><br>2. GAD QUORUM DEVICE 절체시<br> - timeout=10 on-fail=fence 로 진행할시 언클린 상태로 되며 FENCE 진행되고 서비스 불가<br> - timeout=30 on-fail=restart 로 진행할시 클러스터는 아무런 반응도 없었으며 정상적으로 서비스 됨.<br><br>여기서 궁금한것이 있어 하나 있어 여쭤봅니다.<br>on-fail restart의 메카니즘을 설명 부탁드립니다.<br>문제가 발생시 restart를 얼마나 하는것인지? fence는 제대로 되는것인지 답변 부탁드립니니다.<br><br><publishedDate>2017-04-16T12:10:15Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JIclaIAD"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-14T06:59:28Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-14T06:59:28Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>연계 감사합니다.<br>일단 해당 테스트 후 피드백을 기다리도록 하겠습니다. :)<br><br>감사합니다.<br><br><publishedDate>2017-04-14T06:59:28Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JIc9lIAD"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-14T05:32:22Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-14T05:32:22Z</b><br><br>답변 감사합니다.<br>아직 테스트 전 입니다. 테스트 후 결과에 대해서 말씀드리도록 하겠습니다.<br><br><publishedDate>2017-04-14T05:32:22Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JIamIIAT"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-14T01:23:32Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-14T01:23:32Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>문의하신 내용에 대해 답변 드리면 다음과 같습니다.<br><br>1) 재확인 결과, 말씀하신 것과 같이 옵션을 사용할 때는 풀 옵션을 다 써주셔야 합니다.<br><br>  pcs resource update LV_APP_con_ctmag1  op monitor interval=5s timeout=30 on-fail=restart OCF_CHECK_LEVEL=10 <br>  pcs resource update LV_APP_con_ctmag2  op monitor interval=5s timeout=30 on-fail=restart OCF_CHECK_LEVEL=10 <br>  pcs resource update LV_APP_con_ctmag901  op monitor interval=5s timeout=30 on-fail=restart OCF_CHECK_LEVEL=10 <br>  pcs resource update LV_APP_con_ctmag902  op monitor interval=5s timeout=30 on-fail=restart OCF_CHECK_LEVEL=10<br><br>2) 리소스의 경우는 상기 네가지 리소스만 수정해주시면 됩니다. 다른 리소스들은 스토리지와는 관계가 없거나(IPaddr2)<br>이미 많은 타임아웃 값을 가지고 있습니다.(PCTA1_script, 120s).<br><br>3) <br>'Interval'은 얼마나 자주 모니터링을 시작할 지를 나타냅니다.<br>'Timeout' 은 리소스 모니터링이 시작된 후 실패를 감지할 때까지 얼마나 기다려줄지를 정의합니다.<br><br>만일, interval 이 timeout 보다 작으면 그것은 동시에 멀티플 모니터링이 가능할 것입니다<br>이것은 몇몇 상황에서는 이슈를 더욱 빨리 감지하는 능력을 향상 시키는데 바람직할 것입니다.<br><br>다음 예들을 참고하여 주시기 바랍니다.<br><br>Example 1:<br>  interval=5s timeout=30<br>  Cluster checks the health of resource every 5 seconds. In worst case it will notice<br>  that something is wrong in 'interval'+'timeout' time. In this case 5+30 = 35 seconds to<br>  detect issue. It may happen that there will be multiple monitoring processes at same time.<br><br>Example 2:<br>  interval=30s timeout=30<br>  Cluster checks the health of resource every 30 seconds. In worst case it will notice<br>  that something is wrong in 'interval'+'timeout' time. In this case 30+30 = 60 seconds to<br>  detect issue. There will be only one monitoring process at same time.<br><br>감사합니다.<br><br>Jae Wook Shin &amp; Ondrej Famera<br><br><publishedDate>2017-04-14T01:23:32Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JIMaKIAX"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-13T04:04:35Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-13T04:04:35Z</b><br><br>케이스를 보다가 궁금한게 있는데요...<br>LV_APP_con_ctmag901, LV_APP_con_ctmag902 의 리소스의 OP와 <br>LV_APP_con_ctmag1, LV_APP_con_ctmag2 의 리소스 OP 파라메터가 같은데..<br>2개 다 업데이트 해주어야 하는것으로 보이는데요.... 업데이트 해야할 리소스에 대해서 말씀 부탁드립니다.<br><br>연락 바랍니다.<br><br><publishedDate>2017-04-13T04:04:35Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JHslJIAT"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-12T08:28:29Z</b><br><b>마지막 답변자 : Famera, Ondrej</b><br><b>마지막 수정 일자 : 2017-04-12T09:08:41Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>리소스를 변경하는 방법은 다음과 같습니다.<br>~~~<br>  Resource: LV_APP_con_ctmag902 (class=ocf provider=heartbeat type=Filesystem)<br>   Attributes: device=/dev/mapper/SRPCTAAP4VG-APP_con_ctmag902 directory=/APP/controlm/ctmag902 fstype=xfs run_fsck=no <br>   Operations: stop interval=0s timeout=60 (LV_APP_con_ctmag902-stop-interval-0s)<br>               start interval=0s start-delay=5s (LV_APP_con_ctmag902-start-interval-0s)<br>               monitor interval=5s timeout=10 on-fail=fence OCF_CHECK_LEVEL=10 (LV_APP_con_ctmag902-monitor-interval-5s)<br>~~~<br><br># pcs resource update LV_APP_con_ctmag902 op monitor timeout=30 on-fail=restart<br>====<br><br>Hello,<br><br>My name is Ondrej Famera, cluster engineer assisting on this case.<br><br>Commands you provided are OK except of small typo ('timeuot' -&gt; 'timeout'), below corrected.<br><br>  pcs resource update LV_APP_con_ctmag1  op monitor interval=5s timeout=30 on-fail=restart OCF_CHECK_LEVEL=10 <br>  pcs resource update LV_APP_con_ctmag2  op monitor interval=5s timeout=30 on-fail=restart OCF_CHECK_LEVEL=10 <br>  pcs resource update LV_APP_con_ctmag901  op monitor interval=5s timeout=30 on-fail=restart OCF_CHECK_LEVEL=10 <br>  pcs resource update LV_APP_con_ctmag902  op monitor interval=5s timeout=30 on-fail=restart OCF_CHECK_LEVEL=10<br><br>Additional info:  When using 'pcs resource update' you don't need to specify <br>values that will not change. Below commands are also OK. They have same effect as above<br><br>  pcs resource update LV_APP_con_ctmag1  op monitor timeout=30 on-fail=restart <br>  pcs resource update LV_APP_con_ctmag2  op monitor timeout=30 on-fail=restart <br>  pcs resource update LV_APP_con_ctmag901  op monitor timeout=30 on-fail=restart <br>  pcs resource update LV_APP_con_ctmag902  op monitor timeout=30 on-fail=restart<br><br>감사합니다.<br>Jae Wook Shin &amp; Ondrej Famera<br><br><publishedDate>2017-04-12T08:28:28Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JHt3AIAT"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-12T08:51:19Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-12T08:51:19Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>죄송합니다만 커멘드 확인 및 테스트 때문에 늦으면 내일 오전 중 답변 가능할 것 같습니다<br>양해부탁드립니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-12T08:51:19Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JHspQIAT"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-12T08:34:12Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-12T08:34:25Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>체크 후, 금일중(18시까지) 바로 답변 드리도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-12T08:34:11Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JHsnUIAT"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-12T08:31:52Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-12T08:31:52Z</b><br><br>아래와 같이 업데이트 하는것이 맞는것인지요? 그리고 timeout뒤에 s를 붙여야 하나요? 아니면 안붙여도 되나요?<br><br>pcs resource update LV_APP_con_ctmag1  op monitor interval=5s timeuot=30 on-fail=restart OCF_CHECK_LEVEL=10 <br>pcs resource update LV_APP_con_ctmag2  op monitor interval=5s timeuot=30 on-fail=restart OCF_CHECK_LEVEL=10 <br>pcs resource update LV_APP_con_ctmag901  op monitor interval=5s timeuot=30 on-fail=restart OCF_CHECK_LEVEL=10 <br>pcs resource update LV_APP_con_ctmag902  op monitor interval=5s timeuot=30 on-fail=restart OCF_CHECK_LEVEL=10<br><br><publishedDate>2017-04-12T08:31:52Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JHsZuIAL"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-12T08:16:25Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-12T08:16:25Z</b><br><br>답변 감사합니다.<br>타임 아웃 외 모니터 인터벌값은 변경 안해도 되는건지요? 현 5초입니다.<br>그리고 리소스 내용 변경 명령어 하나 부탁드립니다.<br><br>현재까지 변경 해야 할 파라메터값<br>1) resource 모니터링 30초<br>2)on-fail restart<br><br><publishedDate>2017-04-12T08:16:25Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JHrcfIAD"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-12T06:39:32Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-12T07:05:56Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>내부적으로 저희 관련 엔지니어들과 해당 건에 대해서 검토한 결과,<br>multipath 의 polling_interval(히타치 권고값 20초; 디폴트 5초) 시간에 비해<br>리소스 모니터링 timeout(10초) 의 시간이 너무 짧은 것으로 보입니다.<br><br>상기와 같은 설정에서는 multipath 에 문제가 발생시<br>multipath 단에서 이슈에 대응하기 전에 cluster 단에서 리소스 모니터링의 감시 및 이상이 감지될 것입니다.<br><br>더불어 on-fail=fence 이므로 더욱 민감하게 fence 가 발생할 수 있습니다.<br>따라서, 확인을 위해 on-fail 옵션을 다시 디폴트인 restart 로 변경하시고,<br>리소스 모니터링 timeout 의 값을 multipath 에 맞게 30 초로 변경하신 후<br>재테스트 및 피드백 부탁드립니다.<br><br>리소스 수정과 관련해서 다음 링크를 참조하시면 도움이 되실 것으로 보입니다.<br><br>6.8. Modifying Resource Parameters<br>- https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/High_Availability_Add-On_Reference/resourcemodify.html<br><br>감사합니다.<br><br><publishedDate>2017-04-12T06:39:32Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JDOKUIA5"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-11T07:36:12Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-11T07:36:11Z</b><br><br>안녕하세요?<br><br>1) 멀티패스 polling_interval에 대한 값은 히다찌의 권고값으로 설정 하였습니다.<br><br>2) on-fail값은 fail시 리소스를 확실하게 반환시키기 위하여 fence값을 주었씁니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-11T07:36:11Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JDNhiIAH"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-11T06:46:22Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-11T06:46:22Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>올려주신 내용을 정리하여 확인한 결과,<br>두가지 확인이 필요한 요청사항이 있습니다.<br><br>~~~<br># /etc/multipath.conf<br><br>  defaults {<br>        user_friendly_names     yes<br>        find_multipaths         yes<br>        polling_interval        20  &lt;---<br>  }<br><br># man multipath.conf<br>  ...<br>       polling_interval interval between two path checks in seconds. For properly functioning paths, the interval between checks will gradually increase to<br>                        max_polling_interval; default is 5<br><br>       max_polling_interval<br>                        maximal interval between two path checks in seconds; default is 4 * polling_interval<br>  ...<br>~~~<br><br>1) 우선 멀티패스의 polling_interval 시간이 디폴트인 5초의 4배인 20초인데요,<br>어떤 이유가 있으신지 확인바랍니다.<br><br>2) 두번째는 다음 리소스에서 확인가능한 &quot;on-fail&quot; 파라메터의 값이 fence 로 되어 있는데요, 디폴트인 restart 가 아닌 fence 로 하신<br>이유에 대해 확인바랍니다. <br>~~~<br>  Resource: LV_APP_con_ctmag902 (class=ocf provider=heartbeat type=Filesystem)<br>   Attributes: device=/dev/mapper/SRPCTAAP4VG-APP_con_ctmag902 directory=/APP/controlm/ctmag902 fstype=xfs run_fsck=no <br>   Operations: stop interval=0s timeout=60 (LV_APP_con_ctmag902-stop-interval-0s)<br>               start interval=0s start-delay=5s (LV_APP_con_ctmag902-start-interval-0s)<br>               monitor interval=5s timeout=10 on-fail=fence OCF_CHECK_LEVEL=10 (LV_APP_con_ctmag902-monitor-interval-5s)<br>~~~<br><br>감사합니다.<br><br><publishedDate>2017-04-11T06:46:22Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JDMw0IAH"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-11T05:20:43Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-11T05:20:43Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>연계 감사드립니다.<br>추가 주신 내용도 재포함하여 저희 클러스터 전문 그룹의 엔지니어인<br>Ondrej 와 협업중이오니 정리가 되는대로 업데이트 드리도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-11T05:20:43Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JDMtVIAX"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-11T05:15:55Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-11T05:15:55Z</b><br><br>약간 시간 수정건이 있어서 말씀드리겠습니다.<br><br>san switch 에서 disable 명령을 실행한 시간은 15시 07분 34초입니다.<br><br>그렇다면.... <br>아래의 메시지가 발생된 이유는 무엇인지 궁금하네요....<br>Apr  8 15:07:29 PCTAAL02SL pengine[110788]: warning: Processing failed op monitor for LV_APP_con_ctmag901 on PCTAAL01SL-HB: unknown error (1)<br><br>또한 리소스 모니터링 인터벌이 5초에 10초 타임아웃인데 이 값이 영향을 미치는것이 아닌지?<br> <br>이 값을 적정한 값으로 수정할 필요가 있는지 여쭤봅니다.<br><br><publishedDate>2017-04-11T05:15:55Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JD8HRIA1"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-10T09:32:12Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-10T09:32:12Z</b><br><br>아래의 내용 정정합니다.<br><br>kdump 메시지는 15시 09분 29초에 expired되었고 파워 팬싱은 15시 09분 57초경에 진행되었습니다.<br><br><publishedDate>2017-04-10T09:32:12Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JD8DKIA1"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-10T09:27:29Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-10T09:27:29Z</b><br><br>2017년 4월 08일 15:07:29 경에 1번 노드 2번 노드 모두 SAN path가 절체되었으며 클러스터에서 감지가 시작된것으로 판단됩니다.<br><br>kdump 메시지는 15시 12분 01초에 expired되었고 파워 팬싱은 15시 12분 30초경에 진행되었습니다.<br><br>그리기하여 1번노드는 팬스 되어 리부팅 되어 기동 되었고  2번노드에는 언클린 상태로 되어 있었습니다.<br><br>san path가 반이 절체 되었더라도 lun은 정상적으로 보이고 vg도 정상적이어야 함인데 팬싱이 되어 어떤 이유인지 원인과<br><br>어떠한 구조적인 잘못이 있는지 궁금합니다.<br>======================<br><br><br>Apr  8 15:07:29 PCTAAL02SL crmd[110789]:  notice: State transition S_IDLE -&gt; S_POLICY_ENGINE [ input=I_PE_CALC cause=C_FSA_INTERNAL origin=abort_transition_graph ]<br>Apr  8 15:07:29 PCTAAL02SL pengine[110788]: warning: Processing failed op monitor for LV_APP_con_ctmag901 on PCTAAL01SL-HB: unknown error (1)<br><br><br>Apr  8 15:07:29 PCTAAL02SL stonith-ng[110785]:  notice: Client crmd.110789.538e66eb wants to fence (reboot) 'PCTAAL01SL-HB' with device '(any)'<br>Apr  8 15:07:29 PCTAAL02SL stonith-ng[110785]:  notice: Initiating remote operation reboot for PCTAAL01SL-HB: e5e80e05-2e1d-4035-bab0-280f6eafbbc9 (0)<br>Apr  8 15:07:29 PCTAAL02SL stonith-ng[110785]:  notice: kdump_stonith can fence (reboot) PCTAAL01SL-HB: static-list<br>Apr  8 15:07:29 PCTAAL02SL stonith-ng[110785]:  notice: ipmilan_stonith1 can fence (reboot) PCTAAL01SL-HB: static-list<br>Apr  8 15:07:29 PCTAAL02SL stonith-ng[110785]: warning: Agent 'fence_kdump' does not advertise support for 'reboot', performing 'off' action instead<br>Apr  8 15:07:29 PCTAAL02SL fence_kdump[63143]: waiting for message from '172.18.21.151'<br><br><br>Apr  8 15:09:29 PCTAAL02SL stonith-ng[110785]:   error: Operation 'reboot' [63143] (call 2 from crmd.110789) for host 'PCTAAL01SL-HB' with device 'kdump_stonith' returned: -62 (Timer expired)<br><br>Apr  8 15:09:57 PCTAAL02SL stonith-ng[110785]:  notice: Operation 'reboot' [67642] (call 2 from crmd.110789) for host 'PCTAAL01SL-HB' with device 'ipmilan_stonith1' returned: 0 (OK)<br><br>Apr  8 15:10:01 PCTAAL02SL stonith-ng[110785]: warning: Agent 'fence_kdump' does not advertise support for 'reboot', performing 'off' action instead<br>Apr  8 15:10:01 PCTAAL02SL fence_kdump[68773]: waiting for message from '172.18.21.152'<br><br>Apr  8 15:12:01 PCTAAL02SL stonith-ng[110785]:   error: Operation 'reboot' [68773] (call 3 from crmd.110789) for host 'PCTAAL02SL-HB' with device 'kdump_stonith' returned: -62 (Timer expired)<br>Apr  8 15:12:01 PCTAAL02SL stonith-ng[110785]:   error: Operation reboot of PCTAAL02SL-HB by PCTAAL02SL-HB for crmd.110789@PCTAAL02SL-HB.ecf74000: Timer expired<br>Apr  8 15:12:01 PCTAAL02SL crmd[110789]:  notice: Stonith operation 3/31:108:0:1e4dd03e-7a89-4361-94c0-d0c22f145721: Timer expired (-62)<br>Apr  8 15:12:01 PCTAAL02SL crmd[110789]:  notice: Stonith operation 3 for PCTAAL02SL-HB failed (Timer expired): aborting transition.<br>Apr  8 15:12:01 PCTAAL02SL crmd[110789]:  notice: Transition aborted: Stonith failed (source=tengine_stonith_callback:733, 0)<br>Apr  8 15:12:01 PCTAAL02SL crmd[110789]:  notice: Peer PCTAAL02SL-HB was not terminated (reboot) by PCTAAL02SL-HB for PCTAAL02SL-HB: Timer expired (ref=ecf74000-2c34-434f-a2fe-8bb747f9f842) by client crmd.110789<br>Apr  8 15:12:01 PCTAAL02SL crmd[110789]:  notice: Transition 108 (Complete=1, Pending=0, Fired=0, Skipped=0, Incomplete=16, Source=/var/lib/pacemaker/pengine/pe-warn-43.bz2): Complete<br>Apr  8 15:12:01 PCTAAL02SL pengine[110788]: warning: Processing failed op start for kdump_stonith on PCTAAL02SL-HB: unknown error (1)<br>Apr  8 15:12:01 PCTAAL02SL pengine[110788]: warning: Processing failed op monitor for LV_APP_con_ctmag902 on PCTAAL02SL-HB: unknown error (1)<br>Apr  8 15:12:01 PCTAAL02SL pengine[110788]: warning: Node PCTAAL02SL-HB will be fenced because of resource failure(s)<br>Apr  8 15:12:01 PCTAAL02SL pengine[110788]: warning: Forcing kdump_stonith away from PCTAAL02SL-HB after 1000000 failures (max=3)<br>Apr  8 15:12:01 PCTAAL02SL pengine[110788]: warning: Scheduling Node PCTAAL02SL-HB for STONITH<br>Apr  8 15:12:01 PCTAAL02SL pengine[110788]:  notice: Stop of failed resource LV_APP_con_ctmag902 is implicit after PCTAAL02SL-HB is fenced<br>Apr  8 15:12:01 PCTAAL02SL pengine[110788]:  notice: Stop of failed resource kdump_stonith is implicit after PCTAAL02SL-HB is fenced<br><br>Apr  8 15:13:51 PCTAAL01SL rsyslogd: [origin software=&quot;rsyslogd&quot; swVersion=&quot;7.4.7&quot; x-pid=&quot;1340&quot; x-info=&quot;http://www.rsyslog.com&quot;] start<br><br><publishedDate>2017-04-10T09:27:29Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JD7jhIAD"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-10T08:48:21Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-10T08:48:21Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>원할한 조사를 위해 테스트하신 날짜, 시간을 연계 바랍니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-10T08:48:21Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JD7I8IAL"><br>======================<br><b>생성계정 : Shin, Jake Jaewook</b><br><b>생성날짜 : 2017-04-10T08:11:12Z</b><br><b>마지막 답변자 : Shin, Jake Jaewook</b><br><b>마지막 수정 일자 : 2017-04-10T08:11:12Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Service를 이용해주셔서 감사합니다.<br><br>저는 신재욱이라고 하며 앞으로 이 케이스를 담당하게 되었습니다.<br><br>현재 이 케이스의 내용을 살펴보는 중이며, 관련하여 업데이트 드리도록 하겠습니다.<br><br>감사합니다.<br><br><publishedDate>2017-04-10T08:11:12Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JD527IAD"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-10T04:35:04Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-10T04:35:04Z</b><br><br>페이스메이커 클러스터입니다.<br><br><publishedDate>2017-04-10T04:35:04Z</publishedDate><createdByType>Customer</createdByType><br>======================<br></comments><br>