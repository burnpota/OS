======================<br><b>생성계정 : 타임 게이트</b><br><b>생성날짜 : 2017-04-05T05:25:42Z</b><br><b>마지막 답변자 : Meiyan Zheng</b><br><b>마지막 수정 일자 : 2017-04-17T01:59:00Z</b><br><b>id : 500A000000WlflmIAB</b><br>======================<br><br><b><font size=15>
제목  : [pacemaker] corosync 프로세스를 kill signal 9번 15번을 실행하였을때 발생되는 이슈
</font></b><br><br>======================<br><b>사전문의<br></b><br>안녕하세요?<br><br>삼성생명 가용성 테스트 중에 발생된 건에 대해서 문의 드립니다.<br><br>페이스메이커 구성<br>PPOSCL01SL(node1), PPOSCL02SL(node2)<br><br><br>1.  PPOSCL02SL 서버에서 <br>kill -9 &lt;corosync PID&gt; 를 09시 55분 16초에 실행하였습니다.<br>이로 인해서 PPOSCL02SL이 fence 되고 리소스들이 1번에서 리소스가 구동 되었습니다.<br>corosync 를 kill 시그널 9번을 실행하였을시 위와 같은 증상이 발생되는것이 맞는것인지요?<br>리부팅이 되는 증상과 fence되어 리소스가 넘어가는 증상에 대해서 정상적인 현상인지<br>타임테이블 형태로 간단하게 디테일하게 설명 주시면 감사하겠습니다<br><br><br>2. PPOSCL01SL 서버에서 <br>kill -15 &lt;corosync PID&gt; 를 10시 16분 03초에 실행하엿고 <br>이로 인하여 진행된 프로스세가 정상적인지 확인 부탁드립니다. <br><br>-9번과 -15번을 했을시  failover 과정에서 -15로 했을시 약 25초정도 늦게 failover되는데<br> 어떤 이유에서 그런지 확인 부탁드리고 번거로우시겠지만 위 2가지 케이스에 대한 <br>타임테이블 별로 구동 내용 설명 부탁드립니다.<br>=======================<br><b>상태 : Closed</b><br><b>제품명  : Red Hat Enterprise Linux</b><br><b>버젼  : 7.2</b><br><b>타입  : Usage / Documentation Help</b><br><b>계정 번호  : 5251314</b><br><b>심각도  : 3 (Normal)</b><br><enhancedSLA>false</enhancedSLA><contactIsPartner>false</contactIsPartner><tags/><br><br><comment id="a0aA000000JItBFIA1"><br>======================<br><b>생성계정 : Zheng, Meiyan</b><br><b>생성날짜 : 2017-04-17T01:57:51Z</b><br><b>마지막 답변자 : Zheng, Meiyan</b><br><b>마지막 수정 일자 : 2017-04-17T01:57:51Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services 를 이용 해 주셔서 감사합니다.<br><br>피드백에 대단히 감사드립니다. 그럼 본 케이스를 처리완료하도록 하겠습니다. <br>만약 본 케이스와 관련하여 추가 질문이 있으시다면 언제든지 재오픈하실 수 <br>있습니다. <br><br>케이스가 처리 완료되면 가능하게 고객 설문조사 메일이 발송됩니다. 고객님께서 <br>남기 신 의견은 보다 나은 서비스를 위해 지속적으로 반영될 것입니다.<br><br>향후 기술  지원 서비스의 품질 향상을 위해, 소중한 시간을 내어 주시면 대단히 <br>감사드리겠습니다.<br><br><br>감사합니다. 좋은 하루 되십시오. <br><br>Red Hat GSS<br>정미연 드림<br><br><publishedDate>2017-04-17T01:57:51Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JIryKIAT"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-16T11:56:47Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-16T11:56:47Z</b><br><br>답변감사합니다. 팬되는것으로 확인되었습니다.<br><br><publishedDate>2017-04-16T11:56:47Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JCnsQIAT"><br>======================<br><b>생성계정 : Zheng, Meiyan</b><br><b>생성날짜 : 2017-04-07T08:25:14Z</b><br><b>마지막 답변자 : Zheng, Meiyan</b><br><b>마지막 수정 일자 : 2017-04-07T08:25:14Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용 해 주셔서 감사합니다. <br><br><br>-9/-15 시그널로 corosync 프로세스를 킬 시킬때 팬싱 되는 현상은 핫빗 <br>타임아웃과 상관 없이 매번 발생 한 것으로 보입니다. <br><br>제 테스트 환경에서는 핫빗 타임 아웃을 1초나 10초로 설정 할시 모두 corosync<br>킬 시킨후 바로 팬싱 되었습니다. <br><br>혹시 테스트 결과가 다르게 나올때는 테스트 환경이 어떤 것인지 확인 가능 <br>하신다면 저희쪽에서도 재현 테스트 해 보도록 하겠습니다. <br><br><br>감사합니다. <br><br>Red Hat GSS<br>정미연 드림<br><br><publishedDate>2017-04-07T08:25:14Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JCmMmIAL"><br>======================<br><b>생성계정 : 게이트, 타임</b><br><b>생성날짜 : 2017-04-07T05:32:09Z</b><br><b>마지막 답변자 : 게이트, 타임</b><br><b>마지막 수정 일자 : 2017-04-07T05:32:09Z</b><br><br>우선 자세한 분석 감사합니다<br><br>한가지 궁금한 점이 있는데요<br><br>이렇게 -9 시그널이나 -15 시그널로 아래와 같이 kill 명령을 하였다면 <br><br>모두 동일한 아래와 같은 결과를 얻는것인지 아니면 경우에 따라 다른것인지 확인 부탁드립니다<br><br>지난번 비슷한 테스트를 진행했을때에는 팬싱이 되지 않고 둘다 정상적으로 운영이 되었던것으로 기억되는데요<br><br>정상적인 결과인지 아니면 경우나 타이밍마다 결과가 다르게 나타나는 것인지 확인 한번 부탁드립니다<br><br>감사합니다<br><br><publishedDate>2017-04-07T05:32:09Z</publishedDate><createdByType>Customer</createdByType><br>======================<br><comment id="a0aA000000JClRvIAL"><br>======================<br><b>생성계정 : Zheng, Meiyan</b><br><b>생성날짜 : 2017-04-07T02:56:39Z</b><br><b>마지막 답변자 : Zheng, Meiyan</b><br><b>마지막 수정 일자 : 2017-04-07T02:56:39Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용 해 주셔서 감사합니다. <br>======================<br>1. 장애가 났던 노드가 fencing 없이 클러스터에 리조인 할시 쟁애 노드를 fencing 시키는게 정상적인 현상입니다. <br>   아래와 같이 이번 이슈 관련 로그를 정리 해 보았으며 참고 하시기 바랍니다. <br><br>- PPOSCL02SL에서 corosync를 킬 한 것으로 보입니다. <br>Apr  4 09:55:16 PPOSCL02SL systemd: corosync.service: main process exited, code=killed, status=9/KILL<br>Apr  4 09:55:16 PPOSCL02SL systemd: pacemaker.service: main process exited, code=exited, status=107/n/a<br><br><br>- corosync 킬 된후 양 노드의 pacemaker에서 바로 corosync 와의 연결이 끊어진 것을 인식 하였습니다. <br>Apr 04 09:55:16 [91804] PPOSCL02SL pacemakerd:    error: pcmk_cpg_dispatch:     Connection to the CPG API failed: Library error (2)<br>Apr 04 09:55:16 [64029] PPOSCL01SL pacemakerd:     info: pcmk_cpg_membership:   Node 2 left group pacemakerd (peer=PPOSCL02SL-HB, counter=4.0)<br><br><br>- 킬 된 corosync 바로 리커버리 되었으며 다시 클러스터에 등록 시켰습니다. <br>Apr  4 09:55:16 PPOSCL02SL corosync[93589]: [MAIN  ] Corosync Cluster Engine ('2.3.4'): started and ready to provide service.<br>Apr  4 09:55:17 PPOSCL02SL corosync: Starting Corosync Cluster Engine (corosync): [  OK  ]<br>Apr 04 09:55:18 [93620] PPOSCL02SL       crmd:     info: crm_update_peer_proc:  cluster_connect_cpg: Node PPOSCL02SL-HB[2] - corosync-cpg is now online<br><br><br>- 하지만 클러스터 그룹에 리조인 된 노드의 상태는 unclean 으로 판정 하여 해당 노드를 fencing 시킬 준비를 하였습니다. <br>Apr 04 09:55:17 [64034] PPOSCL01SL    pengine:  warning: pe_fence_node: Node PPOSCL02SL-HB will be fenced because our peer process is no longer available<br>Apr 04 09:55:17 [64034] PPOSCL01SL    pengine:  warning: determine_online_status:       Node PPOSCL02SL-HB is unclean<br><br>- fencing을 결정 한 후 바로 리소스 failover를 준비 하였습니다. <br>Apr 04 09:55:17 [64034] PPOSCL01SL    pengine:     info: LogActions:    Leave   PPOSSCS (Started PPOSCL01SL-HB)<br>Apr 04 09:55:17 [64034] PPOSCL01SL    pengine:     info: LogActions:    Leave   PPOSSCS_script  (Started PPOSCL01SL-HB)<br>Apr 04 09:55:17 [64034] PPOSCL01SL    pengine:   notice: LogActions:    Stop    ping:0  (PPOSCL02SL-HB)<br>Apr 04 09:55:17 [64034] PPOSCL01SL    pengine:     info: LogActions:    Leave   ping:1  (Started PPOSCL01SL-HB)<br>Apr 04 09:55:17 [64034] PPOSCL01SL    pengine:     info: LogActions:    Leave   kdump_stonith   (Started PPOSCL01SL-HB)<br>Apr 04 09:55:17 [64034] PPOSCL01SL    pengine:   notice: LogActions:    Stop    vmware_stonith1 (PPOSCL02SL-HB)<br>Apr 04 09:55:17 [64034] PPOSCL01SL    pengine:     info: LogActions:    Leave   vmware_stonith2 (Started PPOSCL01SL-HB)<br><br><br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: group_print:    Resource Group: PPOSSCS_group<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: native_print:       PPOSSCS    (ocf::heartbeat:IPaddr2):       Started PPOSCL01SL-HB<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: native_print:       PPOSSCS_script     (ocf::status:MySAP):    Started PPOSCL01SL-HB<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: clone_print:    Clone Set: ping-clone [ping]<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: short_print:        Started: [ PPOSCL01SL-HB ]<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: short_print:        Stopped: [ PPOSCL02SL-HB ]<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: native_print:  kdump_stonith   (stonith:fence_kdump):  Stopped<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: native_print:  vmware_stonith1 (stonith:fence_vmware_soap):    Stopped<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: native_print:  vmware_stonith2 (stonith:fence_vmware_soap):    Stopped<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: native_color:  Resource ping:1 cannot run anywhere<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: native_color:  Resource vmware_stonith1 cannot run anywhere<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: RecurringOp:    Start recurring monitor (5s) for PPOSSCS on PPOSCL01SL-HB<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: RecurringOp:    Start recurring monitor (5s) for ping:0 on PPOSCL01SL-HB<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: RecurringOp:    Start recurring monitor (60s) for kdump_stonith on PPOSCL01SL-HB<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: RecurringOp:    Start recurring monitor (1200s) for vmware_stonith2 on PPOSCL01SL-HB<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: LogActions:    Leave   PPOSSCS (Started PPOSCL01SL-HB)<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: LogActions:    Leave   PPOSSCS_script  (Started PPOSCL01SL-HB)<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: LogActions:    Leave   ping:0  (Started PPOSCL01SL-HB)<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: LogActions:    Leave   ping:1  (Stopped)<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:   notice: LogActions:    Start   kdump_stonith   (PPOSCL01SL-HB)<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:     info: LogActions:    Leave   vmware_stonith1 (Stopped)<br>Apr 04 09:56:43 [64034] PPOSCL01SL    pengine:   notice: LogActions:    Start   vmware_stonith2 (PPOSCL01SL-HB)<br>======================<br><br>2. -15(termination signal) 시크널은 -9(kill 시크널)와 달리 프로세스를 정상 샷다운 시킵니다. <br><br>- corosyn를 -15로 킬 시킬시 정상 shutdown 시킨 것으로 보입니다. <br>Apr  4 10:16:03 PPOSCL01SL root: TG ## kill -15 &lt;corosync pid&gt; start<br>Apr  4 10:16:03 PPOSCL01SL corosync[64014]: [MAIN  ] Node was shut down by a signal<br>Apr  4 10:16:03 PPOSCL01SL corosync[64014]: [MAIN  ] Corosync Cluster Engine exiting normally<br><br><br>- 하지만 pacemaker 가 원활하게 샷다운 되지 못했습니다.  <br>Apr  4 10:16:03 PPOSCL01SL systemd: pacemaker.service: main process exited, code=exited, status=107/n/a<br><br><br>- 따라서 다시 클러스터에 조인 되어도 unclean 상태라 fencing 된 것입니다. <br>Apr 04 10:16:04 [12090] PPOSCL02SL    pengine:  warning: pe_fence_node: Node PPOSCL01SL-HB will be fenced because our peer process is no longer available<br>Apr 04 10:16:04 [12090] PPOSCL02SL    pengine:  warning: determine_online_status:       Node PPOSCL01SL-HB is unclean<br><br><br>- 장애 노드 팬싱 시키는 것을 결정 한후 pengine에서 바로 리소스 failover를 준비 하였습니다.  <br>Apr 04 10:16:04 [12090] PPOSCL02SL    pengine:   notice: LogActions:    Move    PPOSSCS (Started PPOSCL01SL-HB -&gt; PPOSCL02SL-HB)<br>Apr 04 10:16:04 [12090] PPOSCL02SL    pengine:   notice: LogActions:    Move    PPOSSCS_script  (Started PPOSCL01SL-HB -&gt; PPOSCL02SL-HB)<br>Apr 04 10:16:04 [12090] PPOSCL02SL    pengine:     info: LogActions:    Leave   ping:0  (Started PPOSCL02SL-HB)<br>Apr 04 10:16:04 [12090] PPOSCL02SL    pengine:   notice: LogActions:    Stop    ping:1  (PPOSCL01SL-HB)<br>Apr 04 10:16:04 [12090] PPOSCL02SL    pengine:   notice: LogActions:    Move    kdump_stonith   (Started PPOSCL01SL-HB -&gt; PPOSCL02SL-HB)<br>Apr 04 10:16:04 [12090] PPOSCL02SL    pengine:     info: LogActions:    Leave   vmware_stonith1 (Started PPOSCL02SL-HB)<br>Apr 04 10:16:04 [12090] PPOSCL02SL    pengine:   notice: LogActions:    Stop    vmware_stonith2 (PPOSCL01SL-HB)<br><br><br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: group_print:    Resource Group: PPOSSCS_group<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: native_print:       PPOSSCS    (ocf::heartbeat:IPaddr2):       Stopped<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: native_print:       PPOSSCS_script     (ocf::status:MySAP):    Stopped<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: clone_print:    Clone Set: ping-clone [ping]<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: short_print:        Started: [ PPOSCL02SL-HB ]<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: short_print:        Stopped: [ PPOSCL01SL-HB ]<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: native_print:  kdump_stonith   (stonith:fence_kdump):  Started PPOSCL02SL-HB<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: native_print:  vmware_stonith1 (stonith:fence_vmware_soap):    Started PPOSCL02SL-HB<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: native_print:  vmware_stonith2 (stonith:fence_vmware_soap):    Stopped<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: native_color:  Resource ping:1 cannot run anywhere<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: native_color:  Resource vmware_stonith2 cannot run anywhere<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: RecurringOp:    Start recurring monitor (5s) for PPOSSCS on PPOSCL02SL-HB<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: RecurringOp:    Start recurring monitor (60s) for kdump_stonith on PPOSCL02SL-HB<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:   notice: LogActions:    Start   PPOSSCS (PPOSCL02SL-HB)<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:   notice: LogActions:    Start   PPOSSCS_script  (PPOSCL02SL-HB)<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: LogActions:    Leave   ping:0  (Started PPOSCL02SL-HB)<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: LogActions:    Leave   ping:1  (Stopped)<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: LogActions:    Leave   kdump_stonith   (Started PPOSCL02SL-HB)<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: LogActions:    Leave   vmware_stonith1 (Started PPOSCL02SL-HB)<br>Apr 04 10:17:46 [12090] PPOSCL02SL    pengine:     info: LogActions:    Leave   vmware_stonith2 (Stopped)<br><br><br>fencing 발생시 리소스 위치를 재초기화 할시의 pengine 로그를 보시면 -15 시그널을 날릴때 리커버리 <br>해야할 리소스가 -9 날릴때 보다 많았습니다. 따라서 모든 리소스를 리커버리 하는 시간이 많았던 것으로 <br>보입니다. <br><br>혹시 관련 하여 추가적인 문의 사항이 있으실 경우 다시 연락 주시기 바랍니다. <br><br>감사합니다. <br><br>Red Hat GSS<br>정미연 드림<br><br><publishedDate>2017-04-07T02:56:39Z</publishedDate><createdByType>Associate</createdByType><br>======================<br><comment id="a0aA000000JCU5yIAH"><br>======================<br><b>생성계정 : Zheng, Meiyan</b><br><b>생성날짜 : 2017-04-06T01:14:11Z</b><br><b>마지막 답변자 : Zheng, Meiyan</b><br><b>마지막 수정 일자 : 2017-04-06T01:14:11Z</b><br><br>안녕하세요,<br><br>Red Hat Global Support Services를 이용 해 주셔서 감사합니다. <br><br><br>저는 정미연이라고 하며 앞으로 본 케이스를 담당하게 되었습니다. <br>말씀 하신 테스트 결과에 대해 첨부 파일을 확인 후 업데이트 드리도록 <br>하겠습니다. <br><br><br>감사합니다.<br><br>Red Hat GSS<br>정미연 드림<br><br><publishedDate>2017-04-06T01:14:11Z</publishedDate><createdByType>Associate</createdByType><br>======================<br></comments><br>